[{"path":"https://georgewoolsey.github.io/cloud2trees/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://georgewoolsey.github.io/cloud2trees/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://georgewoolsey.github.io/cloud2trees/articles/cloud2raster-tutorial.html","id":"extract-raster-data-from-point-cloud-defaults","dir":"Articles","previous_headings":"","what":"Extract Raster Data from Point Cloud: Defaults","title":"Creating DTM and CHM rasters","text":"’ll begin using small point cloud dataset ships lidR package processing (previously used data package overview demonstration. cloud2raster() function requires input_las_dir argument path single point cloud file (.las .laz) directory containing files. directory utilized, function treats directory sub-directories single point cloud catalog, processing contained files together. Therefore, ensure specified directory contains point cloud data intended single processing area, function recursively processes files within path. also need define outputs written output_dir argument. demonstration ’ll use temporary directory ’ll likely want point permanent directory, example: C:/Data/MixedConifer. First, ’ll run cloud2raster() default settings see progress bar giving updates process . Now, let’s explore cloud2raster() created command show list five objects output contains. dtm_rast chm_rast contain main raster outputs, users might care three objects. normalize_flist contains list height normalized point cloud tiles, chunk_las_catalog_ans ggplot object creating plot displays dataset’s tiles, create_project_structure_ans table listing data source locations output file locations. cloud2raster() also wrote data disk location defined output_dir argument use outside current working session. process creates sub-folder containing outputs always titled point_cloud_processing_delivery. run process multiple times using output_dir location, everything point_cloud_processing_delivery directory overwritten. , intend perform multiple iterations processing output_dir location recommended rename point_cloud_processing_delivery directory running next iteration. Let’s see written disk. .tif file DTM CHM raster includes resolution data file name. also raw_las_ctg_info.gpkg file includes processing extent covered point cloud data spatial polygon. data can used ensure point cloud covered intended area interest calculate area-based metrics properly representing area covered data. spatial extent chunk_las_catalog_ans$process_data return cloud2raster() function.  Let’s look digital terrain model (DTM) raster DTM created cloud2raster() default 1 m resolution elevations vary 0.00 0.62 m. can plot DTM using terra::plot()  plot shows fair amount variation, let’s remember represents 0.62 m vertical relief. looked area 60 m vertical relief, example, even notice small fluctuations. also canopy height model (CHM) raster CHM created cloud2raster() default 0.25 m resolution elevations vary 2.01 32.02 m. can plot CHM using terra::plot()  can also plot raster data using ggplot2 package provides vast collection customization plotting. , ’ll use different color palette used terra::plot() demonstrate, grDevices::heat.colors color palette used desired.  really like figure want share , can write image file","code":"# the path to a single .las|.laz file  #  -or- the directory to a folder with many .las|.laz files las_dir <- system.file(package = \"lidR\", \"extdata\", \"MixedConifer.laz\") # output directroy out_dir <- tempdir() cloud2raster_ans <- cloud2trees::cloud2raster(   input_las_dir = las_dir   , output_dir = out_dir ) cloud2raster_ans %>% names() #> [1] \"dtm_rast\"                     \"chm_rast\"                     #> [3] \"create_project_structure_ans\" \"chunk_las_catalog_ans\"        #> [5] \"normalize_flist\" file.path(out_dir, \"point_cloud_processing_delivery\") %>%    list.files() #> [1] \"chm_0.25m.tif\"         \"dtm_1m.tif\"            \"raw_las_ctg_info.gpkg\" file.path(out_dir, \"point_cloud_processing_delivery\", \"raw_las_ctg_info.gpkg\") %>%    sf::st_read(quiet = T) %>%    ggplot2::ggplot() +    ggplot2::geom_sf(fill = NA, color = \"navy\", lwd = 5) +   ggplot2::geom_sf(     data = cloud2raster_ans$chunk_las_catalog_ans$process_data     , fill = NA, color = \"gold\", lwd = 1.3   ) +   ggplot2::theme_light() # there's a DTM cloud2raster_ans$dtm_rast #> class       : SpatRaster  #> size        : 90, 90, 1  (nrow, ncol, nlyr) #> resolution  : 1, 1  (x, y) #> extent      : 481260, 481350, 3812921, 3813011  (xmin, xmax, ymin, ymax) #> coord. ref. : NAD83 / UTM zone 12N (EPSG:26912)  #> source      : dtm_1m.tif  #> name        : 1_dtm_1m  #> min value   : 0.000000  #> max value   : 0.622001 terra::plot(cloud2raster_ans$dtm_rast) # there's a CHM cloud2raster_ans$chm_rast #> class       : SpatRaster  #> size        : 360, 360, 1  (nrow, ncol, nlyr) #> resolution  : 0.25, 0.25  (x, y) #> extent      : 481260, 481350, 3812921, 3813011  (xmin, xmax, ymin, ymax) #> coord. ref. : NAD83 / UTM zone 12N (EPSG:26912)  #> source      : chm_0.25m.tif  #> name        : focal_mean  #> min value   :       2.01  #> max value   :      32.02 terra::plot(cloud2raster_ans$chm_rast, col = grDevices::heat.colors(55, alpha = 0.88)) cloud2raster_ans$chm_rast %>%   terra::as.data.frame(xy=T) %>%   dplyr::rename(f=3) %>%   ggplot2::ggplot() +   ggplot2::geom_tile(     mapping = ggplot2::aes(x=x, y=y, fill=f)     , alpha = 0.9   ) +   ggplot2::scale_fill_viridis_c(option = \"plasma\") +   ggplot2::scale_x_continuous(expand = c(0, 0)) +   ggplot2::scale_y_continuous(expand = c(0, 0)) +   ggplot2::labs(x = \"X\", y = \"Y\", fill = \"CHM (m)\") +   ggplot2::theme_light() +   ggplot2::theme(     legend.position = \"top\"     , axis.text = ggplot2::element_text(size = 7)   ) ggplot2::ggsave(   file.path(out_dir,\"MixedConifer_chm_025m.jpg\")   , dpi = 300   , height = 5, width = 6 )"},{"path":"https://georgewoolsey.github.io/cloud2trees/articles/cloud2raster-tutorial.html","id":"customizing-dtm-generation","dir":"Articles","previous_headings":"","what":"Customizing DTM Generation","title":"Creating DTM and CHM rasters","text":"cloud2raster() function offers two key arguments influence DTM’s role pipeline quality final raster products. straightforward argument dtm_res_m, controls final output resolution rasterized DTM. second argument, accuracy_level, requires context. processing point cloud, cloud2raster() always first generates continuous DTM creating Delaunay triangulation (“meshed DTM”) ground classified points. continuous model separate rasterized DTM generated independent accuracy_level setting. accuracy_level argument affect DTM creation, determines DTM product used height-normalize non-ground points subsequent CHM generation. accuracy_level set ‘1’, DTM resolution defined dtm_res_m argument used normalization, meaning chosen dtm_res_m impact final CHM quality. However, accuracy_level set ‘2’ ‘3’, higher-fidelity triangulated DTM used normalization, dtm_res_m setting impact CHM quality. Using higher values (‘2’ ‘3’) accuracy_level argument results longer processing times, however testing shown limited differences CHM output level ‘2’ ‘3’. create DTM 2 m 0.5 m resolutions look differences First, 2 m DTM can confirm got resolution expected checking resolution X Y horizontal Let’s plot DTM raster store . won’t show ’ll combine later using patchwork Second, 0.5 m DTM can confirm got resolution expected checking resolution X Y horizontal Let’s plot DTM raster store . won’t show ’ll combine later using patchwork combine patchwork::wrap_plots()  Visually seems 0.5 m resolution smoother appearance 2.0 m resolution, important consider trade-offs 0.5 m resolution data contains 16 times much data. maximize flexibility avoid repeating computationally expensive point cloud processing (significant issue, especially broad-extent data), strongly advise generating DTM finest resolution needed (.e. smaller dtm_res_m setting). However, set resolution finer analysis requires, generating storing unnecessarily high-resolution data wastes time disk space. far efficient later aggregate fine resolution raster re-run entire pipeline. instance, can take fine 0.5 m resolution raster aggregate coarse 2.0 m resolution. create coarser, 2.0 m resolution raster 0.5 m resolution raster using terra::aggregate() ’ll display resultant resolution X Y horizontal","code":"# 2 m dtm cloud2raster_ans_dtm_2m <- cloud2trees::cloud2raster(   input_las_dir = las_dir   , output_dir = out_dir   , dtm_res_m = 2.0 ) # 2 m dtm paste0(   \"The resolution of `cloud2raster_ans_dtm_2m` is: \"   , paste( terra::res(cloud2raster_ans_dtm_2m$dtm_rast), collapse = \"x\") ) #> [1] \"The resolution of `cloud2raster_ans_dtm_2m` is: 2x2\" # plt_dtm_2m plt_dtm_2m <- cloud2raster_ans_dtm_2m$dtm_rast %>%   terra::as.data.frame(xy=T) %>%   dplyr::rename(f=3) %>%   ggplot2::ggplot() +   ggplot2::geom_tile(     mapping = ggplot2::aes(x=x, y=y, fill=f)     , alpha = 0.9   ) +   ggplot2::scale_fill_viridis_c(option = \"viridis\") +   ggplot2::scale_x_continuous(expand = c(0, 0)) +   ggplot2::scale_y_continuous(expand = c(0, 0)) +   ggplot2::labs(fill = \"Elevation (m)\", title = \"DTM - 2.0 m resolution\") +   ggplot2::theme_light() +   ggplot2::theme(     legend.position = \"none\"     , axis.text = ggplot2::element_text(size = 5)     , axis.title = ggplot2::element_blank()     , plot.title = ggplot2::element_text(hjust = 0.5)   ) # 0.5 m dtm cloud2raster_ans_dtm_0.5m <- cloud2trees::cloud2raster(   input_las_dir = las_dir   , output_dir = out_dir   , dtm_res_m = 0.5 ) # 0.5 m dtm paste0(   \"The resolution of `cloud2raster_ans_dtm_0.5m` is: \"   , paste( terra::res(cloud2raster_ans_dtm_0.5m$dtm_rast), collapse = \"x\") ) #> [1] \"The resolution of `cloud2raster_ans_dtm_0.5m` is: 0.5x0.5\" # plt_dtm_0.5m plt_dtm_0.5m <- cloud2raster_ans_dtm_0.5m$dtm_rast %>%   terra::as.data.frame(xy=T) %>%   dplyr::rename(f=3) %>%   ggplot2::ggplot() +   ggplot2::geom_tile(     mapping = ggplot2::aes(x=x, y=y, fill=f)     , alpha = 0.9   ) +   ggplot2::scale_fill_viridis_c(option = \"viridis\") +   ggplot2::scale_x_continuous(expand = c(0, 0)) +   ggplot2::scale_y_continuous(expand = c(0, 0)) +   ggplot2::labs(fill = \"Elevation (m)\", title = \"DTM - 0.5 m resolution\") +   ggplot2::theme_light() +   ggplot2::theme(     legend.position = \"none\"     , axis.text = ggplot2::element_text(size = 5)     , axis.title = ggplot2::element_blank()     , plot.title = ggplot2::element_text(hjust = 0.5)   ) # patchwork patchwork::wrap_plots(plt_dtm_2m, plt_dtm_0.5m) terra::aggregate(     cloud2raster_ans_dtm_0.5m$dtm_rast     , fact = 4     , fun = \"max\"   ) %>%    terra::res() %>%    paste(collapse = \"x\") #> [1] \"2x2\""},{"path":"https://georgewoolsey.github.io/cloud2trees/articles/cloud2raster-tutorial.html","id":"customizing-chm-generation","dir":"Articles","previous_headings":"","what":"Customizing CHM Generation","title":"Creating DTM and CHM rasters","text":"Individual Tree Detection (ITD) traditionally achieved using two main approaches: segmenting trees directly point cloud clustering points based crown shape spacing (e.g. Li et al. 2012), using Canopy Height Model (CHM) delineate crowns identifying tree tops (local maxima; e.g. Popescu Wynne 2004). cloud2trees package built exclusively upon CHM methodology ITD. CHM therefore critical, indispensable input subsequent steps pipeline. Users wishing explore direct point cloud segmentation methods consult functionalities lidR package (e.g. lidR::li2012()). cloud2raster() function provides several arguments customization CHM. includes influence previously discussed accuracy_level parameter, dictates whether CHM normalized using continuous triangulation (level ‘2’ ‘3’) coarser rasterized DTM (level ‘1’). three primary arguments customizing CHM chm_res_m, sets output resolution, min_height (default 2.0 m) max_height (default 70 m), control height thresholds CHM cell inclusion. high outliers typically removed early noise filtering, max_height parameter primarily serves limit height search range expected forest vegetation heights. min_height setting, hand, represents minimum height threshold segmented object subsequently considered tree ITD process. important note CHM intended ITD, height thresholds must considered carefully reflect expected tree heights, uses, thresholds set meet specific objectives. Let’s create CHM data 0.60 m, 0.40 m, 0.20 m resolutions look differences. , also demonstrate creating unique folders store results cloud2raster() otherwise written overwritten point_cloud_processing_delivery directory. can confirm got resolution expected checking resolution X Y horizontal Let’s plot CHM rasters combine using patchwork combine patchwork::wrap_plots()  transition coarser resolution CHM (0.6 m) finest resolution CHM (0.2 m), several changes apparent. first difference relates canopy coverage: coarser resolution data covers area minimum height threshold. occurs larger cell size forces raster search broader area highest non-ground point, effectively smoothing point cloud data reducing fine detail small gaps. Conversely, finer resolution data makes crown gaps apparent, increased detail comes risk introducing “holes” within continuous individual tree crowns (effect can mitigated post-processing smoothing). Furthermore, finer resolution CHM better resolves small trees, making apparent product. using finer resolution CHM shown improve tree detection tree crown area accuracy, trade-must considered 0.2 m resolution product generates 9 times amount data store process compared 0.6 m resolution product. simple rule thumb determining fine CHM generate ensure least one point per cell target CHM. find minimum CHM resolution created given point density (.e. points m-2) maintaining threshold, use formula 1/point_density\\sqrt{1/\\text{point_density}}. example, point density 17 points m-2 generate minimum CHM resolution approximately 0.24 m (1/17≈0.24\\sqrt{1/17} \\approx 0.24) ensuring least one point per cell average. Alternatively, find minimum point density needed support desired CHM resolution, use formula 1/(desired_res2)1/(\\text{desired_res}^2). instance, creating 0.3 m CHM raster requires point cloud data least 11.11 points m-2 (1/(0.32)≈11.111/(0.3^2) \\approx 11.11).","code":"# 0.6 m chm out_dir_0.6m <- file.path(out_dir,\"chm_0.6m\") dir.create(out_dir_0.6m) cloud2raster_ans_chm_0.6m <- cloud2trees::cloud2raster(   input_las_dir = las_dir   , output_dir = out_dir_0.6m   , chm_res_m = 0.6 ) # 0.4 m chm out_dir_0.4m <- file.path(out_dir,\"chm_0.4m\") dir.create(out_dir_0.4m) cloud2raster_ans_chm_0.4m <- cloud2trees::cloud2raster(   input_las_dir = las_dir   , output_dir = out_dir_0.4m   , chm_res_m = 0.4 ) # 0.2 m chm out_dir_0.2m <- file.path(out_dir,\"chm_0.2m\") dir.create(out_dir_0.2m) cloud2raster_ans_chm_0.2m <- cloud2trees::cloud2raster(   input_las_dir = las_dir   , output_dir = out_dir_0.2m   , chm_res_m = 0.2 ) paste0(   \"The resolution of `cloud2raster_ans_chm_0.4m` is: \"   , terra::res(cloud2raster_ans_chm_0.4m$chm_rast) %>%      scales::comma(accuracy = 0.01) %>%      paste(collapse = \"x\") ) #> [1] \"The resolution of `cloud2raster_ans_chm_0.4m` is: 0.40x0.40\" # plt_chm_0.6m plt_chm_0.6m <-   cloud2raster_ans_chm_0.6m$chm_rast %>%   terra::as.data.frame(xy=T) %>%   dplyr::rename(f=3) %>%   ggplot2::ggplot() +   ggplot2::geom_tile(     mapping = ggplot2::aes(x=x, y=y, fill=f)     , alpha = 0.9   ) +   ggplot2::scale_fill_viridis_c(option = \"plasma\") +   ggplot2::scale_x_continuous(expand = c(0, 0)) +   ggplot2::scale_y_continuous(expand = c(0, 0)) +   ggplot2::labs(fill = \"CHM (m)\", title = \"CHM - 0.6 m resolution\") +   ggplot2::theme_light() +   ggplot2::theme(     legend.position = \"none\"     , axis.text = ggplot2::element_text(size = 5)     , axis.title = ggplot2::element_blank()     , plot.title = ggplot2::element_text(hjust = 0.5)   ) # plt_chm_0.4m plt_chm_0.4m <-   cloud2raster_ans_chm_0.4m$chm_rast %>%   terra::as.data.frame(xy=T) %>%   dplyr::rename(f=3) %>%   ggplot2::ggplot() +   ggplot2::geom_tile(     mapping = ggplot2::aes(x=x, y=y, fill=f)     , alpha = 0.9   ) +   ggplot2::scale_fill_viridis_c(option = \"plasma\") +   ggplot2::scale_x_continuous(expand = c(0, 0)) +   ggplot2::scale_y_continuous(expand = c(0, 0)) +   ggplot2::labs(fill = \"CHM (m)\", title = \"CHM - 0.4 m resolution\") +   ggplot2::theme_light() +   ggplot2::theme(     legend.position = \"none\"     , axis.text = ggplot2::element_text(size = 5)     , axis.title = ggplot2::element_blank()     , plot.title = ggplot2::element_text(hjust = 0.5)   ) # plt_chm_0.2m plt_chm_0.2m <-   cloud2raster_ans_chm_0.2m$chm_rast %>%   terra::as.data.frame(xy=T) %>%   dplyr::rename(f=3) %>%   ggplot2::ggplot() +   ggplot2::geom_tile(     mapping = ggplot2::aes(x=x, y=y, fill=f)     , alpha = 0.9   ) +   ggplot2::scale_fill_viridis_c(option = \"plasma\") +   ggplot2::scale_x_continuous(expand = c(0, 0)) +   ggplot2::scale_y_continuous(expand = c(0, 0)) +   ggplot2::labs(fill = \"CHM (m)\", title = \"CHM - 0.2 m resolution\") +   ggplot2::theme_light() +   ggplot2::theme(     legend.position = \"none\"     , axis.text = ggplot2::element_text(size = 5)     , axis.title = ggplot2::element_blank()     , plot.title = ggplot2::element_text(hjust = 0.5)   ) # patchwork patchwork::wrap_plots(plt_chm_0.6m, plt_chm_0.4m, plt_chm_0.2m, ncol = 1)"},{"path":"https://georgewoolsey.github.io/cloud2trees/articles/cloud2trees-overview.html","id":"raw-point-cloud-data","dir":"Articles","previous_headings":"","what":"Raw Point Cloud Data","title":"Overview","text":"’ll start quick overview aerial point cloud data typical processing R, independent cloud2trees package. Aerial point cloud data highly detailed 3D datasets capture forest’s structure. data typically acquired via fixed wing crewed aircraft uncrewed aerial systems (UAS) equipped lidar sensors high-resolution cameras Digital Aerial Photogrammetry (DAP). demonstrate basic handling using widely adopted lidR package, including initial file loading (.las/.laz), metadata review, essential 3D visualization. See lidR book point cloud processing expert Jean-Romain Roussel excellent detail data processing foundational package. lidR provides necessary foundational tools tasks, cloud2trees steps fill crucial gap compiling automating complex, sequential processing steps, including built-handling large extent data can challenging users scripting pipeline scratch. Let’s load data tutorial small data set ships lidR package data? useful information can explore actual data point cloud get detail can explore X, Y, Z data relatively small data set, can visualize 3D data points colored Z measurement  now ’ve covered foundational concepts point cloud data, ’re ready put cloud2trees pipeline action using core cloud2trees() function rapidly generate complete forest inventory.","code":"# the path to a single .las file las_fpath <- system.file(package = \"lidR\", \"extdata\", \"MixedConifer.laz\") # load the single file point cloud with lidR selecting only the primary information las_data <- lidR::readLAS(las_fpath, select = \"xyzic\") las_data #> class        : LAS (v1.2 format 1) #> memory       : 1.1 Mb  #> extent       : 481260, 481350, 3812921, 3813011 (xmin, xmax, ymin, ymax) #> coord. ref.  : NAD83 / UTM zone 12N  #> area         : 8072 m² #> points       : 37.7 thousand points #> type         : airborne #> density      : 4.67 points/m² las_data@data %>% dplyr::glimpse() #> Rows: 37,657 #> Columns: 5 #> $ X              <dbl> 481349.5, 481348.7, 481348.7, 481348.6, 481348.6, 48134… #> $ Y              <dbl> 3813011, 3813011, 3813010, 3813009, 3813011, 3813011, 3… #> $ Z              <dbl> 0.07, 0.11, 0.04, 0.02, 0.04, 0.03, 0.10, 0.15, 7.40, 0… #> $ Intensity      <int> 132, 202, 148, 155, 178, 138, 126, 157, 125, 133, 131, … #> $ Classification <int> 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1… las_data@data %>% dplyr::select(X,Y,Z) %>% summary() #>        X                Y                 Z         #>  Min.   :481260   Min.   :3812921   Min.   : 0.00   #>  1st Qu.:481283   1st Qu.:3812944   1st Qu.: 1.81   #>  Median :481305   Median :3812966   Median :14.08   #>  Mean   :481305   Mean   :3812966   Mean   :12.01   #>  3rd Qu.:481328   3rd Qu.:3812989   3rd Qu.:18.67   #>  Max.   :481350   Max.   :3813011   Max.   :32.07 lidR::plot(   x = las_data   , color = \"Z\", bg = \"white\"   , legend = T   , pal = grDevices::heat.colors(55)   , rgl = T ) rgl::rglwidget()"},{"path":"https://georgewoolsey.github.io/cloud2trees/articles/cloud2trees-overview.html","id":"core-cloud2trees-pipeline","dir":"Articles","previous_headings":"","what":"Core cloud2trees() Pipeline","title":"Overview","text":"heart package cloud2trees() function, runs entire Individual Tree Detection (ITD) attribute extraction workflow based settings defined user. illustrate immediate simplicity, first demonstrate execution --one pipeline using default settings, specifying just input location example point cloud want save results (temporary directory example). strongly recommend users customize function parameters meet specific study objectives, demonstration illustrate simply cloud2trees can process raw point cloud data produce spatial forest inventory tree list well intermediate products like Digital Terrain Model (DTM) Canopy Height Model (CHM). single cloud2trees() function call needed produce spatial forest inventory tree list, DTM, CHM raw point cloud data","code":"cloud2trees_ans <- cloud2trees::cloud2trees(   input_las_dir = las_fpath   , output_dir = tempdir() )"},{"path":"https://georgewoolsey.github.io/cloud2trees/articles/cloud2trees-overview.html","id":"reviewing-outputs","dir":"Articles","previous_headings":"","what":"Reviewing Outputs","title":"Overview","text":"Regardless custom parameters selected user, upon successful completion area trees, cloud2trees() function always return spatial forest inventory tree list (including core attributes height, location, crown area typical ITD processing), well intermediate DTM CHM rasters. section focuses reviewing results, visualizing segmented crowns tree tops. Let’s check included return cloud2trees() function. digital terrain model (DTM) raster DTM created cloud2trees() default 1 m resolution elevations vary 0.00 0.62 m. can plot DTM using terra::plot()  plot shows fair amount variation, let’s remember represents 0.62 m vertical relief. looked area 60 m vertical relief, example, even notice small fluctuations. canopy height model (CHM) raster CHM created cloud2trees() default 0.25 m resolution elevations vary 2.01 32.02 m. can plot CHM using terra::plot()  treetops_sf object return cloud2trees() spatial data frame representing extracted tree tops individual points tree list contains 340 rows 25 columns. 340 rows means cloud2trees() detected 340 trees across 0.81 hectare area. default use cloud2trees() provides height, crown area, location (X Y coordinate) trees identified. However, also see many columns NA values explore cloud2trees can estimate attributes later tutorials. crowns_sf object return cloud2trees() spatial data frame representing extracted tree crowns polygons Notice cloud2trees_ans$crowns_sf cloud2trees_ans$treetops_sf exact structure one spatial polygons spatial points. Now let’s create visual individual tree crowns stored crowns_sf object overlaid CHM. time, ’ll plot using ggplot2 package  figure displays individual tree crowns cloud2trees() identified using default variable window function tree detection (.e. ws argument). look closely, can likely find places tree crowns divided. later tutorial look itd_tuning() function cloud2trees can used optimize local tree detection given crown architecture forest analyzed.","code":"# what is it? cloud2trees_ans %>% names() #> [1] \"crowns_sf\"       \"treetops_sf\"     \"dtm_rast\"        \"chm_rast\"        #> [5] \"foresttype_rast\" # there's a DTM cloud2trees_ans$dtm_rast #> class       : SpatRaster  #> size        : 90, 90, 1  (nrow, ncol, nlyr) #> resolution  : 1, 1  (x, y) #> extent      : 481260, 481350, 3812921, 3813011  (xmin, xmax, ymin, ymax) #> coord. ref. : NAD83 / UTM zone 12N (EPSG:26912)  #> source      : dtm_1m.tif  #> name        : 1_dtm_1m  #> min value   : 0.000000  #> max value   : 0.622001 terra::plot(cloud2trees_ans$dtm_rast) # there's a CHM cloud2trees_ans$chm_rast #> class       : SpatRaster  #> size        : 360, 360, 1  (nrow, ncol, nlyr) #> resolution  : 0.25, 0.25  (x, y) #> extent      : 481260, 481350, 3812921, 3813011  (xmin, xmax, ymin, ymax) #> coord. ref. : NAD83 / UTM zone 12N (EPSG:26912)  #> source      : chm_0.25m.tif  #> name        : focal_mean  #> min value   :       2.01  #> max value   :      32.02 terra::plot(cloud2trees_ans$chm_rast, col = grDevices::heat.colors(55, alpha = 0.88)) cloud2trees_ans$treetops_sf %>% dplyr::glimpse() #> Rows: 340 #> Columns: 25 #> $ treeID                    <chr> \"1_481294.4_3813010.9\", \"2_481312.9_3813010.… #> $ tree_height_m             <dbl> 15.85, 13.44, 22.07, 22.93, 24.43, 22.23, 11… #> $ crown_area_m2             <dbl> 10.8750, 6.4375, 6.3750, 26.6875, 10.1250, 1… #> $ fia_est_dbh_cm            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ fia_est_dbh_cm_lower      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ fia_est_dbh_cm_upper      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ dbh_cm                    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ is_training_data          <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ dbh_m                     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ radius_m                  <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ basal_area_m2             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ basal_area_ft2            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ ptcld_extracted_dbh_cm    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ ptcld_predicted_dbh_cm    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ tree_cbh_m                <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ is_training_cbh           <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ forest_type_group_code    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ forest_type_group         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ hardwood_softwood         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ comp_trees_per_ha         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ comp_relative_tree_height <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ comp_dist_to_nearest_m    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ max_crown_diam_height_m   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ is_training_hmd           <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ geometry                  <POINT [m]> POINT (481294.4 3813011), POINT (48131… cloud2trees_ans$crowns_sf %>% dplyr::glimpse() #> Rows: 340 #> Columns: 27 #> $ treeID                    <chr> \"1_481294.4_3813010.9\", \"2_481312.9_3813010.… #> $ tree_height_m             <dbl> 15.85, 13.44, 22.07, 22.93, 24.43, 22.23, 11… #> $ tree_x                    <dbl> 481294.4, 481312.9, 481325.1, 481335.9, 4812… #> $ tree_y                    <dbl> 3813011, 3813011, 3813011, 3813011, 3813011,… #> $ crown_area_m2             <dbl> 10.8750, 6.4375, 6.3750, 26.6875, 10.1250, 1… #> $ geometry                  <GEOMETRY [m]> POLYGON ((481292.5 3813011,..., POL… #> $ fia_est_dbh_cm            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ fia_est_dbh_cm_lower      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ fia_est_dbh_cm_upper      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ dbh_cm                    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ is_training_data          <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ dbh_m                     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ radius_m                  <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ basal_area_m2             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ basal_area_ft2            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ ptcld_extracted_dbh_cm    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ ptcld_predicted_dbh_cm    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ tree_cbh_m                <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ is_training_cbh           <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ forest_type_group_code    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ forest_type_group         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ hardwood_softwood         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ comp_trees_per_ha         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ comp_relative_tree_height <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ comp_dist_to_nearest_m    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ max_crown_diam_height_m   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ is_training_hmd           <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … cloud2trees_ans$chm_rast %>%   terra::as.data.frame(xy = T) %>%   dplyr::rename(f = 3) %>%   ggplot2::ggplot() +   ggplot2::geom_tile(     mapping = ggplot2::aes(x = x, y = y, fill = f)     ) +   ggplot2::geom_sf(     data = cloud2trees_ans$crowns_sf     , color = \"grey33\"     , lwd = 0.8     ) +   ggplot2::scale_fill_gradientn(colors = grDevices::heat.colors(55, alpha = 0.88)) +   ggplot2::labs(fill = \"CHM (m)\") +   ggplot2::theme_void()"},{"path":"https://georgewoolsey.github.io/cloud2trees/articles/cloud2trees-overview.html","id":"analyzing-outputs","dir":"Articles","previous_headings":"","what":"Analyzing Outputs","title":"Overview","text":"ultimate goal cloud2trees provide accurate spatially explicit inputs directly support management decisions. final section demonstrates output spatial tree list can immediately used forest management planning. showcase examples calculating stand-level metrics (e.g. trees per hectare mean stand height), generating height distributions, identifying potentially ecologically important trees. brief overview meant showcase easily insight can gained cloud2trees() spatial inventory, improving access data enabling cross-disciplinary integration spur novel forest management approaches enable collaborative action.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/articles/cloud2trees-overview.html","id":"stand-level-metrics","dir":"Articles","previous_headings":"Analyzing Outputs","what":"Stand-Level Metrics","title":"Overview","text":"’ll pretend forest stand central 4,000 m2 point cloud data create square polygon use stand boundary Let’s look tree top points identified cloud2trees() relation stand boundary. ’ll color tree top points tree height  get stand-level metrics can crop tree list stand boundary summarize. ’ll one tidy pipeline can break pipes (%>%) see step . cloud2trees() identified 152 trees 0.40 ha stand resulting 380.0 trees per hectare (TPH). Based 152 trees, mean stand height 14.2 m.","code":"my_stand <-   cloud2trees_ans$treetops_sf %>%      sf::st_union() %>%      sf::st_centroid() %>%      sf::st_buffer(sqrt(4000)/2, endCapStyle = \"SQUARE\") # what is this? ggplot2::ggplot() +    # tree tops   ggplot2::geom_sf(     data = cloud2trees_ans$treetops_sf     , mapping = ggplot2::aes(color = tree_height_m)     , size = 1.8   ) +    # stand polygon   ggplot2::geom_sf(     data = my_stand     , fill = NA, color = \"black\", lwd = 1.1   ) +   ggplot2::scale_color_distiller(     palette = \"Blues\", direction = 1, name = \"tree ht. (m)\"   ) +   ggplot2::theme_void() # first we'll crop the tree list to the stand treetops_in_stand <- cloud2trees_ans$treetops_sf %>% sf::st_intersection(my_stand) # summarize stand_summary <-    treetops_in_stand %>%    sf::st_drop_geometry() %>% # don't need geom now   # summarize   dplyr::summarise(     mean_tree_height_m = mean(tree_height_m)     , n_trees = dplyr::n()   ) %>%    # add stand information   dplyr::mutate(     stand_area_m2 = sf::st_area(my_stand) %>% as.numeric()     , stand_area_ha = stand_area_m2/10000     , trees_per_ha = n_trees/stand_area_ha   ) # what is this? stand_summary #> # A tibble: 1 × 5 #>   mean_tree_height_m n_trees stand_area_m2 stand_area_ha trees_per_ha #>                <dbl>   <int>         <dbl>         <dbl>        <dbl> #> 1               14.2     152         4000.         0.400         380."},{"path":"https://georgewoolsey.github.io/cloud2trees/articles/cloud2trees-overview.html","id":"height-distributions","dir":"Articles","previous_headings":"Analyzing Outputs","what":"Height Distributions","title":"Overview","text":"’ll continue look trees within stand explore tree height distribution. simple density plot heights can generated quickly  can also create custom height bins summarize trees within bins. , one big tidy pipeline can break pipes (%>%) see step .","code":"treetops_in_stand %>%    ggplot2::ggplot() +    ggplot2::geom_density(     ggplot2::aes(x = tree_height_m)     , alpha = 0.88     , fill = \"navy\", color = NA   ) +   ggplot2::labs(x = \"tree ht. (m)\") +   ggplot2::theme_light() treetops_in_stand %>%   sf::st_drop_geometry() %>%   dplyr::mutate(     height_bin = ggplot2::cut_width(       tree_height_m, width = 3, boundary = 0, closed = \"left\"     )   ) %>%    dplyr::group_by(height_bin) %>%    dplyr::summarise(     n_trees = dplyr::n()   ) %>%   dplyr::ungroup() %>%    dplyr::mutate(     stand_area_m2 = sf::st_area(my_stand) %>% as.numeric()     , stand_area_ha = stand_area_m2/10000     , trees_per_ha = n_trees/stand_area_ha     , tot_trees_per_ha = sum(trees_per_ha)     , pct = trees_per_ha/tot_trees_per_ha     , height_bin_lab = paste0(       stringr::word(           height_bin           , 1           , sep = stringr::fixed(\",\")         ) %>% readr::parse_number()       , \" to \"       , stringr::word(           height_bin           , -1           , sep = stringr::fixed(\",\")         ) %>% readr::parse_number() %>% `-`(0.1)     ) %>%      factor() %>%      forcats::fct_reorder(       stringr::word(         height_bin         , 1         , sep = stringr::fixed(\",\")       ) %>% readr::parse_number()     )   ) %>%    # plot   ggplot2::ggplot(     mapping = ggplot2::aes(       x = height_bin_lab, y = trees_per_ha       , fill = trees_per_ha       , label = paste0(         scales::comma(trees_per_ha, accuracy = 0.1)         , \"\\n\"         , scales::percent(pct, accuracy = 0.1)       )     )   ) +   ggplot2::geom_col(width = 0.7) +   ggplot2::geom_text(color = \"black\", size = 3, vjust = -0.2) +   ggplot2::scale_fill_distiller(palette = \"Purples\", direction = 1) +   ggplot2::scale_y_continuous(     labels = scales::comma_format(accuracy = 1)     , expand = ggplot2::expansion(mult = c(0, 0.1))   ) +   ggplot2::labs(     x = \"height (m) class\"     , y = \"TPH\"     , title = \"TPH by height class\"   ) +   ggplot2::theme_light() +   ggplot2::theme(     legend.position = \"none\"     , axis.text.y = ggplot2::element_text(size = 10)     , axis.text.x = element_text(angle = 90, size = 10, vjust = 0.5, hjust = 1)   )"},{"path":"https://georgewoolsey.github.io/cloud2trees/articles/cloud2trees-overview.html","id":"identify-potentially-ecologically-important-trees","dir":"Articles","previous_headings":"Analyzing Outputs","what":"Identify Potentially Ecologically important trees","title":"Overview","text":"finally, let’s identify potentially ecologically important trees based height threshold 24 m across entire extent point cloud data  since X Y coordinates trees, can easily load onto tablet GPS device navigate important trees field","code":"cloud2trees_ans$treetops_sf %>%    dplyr::mutate(     tall_tree = ifelse(tree_height_m>=24,\"Tall Tree\", \"Other\")   ) %>%    ggplot2::ggplot() +    # tree tops   ggplot2::geom_sf(     mapping = ggplot2::aes(color = tall_tree)     , size = 1.8   ) +    # stand polygon   ggplot2::geom_sf(     data = my_stand     , fill = NA, color = \"black\", lwd = 1.1   ) +   ggplot2::scale_color_viridis_d(option = \"viridis\", direction = -1, name = \"\") +   ggplot2::theme_void() +   ggplot2::theme(legend.position = \"top\") +   ggplot2::guides(color = ggplot2::guide_legend(override.aes = list(size = 5)))"},{"path":"https://georgewoolsey.github.io/cloud2trees/articles/cloud2trees-pipeline.html","id":"introduction-the-cloud2trees-processing-pipeline","dir":"Articles","previous_headings":"","what":"Introduction: The cloud2trees() Processing Pipeline","title":"cloud2trees Pipeline","text":"cloud2trees package developed streamline complex process generating consistent, scalable, spatially explicit forest fuels inventories types aerial point cloud data, including lidar Digital Aerial Photogrammetry (DAP) products. DAP utilizes techniques, Structure--Motion (SfM), overlapping aerial imagery generate 3D point clouds. development package largely spurred need among researchers managers efficiently integrate detailed forest spatial arrangements modern silviculture fire management practices. core package --one processing routine: cloud2trees() pipeline. Taking raw point cloud data, function handles every step process, including terrain modeling, Individual Tree Detection (ITD), generating comprehensive spatial tree list attributed key biophysical metrics (e.g., height, diameter, crown bulk density). guide walk function’s essential setup, detail output files, provide quick demonstration use outputs visualize analyze forest structure.","code":"library(cloud2trees)"},{"path":"https://georgewoolsey.github.io/cloud2trees/articles/cloud2trees-setup.html","id":"package-installation","dir":"Articles","previous_headings":"","what":"Package Installation","title":"Setup","text":"installation process ’ll use pkgbuild package ensure Rtools working correctly. let’s check Rtools installed correctly command issue one two responses: system ready build packages! - continue installation process select “yes” build tools begin installing (minimize R window see back ) response system ready build packages! still issues, return Rtools installation ensure RTools version matches R version. Next, need install dependent packages CRAN Now, ’ll install packages CRAN lasR package (https://r-lidar.github.io/lasR/) enables large-scale point cloud processing speed TreeLS package (https://github.com/tiagodc/TreeLS) helps us extract DBH point cloud leafR package (https://github.com/DRAAlmeida/leafR) computes leaf area density (LAD) profiles point cloud LadderFuelsR package (https://github.com/olgaviedma/LadderFuelsR) helps us extract CBH point cloud Finally, install cloud2trees package, integrates tools several others enable end--end processing point clouds generate individual tree forest inventories let’s load cloud2trees package current session ’ll also load tidyverse terra working raster data","code":"# install pkgbuild install.packages(\"pkgbuild\") # check for Rtools which is required to build packages pkgbuild::check_build_tools(debug = TRUE) # install remotes package install.packages(\"remotes\") # install tidyverse package install.packages(\"tidyverse\") # install sf package... install.packages(\"sf\") # install terra package... install.packages(\"terra\") # install BH package... install.packages(\"BH\") # install lasR for point cloud processing install.packages(\"lasR\", repos = 'https://r-lidar.r-universe.dev') # install github package from \"tiagodc/TreeLS\" remotes::install_github(repo = \"tiagodc/TreeLS\", upgrade = F) # install github package from \"DRAAlmeida/leafR\" remotes::install_github(repo = \"DRAAlmeida/leafR\", upgrade = F) # install github package from \"olgaviedma/LadderFuelsR\" remotes::install_github(repo = \"olgaviedma/LadderFuelsR\", upgrade = F) # install github package from \"georgewoolsey/cloud2trees\" remotes::install_github(repo = \"georgewoolsey/cloud2trees\", upgrade = F) library(cloud2trees) library(ggplot2) library(magrittr) library(terra)"},{"path":"https://georgewoolsey.github.io/cloud2trees/articles/cloud2trees-setup.html","id":"get-external-data","dir":"Articles","previous_headings":"","what":"Get External Data","title":"Setup","text":"cloud2trees package relies external data estimate tree DBH, USDA Forest Service’s Forest Inventory Analysis (FIA) forest type, canopy fuel loading. plan use functionality, data must downloaded first time use cloud2trees package. downloads combined use ~7 GB storage space. filter DBH values high density point clouds estimate tree DBH extracted tree height data requires training data model DBH using height. cloud2trees using site-specific allometric equations made FIA field plots extracted TreeMap 2022 data product (Houtman et al. 2025). TreeMap model FIA plot locations imputed throughout forested areas Contiguous United States 30 m spatial resolution. took ~3 minutes fast internet connection (900 mb per second) ~19 minutes Forest Service internet (50 mb per second) External data required estimate FIA forest type group append extracted trees. Forest type groups identified using Forest Type Groups Continental United States data (Wilson 2023). forest type group layer developed using data 213,000 national forest inventory plots measured period 2014-2018 FIA program. raster layer 30-meter resolution covers forested extent Contiguous United States. estimate tree crown biomass extracted trees, cloud2trees uses LANDFIRE’s Forest Canopy Bulk Density (CBD) maps spatially determine fuel loading area. currently done using LANDFIRE’s Forest Canopy Bulk Density (CBD) 2023 estimates (“CONUS LF 2023”) 30-meter resolution Contiguous United States. slow connections US Federal Government computers, command known fail. red message stating SSL connect error appears, simply retry command connects USGS server hosting data. point, full functionality cloud2trees ready use. recommend starting example dataset cloud2trees Data Structure Functionality section familiarize cloud2trees.","code":"cloud2trees::get_treemap() cloud2trees::get_foresttype() cloud2trees::get_landfire()"},{"path":"https://georgewoolsey.github.io/cloud2trees/articles/cloud2trees-setup.html","id":"quick-tests","dir":"Articles","previous_headings":"","what":"Quick Tests","title":"Setup","text":"’ll use MixedConifer.laz file ships lidR package demonstration let’s try process point cloud using defaults cloud2trees::cloud2trees() function get back? DTM?  CHM?  tree inventory? CHM tree crowns overlaid look neat?  neat-o! Next, recommended check Overview","code":"# path to las data # a test las file but this could also be a directory path with >1 .las|.laz files ## ... notice, we didn't directly install \"lidR\" above ## ... it was installed with the other packages as a dependency i <- system.file(package=\"lidR\", \"extdata\", \"MixedConifer.laz\") # run it cloud2trees_ans <- cloud2trees::cloud2trees(   output_dir = tempdir()   , input_las_dir = i ) # did it do it? cloud2trees_ans %>% names() #> [1] \"crowns_sf\"       \"treetops_sf\"     \"dtm_rast\"        \"chm_rast\"        #> [5] \"foresttype_rast\" cloud2trees_ans$dtm_rast %>%   terra::plot(axes = F) cloud2trees_ans$chm_rast %>%   terra::plot(col = viridis::plasma(100), axes = F) cloud2trees_ans$treetops_sf %>% dplyr::glimpse() #> Rows: 340 #> Columns: 25 #> $ treeID                    <chr> \"1_481294.4_3813010.9\", \"2_481312.9_3813010.… #> $ tree_height_m             <dbl> 15.85, 13.44, 22.07, 22.93, 24.43, 22.23, 11… #> $ crown_area_m2             <dbl> 10.8750, 6.4375, 6.3750, 26.6875, 10.1250, 1… #> $ fia_est_dbh_cm            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ fia_est_dbh_cm_lower      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ fia_est_dbh_cm_upper      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ dbh_cm                    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ is_training_data          <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ dbh_m                     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ radius_m                  <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ basal_area_m2             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ basal_area_ft2            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ ptcld_extracted_dbh_cm    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ ptcld_predicted_dbh_cm    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ tree_cbh_m                <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ is_training_cbh           <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ forest_type_group_code    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ forest_type_group         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ hardwood_softwood         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ comp_trees_per_ha         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ comp_relative_tree_height <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ comp_dist_to_nearest_m    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ max_crown_diam_height_m   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ is_training_hmd           <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ geometry                  <POINT [m]> POINT (481294.4 3813011), POINT (48131… cloud2trees_ans$chm_rast %>%   terra::as.data.frame(xy=T) %>%   dplyr::rename(f=3) %>%   ggplot2::ggplot() +   ggplot2::geom_tile(     mapping = ggplot2::aes(x=x,y=y,fill=f)   ) +   ggplot2::geom_sf(     data = cloud2trees_ans$crowns_sf     , color = \"gray33\"     , fill = NA     , lwd = 0.8   ) +   ggplot2::scale_fill_viridis_c(option = \"plasma\") +   ggplot2::labs(fill=\"CHM ht. (m)\") +   ggplot2::theme_void()"},{"path":"https://georgewoolsey.github.io/cloud2trees/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"George Woolsey. Author, maintainer.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Woolsey G (2025). cloud2trees: Aerial point cloud data forest inventory tree lists. R package version 0.7.3, https://georgewoolsey.github.io/cloud2trees/.","code":"@Manual{,   title = {cloud2trees: Aerial point cloud data to forest inventory tree lists},   author = {George Woolsey},   year = {2025},   note = {R package version 0.7.3},   url = {https://georgewoolsey.github.io/cloud2trees/}, }"},{"path":"https://georgewoolsey.github.io/cloud2trees/index.html","id":"cloud2trees","dir":"","previous_headings":"","what":"Aerial point cloud data to forest inventory tree lists","title":"Aerial point cloud data to forest inventory tree lists","text":"cloud2trees: Aerial point cloud data forest inventory tree lists Installation Setup Extract Trees Point Cloud: Default Individual Tree Detection (ITD) Tuning Extract Trees Point Cloud: Custom Format cloud2trees() output LANL TREES Extract Raster Data Point Cloud Extract Trees Raster Data Estimate Tree DBH Tree List Estimate Tree Forest Type Tree List Estimate Tree CBH Tree List Estimate Tree HMD Tree List Estimate Tree Biomass Tree List","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/index.html","id":"cloud2trees-aerial-point-cloud-data-to-forest-inventory-tree-lists","dir":"","previous_headings":"","what":"cloud2trees: Aerial point cloud data to forest inventory tree lists","title":"Aerial point cloud data to forest inventory tree lists","text":"goal cloud2trees provide accessible routines processing point cloud data collected airborne lidar developed using UAS imagery photogrammetry (e.g. structure motion). cloud2trees package implements methods outlined literature . methodologies implemented cloud2trees package developed specifically quantify conifer forest structure may appropriate uses. Swayze, Neal C., Wade T. Tinkham. “Application unmanned aerial system structure motion point cloud detected tree heights stem diameters model missing stem diameters.” MethodsX 9 (2022): 101729. Tinkham, Wade T., Neal C. Swayze, Chad M. Hoffman, Lauren E. Lad, Mike . Battaglia. “Modeling missing DBHs: Influence model form UAV DBH characterization.” Forests 13, . 12 (2022): 2077. Creasy, Matthew B., Wade T. Tinkham, Chad M. Hoffman, Jody C. Vogeler. “Potential individual tree monitoring ponderosa pine dominated forests using unmanned aerial system structure motion point clouds.” Canadian Journal Forest Research 51, . 8 (2021): 1093-1105. Almeida, Danilo Roberti Alves de, Scott C. Stark, Gang Shao, Juliana Schietti, Bruce Walker Nelson, Carlos Alberto Silva, Eric Bastos Gorgens, Ruben Valbuena, Daniel de Almeida Papa, Pedro Henrique Santin Brancalion. “Optimizing remote detection tropical rainforest structure airborne lidar: Leaf area profile sensitivity pulse density spatial sampling.” Remote Sensing 11, . 1 (2019): 92. Viedma, O., C. . Silva, J. M. Moreno, . T. Hudak. “LadderFuelsR: new automated tool vertical fuel continuity analysis crown base height detection using light detection ranging.” Methods Ecology Evolution (2024). development functionality cloud2trees package relies extensively groundbreaking work others. gratefully acknowledge encourage users properly cite authors contributors behind following essential R packages: lidR package (https://github.com/r-lidar/lidR) fundamental point cloud processing capabilities routines lasR package (https://r-lidar.github.io/lasR) enables large-scale point cloud processing speed TreeLS package (https://github.com/tiagodc/TreeLS) helps us extract DBH directly point cloud leafR package (https://github.com/DRAAlmeida/leafR) computes leaf area density (LAD) profiles point cloud LadderFuelsR package (https://github.com/olgaviedma/LadderFuelsR) helps us extract CBH point cloud","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/index.html","id":"installation-and-setup","dir":"","previous_headings":"","what":"Installation and Setup","title":"Aerial point cloud data to forest inventory tree lists","text":"full demonstration install setup cloud2trees including dependencies available Setup demonstration recommended users follow full install demonstration includes program functionality checks installation steps completed.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/index.html","id":"extract-trees-from-point-cloud-default","dir":"","previous_headings":"","what":"Extract Trees from Point Cloud: Default","title":"Aerial point cloud data to forest inventory tree lists","text":"addition cloud2trees, ’ll using tidyverse, sf, terra examples . cloud2trees() function --one function process raw .las|.laz files generate CHM raster (.tif), DTM raster (.tif), tree list tree location, height, DBH. example ’ll use MixedConifer.laz ships lidR package (https://r-lidar.github.io/lidRbook/). basic example using cloud2trees() function defaults single .laz file writing output temporary directory : Let’s check included return cloud2trees() function. digital terrain model (DTM) raster can plot using terra::plot()  canopy height model (CHM) raster can plot using terra::plot()  spatial data frame tree crown polygons returned. Notice dbh, cbh, forest_type, HMD (max_crown_diam_height_m), competition (comp_) columns data. estimate values, need explicitly tell cloud2trees() perform processing required setting parameters: estimate_tree_dbh=TRUE DBH (see also trees_dbh()) estimate_tree_cbh=TRUE CBH (see also trees_cbh()) estimate_tree_type=TRUE forest type (see also trees_type()) estimate_tree_hmd=TRUE tree HMD (see also trees_hmd()) estimate_tree_competition=TRUE competition (see also trees_competition()) Let’s plot tree crown polygons using ggplot2::ggplot() custom plot settings.  spatial data frame tree top points returned. Notice cloud2trees_ans$crowns_sf cloud2trees_ans$treetops_sf exact structure one spatial polygons spatial points. Let’s plot tree top points using ggplot2::ggplot() custom plot settings.  also case points cloud2trees_ans$treetops_sf match exactly one crown polygon cloud2trees_ans$crowns_sf.","code":"library(cloud2trees) # install.packages(\"tidyverse\") library(tidyverse) # install.packages(\"sf\") library(sf) # install.packages(\"terra\") library(terra) # a test las file but this could also be a directory path with >1 .las|.laz files i <- system.file(\"extdata\", \"MixedConifer.laz\", package=\"lidR\") # run it cloud2trees_ans <- cloud2trees::cloud2trees(output_dir = tempdir(), input_las_dir = i) # what is it? cloud2trees_ans %>% names() #> [1] \"crowns_sf\"       \"treetops_sf\"     \"dtm_rast\"        \"chm_rast\"        #> [5] \"foresttype_rast\" # there's a DTM cloud2trees_ans$dtm_rast %>% terra::plot() # there's a CHM cloud2trees_ans$chm_rast %>% terra::plot() # there are tree crowns cloud2trees_ans$crowns_sf %>% dplyr::glimpse() #> Rows: 340 #> Columns: 27 #> $ treeID                    <chr> \"1_481294.4_3813010.9\", \"2_481312.9_3813010.… #> $ tree_height_m             <dbl> 15.85, 13.44, 22.07, 22.93, 24.43, 22.23, 11… #> $ tree_x                    <dbl> 481294.4, 481312.9, 481325.1, 481335.9, 4812… #> $ tree_y                    <dbl> 3813011, 3813011, 3813011, 3813011, 3813011,… #> $ crown_area_m2             <dbl> 10.8750, 6.5000, 6.3750, 27.0625, 10.1250, 1… #> $ geometry                  <GEOMETRY [m]> POLYGON ((481292.5 3813011,..., POL… #> $ fia_est_dbh_cm            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ fia_est_dbh_cm_lower      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ fia_est_dbh_cm_upper      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ dbh_cm                    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ is_training_data          <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ dbh_m                     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ radius_m                  <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ basal_area_m2             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ basal_area_ft2            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ ptcld_extracted_dbh_cm    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ ptcld_predicted_dbh_cm    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ tree_cbh_m                <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ is_training_cbh           <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ forest_type_group_code    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ forest_type_group         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ hardwood_softwood         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ comp_trees_per_ha         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ comp_relative_tree_height <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ comp_dist_to_nearest_m    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ max_crown_diam_height_m   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ is_training_hmd           <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … cloud2trees_ans$crowns_sf %>%    ggplot2::ggplot(mapping = ggplot2::aes(fill = tree_height_m)) +    ggplot2::geom_sf() +    ggplot2::scale_fill_distiller(palette = \"Oranges\", name = \"tree ht. (m)\", direction = 1) +   ggplot2::theme_void() +   ggplot2::theme(legend.position = \"top\", legend.direction = \"horizontal\") # there are tree top points cloud2trees_ans$treetops_sf %>% dplyr::glimpse() #> Rows: 340 #> Columns: 25 #> $ treeID                    <chr> \"1_481294.4_3813010.9\", \"2_481312.9_3813010.… #> $ tree_height_m             <dbl> 15.85, 13.44, 22.07, 22.93, 24.43, 22.23, 11… #> $ crown_area_m2             <dbl> 10.8750, 6.5000, 6.3750, 27.0625, 10.1250, 1… #> $ fia_est_dbh_cm            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ fia_est_dbh_cm_lower      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ fia_est_dbh_cm_upper      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ dbh_cm                    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ is_training_data          <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ dbh_m                     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ radius_m                  <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ basal_area_m2             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ basal_area_ft2            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ ptcld_extracted_dbh_cm    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ ptcld_predicted_dbh_cm    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ tree_cbh_m                <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ is_training_cbh           <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ forest_type_group_code    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ forest_type_group         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ hardwood_softwood         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ comp_trees_per_ha         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ comp_relative_tree_height <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ comp_dist_to_nearest_m    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ max_crown_diam_height_m   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ is_training_hmd           <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ geometry                  <POINT [m]> POINT (481294.4 3813011), POINT (48131… cloud2trees_ans$treetops_sf %>%    ggplot2::ggplot(mapping = ggplot2::aes(color = tree_height_m)) +    ggplot2::geom_sf() +    ggplot2::scale_color_distiller(palette = \"Oranges\", name = \"tree ht. (m)\", direction = 1) +   ggplot2::theme_void() +   ggplot2::theme(legend.position = \"top\", legend.direction = \"horizontal\") ggplot2::ggplot() +    ggplot2::geom_sf(data = cloud2trees_ans$crowns_sf, mapping = ggplot2::aes(fill = tree_height_m)) +    ggplot2::geom_sf(data = cloud2trees_ans$treetops_sf, shape = 20) +    ggplot2::scale_fill_distiller(palette = \"Oranges\", name = \"tree ht. (m)\", direction = 1) +   ggplot2::theme_void() +   ggplot2::theme(legend.position = \"top\", legend.direction = \"horizontal\")"},{"path":"https://georgewoolsey.github.io/cloud2trees/index.html","id":"individual-tree-detection-itd-tuning","dir":"","previous_headings":"","what":"Individual Tree Detection (ITD) Tuning","title":"Aerial point cloud data to forest inventory tree lists","text":"cloud2trees package performs individual tree detection using lidR::locate_trees() lidR::lmf() algorithm. local maximum filter algorithm allows constant window size variable window size defined function. See lidR package book section point cloud processing expert Jean-Romain Roussel excellent detail ITD defining window size. itd_tuning() function used visually assess tree crown delineation results different window size functions used detection individual trees. itd_tuning() allows users test different window size functions sample data determine function suitable area analyzed. preferred function can used ws parameter raster2trees() cloud2trees(). generally recommended different window size function defined region study area significantly different forest structure. example, one might want define different window size forest type different silvicultural treatment. accomplish current version cloud2trees require analyst pre-process aerial point cloud data split distinct regions, perform ITD region, compile tree list post-processing.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/index.html","id":"default-itd-window-size-functions","dir":"","previous_headings":"","what":"Default ITD window size functions","title":"Aerial point cloud data to forest inventory tree lists","text":"’ll continue use MixedConifer.laz ships lidR package example. itd_tuning() enables users sample five 0.1 ha plots (n_samples parameter) randomly selected within bounding box point cloud data coverage. function named list functions can tested using ws_fn_list parameter can also left default value (NULL) test default exponential (concave ), linear, logarithmic (concave ) functions. ’ll run itd_tuning() default options start. Let’s check included return itd_tuning() function. plot different ITD window size functions tested (columns) different 0.1 ha sample plots (plot rows) number individual trees extracted shown outlined gray overlaid canopy height model (CHM).  plot summarizes trees detected based different ITD window search functions tested sample plot area. first view provides aggregated plot summary metrics including trees per hectare (TPH), mean tree height meters, mean crown diameter meters. second view shows tree size-class distribution showing proportion trees (bar label) count trees (y-axis) using five equally spaced height bins enhance insight effect search function. example, distribution can help diagnose issues -segmentation small trees, can inflate TPH estimates, , conversely, failure detect targeted height-class range. third view shows tree height--crown diameter relationship. goal window search function accurately model relationship, positive correlation expected across forest types deviations general trend suggesting need tuning (e.g. small trees unrealistically wide crowns).  think “lin_fn” appropriate area, can access function returned list window size functions store use raster2trees() cloud2trees() can plot function looks like","code":"itd_tuning_ans <- itd_tuning(input_las_dir = i, n_samples = 2) # what is it? itd_tuning_ans %>% names() #> [1] \"plot_samples\"        \"ws_fn_list\"          \"plot_sample_summary\" itd_tuning_ans$plot_samples itd_tuning_ans$plot_sample_summary # get the best function best_ws <- itd_tuning_ans$ws_fn_list$lin_fn ggplot2::ggplot() +   ggplot2::geom_function(fun = best_ws, color = \"brown\", lwd = 1) +   ggplot2::xlim(-5,60) +   ggplot2::labs(x = \"heights\", y = \"ws\", color = \"\") +   ggplot2::theme_light()"},{"path":"https://georgewoolsey.github.io/cloud2trees/index.html","id":"custom-itd-window-size-functions","dir":"","previous_headings":"","what":"Custom ITD window size functions","title":"Aerial point cloud data to forest inventory tree lists","text":"Let’s work test custom window size functions. ’ll test constant window size 3 m custom function windows size linearly related point height run itd_tuning() custom window size definitions try two sample plots 0.1 ha let’s check tuning plot  can also check custom “my_linear” function looks like","code":"# a constant window size has to be defined as:  ## rep(constant, times = length(x))  ## x*0 + constant   my_constant <- function(x){     return( rep(3, times = length(x)) ) ## will always return 3   }  # a custom linear function  my_linear <- function(x) {(x * 0.1) + 3} # let's put these in a list to test with the best default function we saved from above   my_fn_list <- list(     my_constant = my_constant     , my_linear = my_linear     , best_default_ws = best_ws   ) # run it with custom functions itd_tuning_ans2 <- itd_tuning(  input_las_dir = i  , ws_fn_list = my_fn_list  , n_samples = 2 ) # look at the tuning plot itd_tuning_ans2$plot_samples ggplot2::ggplot() +   ggplot2::geom_function(     fun = itd_tuning_ans2$ws_fn_list$my_linear     , color = \"gold\"     , lwd = 1   ) +   ggplot2::xlim(-5,60) +   ggplot2::ylim(-0.5,NA) +   ggplot2::labs(x = \"heights\", y = \"ws\", color = \"\") +   ggplot2::theme_light()"},{"path":"https://georgewoolsey.github.io/cloud2trees/index.html","id":"extract-trees-from-point-cloud-custom","dir":"","previous_headings":"","what":"Extract Trees from Point Cloud: Custom","title":"Aerial point cloud data to forest inventory tree lists","text":"’ll continue use MixedConifer.laz ships lidR package example. Customizing cloud2trees() function parameters ’ll: Change resolution DTM using dtm_res_m Change moving window used detect local maxima tree tops using ws best window size itd_tuning() exploration Estimate tree DBH using allometry FIA plot data estimate_tree_dbh Extract tree FIA Forest Type Group estimate_tree_type Quantify tree competition metrics estimate_tree_competition Extract tree CBH point cloud estimate_tree_cbh sample 555 trees using cbh_tree_sample_n Model remaining tree CBH values cbh_estimate_missing_cbh based sample 555 trees Extract tree height maximum crown diameter (HMD) point cloud estimate_tree_hmd sample 50% trees using hmd_tree_sample_prop Model remaining tree HMD values hmd_estimate_missing_hmd based sample Estimate tree crown biomass using LANDFIRE CBD product estimate_biomass_method Check digital terrain model (DTM) raster changed Check spatial data frame tree crown polygons data DBH (dbh_*), CBH (tree_cbh_m), HMD (max_crown_diam_height_m), forest_type_*, competition (comp_*), crown biomass using LANDFIRE data (landfire_*). Remember, also changed ws parameter used detect local maxima identifying tree tops got trees compared default settings. Let’s look relationship tree height tree DBH estimated FIA plot data.  Let’s look relationship tree height tree CBH extracted point cloud. Note, expect perfect linear relationship tree height CBH throughout entire height range CBH also determined spatially (e.g. fire moves stand).  can also plot height, diameter, CBH trees spatially ’ll use patchwork package combine plots.  Let’s plot distance nearest tree obtained turning estimate_tree_competition parameter cloud2trees() function call quantify tree competition metrics. ’ll use spatial tree points data cloud2trees_ans_c$treetops_sf.  Let’s look FIA Forest Type Group data extracted tree list.","code":"# make sure we know where the results are going my_dir <- tempdir() # run it cloud2trees_ans_c <- cloud2trees::cloud2trees(   output_dir = my_dir   , input_las_dir = i   , dtm_res_m = 0.5   , ws = best_ws   , estimate_tree_dbh = TRUE   , estimate_tree_type = TRUE   , estimate_tree_competition = TRUE   , estimate_tree_cbh = TRUE   , cbh_tree_sample_n = 555   , cbh_estimate_missing_cbh = TRUE   , estimate_tree_hmd = TRUE   , hmd_tree_sample_prop = 0.5   , hmd_estimate_missing_hmd = TRUE   , estimate_biomass_method = \"landfire\" ) paste(   \"Default DTM resolution:\"   , cloud2trees_ans$dtm_rast %>% terra::res() %>% paste(collapse = \",\")   , \"|| Custom DTM resolution:\"   , cloud2trees_ans_c$dtm_rast %>% terra::res() %>% paste(collapse = \",\") ) #> [1] \"Default DTM resolution: 1,1 || Custom DTM resolution: 0.5,0.5\" cloud2trees_ans_c$crowns_sf %>% dplyr::glimpse() #> Rows: 343 #> Columns: 34 #> $ treeID                    <chr> \"1_481281.4_3813010.9\", \"2_481294.4_3813010.… #> $ tree_height_m             <dbl> 22.23, 15.85, 10.06, 13.44, 22.07, 22.48, 22… #> $ tree_x                    <dbl> 481281.4, 481294.4, 481306.4, 481312.9, 4813… #> $ tree_y                    <dbl> 3813011, 3813011, 3813011, 3813011, 3813011,… #> $ crown_area_m2             <dbl> 10.3750, 10.8125, 1.1875, 4.5625, 6.3750, 10… #> $ geometry                  <GEOMETRY [m]> MULTIPOLYGON (((481280.5 38..., POL… #> $ fia_est_dbh_cm            <dbl> 49.489231, 31.309071, 17.135796, 24.843153, … #> $ fia_est_dbh_cm_lower      <dbl> 27.746832, 17.725274, 9.644044, 14.225778, 2… #> $ fia_est_dbh_cm_upper      <dbl> 75.479259, 48.115126, 26.246084, 38.082835, … #> $ dbh_cm                    <dbl> 49.489231, 31.309071, 17.135796, 24.843153, … #> $ is_training_data          <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA… #> $ dbh_m                     <dbl> 0.49489231, 0.31309071, 0.17135796, 0.248431… #> $ radius_m                  <dbl> 0.24744616, 0.15654536, 0.08567898, 0.124215… #> $ basal_area_m2             <dbl> 0.192358462, 0.076989280, 0.023062080, 0.048… #> $ basal_area_ft2            <dbl> 2.07054648, 0.82871261, 0.24824023, 0.521767… #> $ ptcld_extracted_dbh_cm    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ ptcld_predicted_dbh_cm    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ tree_cbh_m                <dbl> 15.500000, 8.500000, 7.012133, 11.720800, 20… #> $ is_training_cbh           <lgl> TRUE, TRUE, FALSE, FALSE, TRUE, TRUE, TRUE, … #> $ forest_type_group_code    <chr> \"220\", \"220\", \"220\", \"220\", \"220\", \"220\", \"2… #> $ forest_type_group         <chr> \"Ponderosa pine group\", \"Ponderosa pine grou… #> $ hardwood_softwood         <chr> \"Softwood\", \"Softwood\", \"Softwood\", \"Softwoo… #> $ comp_trees_per_ha         <dbl> 495.0296, 742.5445, 742.5445, 990.0593, 742.… #> $ comp_relative_tree_height <dbl> 0.9099468, 1.0000000, 0.5804963, 1.0000000, … #> $ comp_dist_to_nearest_m    <dbl> 3.010399, 2.549510, 1.677051, 1.414214, 3.60… #> $ max_crown_diam_height_m   <dbl> 10.644080, 10.660000, 6.370394, 10.096082, 1… #> $ is_training_hmd           <lgl> FALSE, TRUE, FALSE, FALSE, TRUE, FALSE, FALS… #> $ landfire_stand_id         <dbl> 49, 50, 50, 50, 51, 51, 51, 49, 50, 50, 51, … #> $ crown_dia_m               <dbl> 3.6345371, 3.7103777, 1.2296227, 2.4102190, … #> $ crown_length_m            <dbl> 6.7299995, 7.3500004, 3.0478671, 1.7191996, … #> $ crown_volume_m3           <dbl> 46.5491635, 52.9812527, 2.4128948, 5.2292321… #> $ landfire_tree_kg_per_m3   <dbl> 0.2167401, 0.1645076, 0.1645076, 0.1645076, … #> $ landfire_stand_kg_per_m3  <dbl> 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.… #> $ landfire_crown_biomass_kg <dbl> 10.08907036, 8.71581875, 0.39693953, 0.86024… paste(   \"Default trees extracted:\"   , cloud2trees_ans$crowns_sf %>% nrow()   , \"|| Custom trees extracted:\"   , cloud2trees_ans_c$crowns_sf %>% nrow() ) #> [1] \"Default trees extracted: 340 || Custom trees extracted: 343\" cloud2trees_ans_c$crowns_sf %>%   ggplot2::ggplot(mapping = ggplot2::aes(x = tree_height_m, y = dbh_cm)) +    ggplot2::geom_point(color = \"navy\", alpha = 0.6) +   ggplot2::labs(x = \"tree ht. (m)\", y = \"tree DBH (cm)\") +   ggplot2::scale_x_continuous(limits = c(0,NA)) +   ggplot2::scale_y_continuous(limits = c(0,NA)) +   ggplot2::theme_light() cloud2trees_ans_c$crowns_sf %>%   dplyr::arrange(is_training_cbh) %>%   ggplot2::ggplot(mapping = ggplot2::aes(x = tree_height_m, y = tree_cbh_m, color=is_training_cbh)) +    ggplot2::geom_point() +   ggplot2::labs(x = \"tree ht. (m)\", y = \"tree CBH (m)\") +   ggplot2::scale_y_continuous(breaks = scales::extended_breaks(n=12)) +   ggplot2::scale_x_continuous(breaks = scales::extended_breaks(n=14)) +   ggplot2::scale_color_viridis_d(alpha = 0.8, name = \"is CBH\\nfrom cloud?\") +   ggplot2::theme_light() library(patchwork) # height plot plt_ht <-   cloud2trees_ans_c$crowns_sf %>%    ggplot2::ggplot(mapping = ggplot2::aes(fill = tree_height_m)) +    ggplot2::geom_sf() +    ggplot2::scale_fill_distiller(palette = \"Oranges\", name = \"tree ht. (m)\", direction = 1) +   ggplot2::theme_void() +   ggplot2::theme(legend.position = \"top\", legend.direction = \"horizontal\") # diameter plot plt_dbh <-   cloud2trees_ans_c$crowns_sf %>%    ggplot2::ggplot(mapping = ggplot2::aes(fill = dbh_cm)) +    ggplot2::geom_sf() +    ggplot2::scale_fill_distiller(palette = \"Purples\", name = \"tree DBH (cm)\", direction = 1) +   ggplot2::theme_void() +   ggplot2::theme(legend.position = \"top\", legend.direction = \"horizontal\") # CBH plot plt_cbh <-   cloud2trees_ans_c$crowns_sf %>%    ggplot2::ggplot(mapping = ggplot2::aes(fill = tree_cbh_m)) +    ggplot2::geom_sf() +    ggplot2::scale_fill_distiller(palette = \"Greens\", name = \"tree CBH (m)\", direction = 1) +   ggplot2::theme_void() +   ggplot2::theme(legend.position = \"top\", legend.direction = \"horizontal\") # combine with patchwork plt_ht + plt_dbh + plt_cbh + patchwork::plot_layout(ncol = 2) &   ggplot2::theme(     legend.title = ggplot2::element_text(size = 8)     , legend.text = ggplot2::element_text(size = 7)   ) cloud2trees_ans_c$treetops_sf %>%   ggplot2::ggplot(mapping = ggplot2::aes(color = comp_dist_to_nearest_m)) +    ggplot2::geom_sf() +   ggplot2::scale_color_distiller(palette = \"Greys\", name = \"distance to\\nnearest tree\", direction = 1) +   ggplot2::theme_void() +   ggplot2::theme(legend.position = \"top\", legend.direction = \"horizontal\") cloud2trees_ans_c$treetops_sf %>%   sf::st_drop_geometry() %>%    dplyr::count(forest_type_group_code, forest_type_group) #> # A tibble: 1 × 3 #>   forest_type_group_code forest_type_group        n #>   <chr>                  <chr>                <int> #> 1 220                    Ponderosa pine group   343"},{"path":"https://georgewoolsey.github.io/cloud2trees/index.html","id":"cloud2trees-outputs","dir":"","previous_headings":"","what":"cloud2trees() outputs","title":"Aerial point cloud data to forest inventory tree lists","text":"cloud2trees() process generates list outputs written disk delivery directory titled point_cloud_processing_delivery output_dir argument defined user function call. astute reader noticed saved outputs temporary directory (my_dir) directory local machine (e.g. “C:”). Let’s check files delivered point_cloud_processing_delivery folder. description files:","code":"# append the \"point_cloud_processing_delivery\"  to our output_dir cloud2trees_delivery_dir <- file.path(my_dir,\"point_cloud_processing_delivery\") # which files? list.files( cloud2trees_delivery_dir ) #>  [1] \"cbh_height_model_estimates.rds\"              #>  [2] \"chm_0.25m.tif\"                               #>  [3] \"dtm_0.5m.tif\"                                #>  [4] \"fia_foresttype_raster.tif\"                   #>  [5] \"final_detected_crowns.gpkg\"                  #>  [6] \"final_detected_tree_tops.gpkg\"               #>  [7] \"hmd_height_model_estimates.rds\"              #>  [8] \"norm_las\"                                    #>  [9] \"processed_tracking_data.csv\"                 #> [10] \"raw_las_ctg_info.gpkg\"                       #> [11] \"regional_dbh_height_model.rds\"               #> [12] \"regional_dbh_height_model_estimates.csv\"     #> [13] \"regional_dbh_height_model_predictions.csv\"   #> [14] \"regional_dbh_height_model_training_data.csv\" #> [15] \"stand_cell_data_landfire.csv\""},{"path":"https://georgewoolsey.github.io/cloud2trees/index.html","id":"format-cloud2trees-output-for-lanl-trees","dir":"","previous_headings":"","what":"Format cloud2trees() output for LANL TREES","title":"Aerial point cloud data to forest inventory tree lists","text":"developed cloud2trees_to_lanl_trees() function use output cloud2trees() generate inputs LANL TREES program pathway fire modeling Quic-Fire want use cloud2trees() framework generate required fire modeling input variables, minimum required settings : primary input cloud2trees_to_lanl_trees() directory outputs cloud2trees(). reminder, default directory written cloud2trees() point_cloud_processing_delivery. Also required spatial file defining boundary area interest. ’ll pretend area interest central 2,000 m2 point cloud data Now, ’ll call function tell cloud2trees() outputs located study area . ’ll also tell just write inputs LANL TREES program directory program automatically create new folder titled lanl_trees_delivery Let’s check files delivered lanl_trees_delivery folder. description files:","code":"cloud2trees::cloud2trees(   ...   , estimate_tree_dbh = TRUE   , estimate_tree_type = TRUE   , estimate_tree_cbh = TRUE   , cbh_estimate_missing_cbh = TRUE   , estimate_tree_hmd = TRUE   , hmd_estimate_missing_hmd = TRUE   , estimate_biomass_method = \"landfire\" # or \"cruz\" or both c(\"landfire\",\"cruz\") ) my_aoi <-   cloud2trees_ans_c$treetops_sf %>%      sf::st_union() %>%      sf::st_centroid() %>%      sf::st_buffer(sqrt(2000)/2, endCapStyle = \"SQUARE\") # what is this? my_aoi %>% dplyr::glimpse() #> sfc_POLYGON of length 1; first list element: List of 1 #>  $ : num [1:5, 1:2] 481328 481328 481283 481283 481328 ... #>  - attr(*, \"class\")= chr [1:3] \"XY\" \"POLYGON\" \"sfg\" # run it with no customization cloud2trees_to_lanl_trees(   input_dir = cloud2trees_delivery_dir   , study_boundary = my_aoi   , output_dir = cloud2trees_delivery_dir ) # append the \"lanl_trees_delivery\" to our cloud2trees_delivery_dir lanl_trees_delivery_dir <- file.path(cloud2trees_delivery_dir,\"lanl_trees_delivery\") # which files? list.files( lanl_trees_delivery_dir ) #> [1] \"Cloud2Trees_TreeList.txt\" \"dtm_Clipped.tif\"          #> [3] \"fuellist\"                 \"Lidar_Bounds.geojson\"     #> [5] \"topo.dat\""},{"path":"https://georgewoolsey.github.io/cloud2trees/index.html","id":"define-surface-fuel","dir":"","previous_headings":"","what":"Define surface fuel","title":"Aerial point cloud data to forest inventory tree lists","text":"current iteration cloud2trees_to_lanl_trees() requires user specify surface fuel load parameters, litter herbaceous/grass fuel loads, assumed constant across study area. Surface fuel loading parameters determined literature review expert opinion. fuel_litter argument cloud2trees_to_lanl_trees() function allows users define litter fuel load parameters order: ilitter : 0 = litter, 1 = litter lrho : litter bulk density (kg/m3) lmoisture: litter moisture (percent 0-1 scale) lss : litter sizescale (m) ldepth : litter depth (m) fuel_grass argument cloud2trees_to_lanl_trees() function allows users define grass/herbaceous fuel load parameters order: igrass : 0 = grass, 1 = grass grho : grass bulk density (kg/m3) gmoisture : grass moisture (percent 0-1 scale) gss : grass sizescale (m) gdepth : grass depth (m) customizing fuel loads look like cloud2trees_to_lanl_trees() call","code":"# fuel_litter my_fuel_litter <- list(   ilitter = 1   , lrho = 13.44   , lmoisture = 0.09   , lss = 0.00041   , ldepth = 0.032 ) # fuel_grass my_fuel_grass <- list(   igrass = 1   , grho = 0.0065   , gmoisture = 0.3   , gss = 0.00033   , gdepth = 0.15 ) # run it with all customization cloud2trees_to_lanl_trees(   input_dir = cloud2trees_delivery_dir   , study_boundary = my_aoi   , output_dir = cloud2trees_delivery_dir   , topofile = \"flat\"   , fuel_litter = my_fuel_litter   , fuel_grass = my_fuel_grass )"},{"path":"https://georgewoolsey.github.io/cloud2trees/index.html","id":"extract-raster-data-from-point-cloud","dir":"","previous_headings":"","what":"Extract Raster Data from Point Cloud","title":"Aerial point cloud data to forest inventory tree lists","text":"can use cloud2raster() function want create DTM CHM point cloud data. function also creates classified height normalized point cloud process. wish keep point clouds, ensure turn keep_intrmdt parameter see point_cloud_processing_temp directory nested output_dir. digital terrain model (DTM) raster can plot using terra::plot()  canopy height model (CHM) raster can plot using terra::plot()","code":"cloud2raster_ans <- cloud2trees::cloud2raster(output_dir = tempdir(), input_las_dir = i) # there's a DTM cloud2raster_ans$dtm_rast %>% terra::plot() # there's a CHM cloud2raster_ans$chm_rast %>% terra::plot()"},{"path":"https://georgewoolsey.github.io/cloud2trees/index.html","id":"extract-trees-from-raster-data","dir":"","previous_headings":"","what":"Extract Trees from Raster Data","title":"Aerial point cloud data to forest inventory tree lists","text":"can use raster2trees() function already CHM raster want extract tree list. ’ll use CHM example ships cloud2trees package. spatial data frame tree crown polygons returned. Let’s plot tree crown polygons using ggplot2::ggplot() custom plot settings.","code":"# read example CHM raster f <- paste0(system.file(package = \"cloud2trees\"),\"/extdata/chm.tif\") r <- terra::rast(f) # extract trees from raster raster2trees_ans <- cloud2trees::raster2trees(chm_rast = r, outfolder = tempdir()) # there are tree crowns raster2trees_ans %>% dplyr::glimpse() #> Rows: 147 #> Columns: 6 #> $ treeID        <chr> \"1_458054.1_4450092.9\", \"2_458055.9_4450092.9\", \"3_45807… #> $ tree_height_m <dbl> 4.599, 5.130, 4.610, 8.957, 10.310, 3.023, 4.271, 5.653,… #> $ tree_x        <dbl> 458054.1, 458055.9, 458078.4, 458067.6, 458044.9, 458077… #> $ tree_y        <dbl> 4450093, 4450093, 4450093, 4450092, 4450092, 4450092, 44… #> $ crown_area_m2 <dbl> 0.5625, 0.3750, 0.6250, 3.2500, 5.0000, 0.3750, 0.9375, … #> $ geometry      <GEOMETRY [m]> POLYGON ((458054 4450093, 4..., POLYGON ((45805… raster2trees_ans %>%    ggplot2::ggplot(mapping = ggplot2::aes(fill = tree_height_m)) +    ggplot2::geom_sf() +    ggplot2::scale_fill_distiller(palette = \"Oranges\", name = \"tree ht. (m)\", direction = 1) +   ggplot2::theme_void() +   ggplot2::theme(legend.position = \"top\", legend.direction = \"horizontal\")"},{"path":"https://georgewoolsey.github.io/cloud2trees/index.html","id":"estimate-tree-dbh-for-a-tree-list","dir":"","previous_headings":"","what":"Estimate Tree DBH for a Tree List","title":"Aerial point cloud data to forest inventory tree lists","text":"already list trees tree coordinate tree height data, can estimate tree DBH using site-specific allometric equation based FIA data trees_dbh() function. just need pass data frame columns treeID, tree_x, tree_y, tree_height_m trees_dbh() function. Use trees_dbh() function estimate DBH based tree height tree location. data? Let’s look relationship tree height tree DBH estimated FIA plot data.  can look data spatially .","code":"set.seed(111) # a fake tree list tl <- dplyr::tibble(     treeID = c(1:21)     , tree_x = rnorm(n=21, mean = 458064, sd = 11)     , tree_y = rnorm(n=21, mean = 4450074, sd = 11)     , tree_height_m = exp(rgamma(n = 21, shape = (7/4)^2, rate = (4^2)/7))   ) # call the function tl_dbh <- cloud2trees::trees_dbh(tree_list = tl, crs = \"32613\") tl_dbh %>% dplyr::glimpse() #> Rows: 21 #> Columns: 16 #> $ treeID                 <chr> \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"1… #> $ tree_x                 <dbl> 458066.6, 458060.4, 458060.6, 458038.7, 458062.… #> $ tree_y                 <dbl> 4450078, 4450076, 4450072, 4450078, 4450081, 44… #> $ tree_height_m          <dbl> 1.447969, 4.970239, 3.549897, 7.216735, 3.54328… #> $ geometry               <POINT [m]> POINT (458066.6 4450078), POINT (458060.4… #> $ fia_est_dbh_cm         <dbl> 3.229841, 8.447579, 6.094372, 12.563307, 6.0943… #> $ fia_est_dbh_cm_lower   <dbl> 1.939234, 5.030607, 3.647726, 7.505863, 3.64772… #> $ fia_est_dbh_cm_upper   <dbl> 4.805320, 12.666605, 9.087239, 18.769135, 9.087… #> $ dbh_cm                 <dbl> 3.229841, 8.447579, 6.094372, 12.563307, 6.0943… #> $ is_training_data       <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE… #> $ dbh_m                  <dbl> 0.03229841, 0.08447579, 0.06094372, 0.12563307,… #> $ radius_m               <dbl> 0.01614921, 0.04223790, 0.03047186, 0.06281654,… #> $ basal_area_m2          <dbl> 0.0008193176, 0.0056047266, 0.0029170762, 0.012… #> $ basal_area_ft2         <dbl> 0.008819135, 0.060329277, 0.031399409, 0.133435… #> $ ptcld_extracted_dbh_cm <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… #> $ ptcld_predicted_dbh_cm <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… tl_dbh %>%   ggplot2::ggplot(mapping = ggplot2::aes(x = tree_height_m, y = dbh_cm)) +    ggplot2::geom_point(color = \"navy\", alpha = 0.6) +   ggplot2::labs(x = \"tree ht. (m)\", y = \"tree DBH (cm)\") +   ggplot2::scale_x_continuous(limits = c(0,NA)) +   ggplot2::scale_y_continuous(limits = c(0,NA)) +   ggplot2::theme_light() # height plot plt_ht2 <-   tl_dbh %>%    ggplot2::ggplot(mapping = ggplot2::aes(color = tree_height_m)) +    ggplot2::geom_sf(size = 3) +    ggplot2::scale_color_distiller(palette = \"Oranges\", name = \"tree ht. (m)\", direction = 1) +   ggplot2::theme_void() +   ggplot2::theme(     legend.position = \"top\", legend.direction = \"horizontal\"     , panel.border = ggplot2::element_rect(color = \"black\", fill = NA)   ) # diameter plot plt_dbh2 <-   tl_dbh %>%    ggplot2::ggplot(mapping = ggplot2::aes(color = dbh_cm)) +    ggplot2::geom_sf(size = 3) +    ggplot2::scale_color_distiller(palette = \"Purples\", name = \"tree DBH (cm)\", direction = 1) +   ggplot2::theme_void() +   ggplot2::theme(     legend.position = \"top\", legend.direction = \"horizontal\"     , panel.border = ggplot2::element_rect(color = \"black\", fill = NA)   ) # combine with patchwork plt_ht2 + plt_dbh2"},{"path":"https://georgewoolsey.github.io/cloud2trees/index.html","id":"estimate-tree-forest-type-for-a-tree-list","dir":"","previous_headings":"","what":"Estimate Tree Forest Type for a Tree List","title":"Aerial point cloud data to forest inventory tree lists","text":"already list trees tree coordinate, can use trees_type() function attach tree forest type based spatial overlap Forest Type Groups Continental United States data (Wilson 2023). forest type group layer developed using data 213,000 national forest inventory plots measured period 2014-2018 FIA program 30-meter resolution covering forested extent continental US. just need pass data frame columns treeID, tree_x, tree_y trees_type() function. can also use sf class object POINT POLYGON geometry (see sf::st_geometry_type()) program use data “-” require treeID column. Use trees_type() function extract FIA forest type group based tree location. tree overlaps area classified “non-forest”, program search nearest forest type impute value; ’ll limit search radius setting max_search_dist_m parameter 88 meters. return includes tree list forest type data (tree_list) well FIA Forest Types Group raster (foresttype_rast) area searched. tree list data? Let’s look FIA Forest Type Group data extracted tree list. can plot spatial tree list  Let’s check FIA Forest Types Group raster (foresttype_rast) area searched  See Forest Type Groups Continental United States data (Wilson 2023) list possible forest type group codes Let’s overlay tree points raster data","code":"# a fake tree list tl <- dplyr::tibble(     treeID = c(1:66)     , tree_x = rnorm(n=66, mean = 458000, sd = 75)     , tree_y = rnorm(n=66, mean = 4450000, sd = 75)   ) # call the function tl_type <- cloud2trees::trees_type(tree_list = tl, crs = \"32613\", max_search_dist_m = 88) tl_type %>% names() #> [1] \"tree_list\"       \"foresttype_rast\" tl_type$tree_list %>% dplyr::glimpse() #> Rows: 66 #> Columns: 7 #> $ treeID                 <chr> \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"1… #> $ tree_x                 <dbl> 457980.9, 457941.7, 457902.6, 457927.3, 457916.… #> $ tree_y                 <dbl> 4449951, 4450079, 4449905, 4449872, 4450004, 44… #> $ geometry               <POINT [m]> POINT (457980.9 4449951), POINT (457941.7… #> $ forest_type_group_code <chr> \"200\", \"200\", \"200\", \"220\", \"200\", \"200\", \"260\"… #> $ forest_type_group      <chr> \"Douglas-fir group\", \"Douglas-fir group\", \"Doug… #> $ hardwood_softwood      <chr> \"Softwood\", \"Softwood\", \"Softwood\", \"Softwood\",… tl_type$tree_list %>%   sf::st_drop_geometry() %>%    dplyr::count(forest_type_group_code, forest_type_group) #> # A tibble: 4 × 3 #>   forest_type_group_code forest_type_group                         n #>   <chr>                  <chr>                                 <int> #> 1 200                    Douglas-fir group                        39 #> 2 220                    Ponderosa pine group                      4 #> 3 260                    Fir / spruce / mountain hemlock group     4 #> 4 280                    Lodgepole pine group                     19 # now plot tl_type$tree_list %>%   ggplot2::ggplot() +    ggplot2::geom_sf(ggplot2::aes(color=forest_type_group), size = 3) +   ggplot2::labs(color = \"FIA forest\\ntype group\") +   ggplot2::scale_color_brewer(palette = \"Dark2\") +   ggplot2::theme_void() +   ggplot2::theme(panel.border = ggplot2::element_rect(color = \"black\", fill = NA)) r_plt <-    tl_type$foresttype_rast %>%     as.data.frame(xy=T) %>%      dplyr::rename(f = 3) %>%      dplyr::mutate(f = as.factor(f)) %>%      ggplot2::ggplot() +      ggplot2::geom_tile(mapping = ggplot2::aes(x=x, y=y, fill = f)) +     ggplot2::labs(fill = \"FIA forest type\\ngroup code\") +     ggplot2::scale_fill_viridis_d(option = \"turbo\", alpha = 0.9) +     ggplot2::theme_void() r_plt r_plt +   ggplot2::geom_sf(     data = tl_type$tree_list %>%         # we have to reproject       sf::st_transform(         crs = tl_type$foresttype_rast %>%           terra::crs(describe=T) %>%           dplyr::pull(code) %>%           as.numeric() %>%           sf::st_crs()       )     , mapping = ggplot2::aes(shape = forest_type_group)     , color = \"white\"     , size = 2   ) +   ggplot2::labs(shape = \"FIA forest\\ntype group\") +   ggplot2::guides(shape = ggplot2::guide_legend(override.aes = list(size = 3, color = \"black\")))"},{"path":"https://georgewoolsey.github.io/cloud2trees/index.html","id":"estimate-tree-cbh-for-a-tree-list","dir":"","previous_headings":"","what":"Estimate Tree CBH for a Tree List","title":"Aerial point cloud data to forest inventory tree lists","text":"wish estimate crown base height (CBH) part point cloud processing LadderFuelsR package (https://github.com/olgaviedma/LadderFuelsR) leafR package (https://github.com/DRAAlmeida/leafR) must manually installed first. installing packages, already spatial polygons tree crowns height normalized point cloud data, can attempt extract tree CBH point cloud using trees_cbh() function. just need pass sf class object POLYGON geometry columns treeID tree_height_m height normalized point cloud data trees_cbh() function. ’ll use tree crown polygons normalized point cloud data examples ship cloud2trees package. turn force_same_crs parameter force projection point cloud polygon since confident data generated projection. Data generated cloud2trees pipeline (e.g. cloud2raster()) always projection. data? Let’s look relationship tree height tree CBH extracted point cloud. Note, expect perfect linear relationship tree height CBH throughout entire height range CBH also determined spatially (e.g. fire moves stand).  can look data spatially .","code":"# install.packages(\"remotes\") ## install LadderFuelsR remotes::install_github(repo = \"olgaviedma/LadderFuelsR\", upgrade = F) ## install leafR remotes::install_github(repo = \"DRAAlmeida/leafR\", upgrade = F) # read example crown polygons f <- system.file(package = \"cloud2trees\",\"extdata\", \"crowns_poly.gpkg\") p <- sf::st_read(f, quiet = T) # path to the normalized point cloud data nlas <- system.file(package = \"cloud2trees\",\"extdata\",\"norm_las\") # call the function trees_cbh_ans <- cloud2trees::trees_cbh(   trees_poly = p   , norm_las = nlas   , tree_sample_prop = 0.77   , estimate_missing_cbh = TRUE ) trees_cbh_ans %>%    dplyr::select(treeID, tree_height_m, tree_cbh_m, is_training_cbh) %>%    dplyr::glimpse() #> Rows: 196 #> Columns: 5 #> $ treeID          <chr> \"1_458054.1_4450092.9\", \"2_458055.9_4450092.9\", \"3_458… #> $ tree_height_m   <dbl> 4.599, 5.130, 10.641, 4.610, 4.599, 8.957, 10.310, 4.6… #> $ tree_cbh_m      <dbl> 4.102961, 4.500000, 8.500000, 2.500000, 4.500000, 4.76… #> $ is_training_cbh <lgl> FALSE, TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, FALSE, FAL… #> $ geom            <MULTIPOLYGON [m]> MULTIPOLYGON (((458054 4450..., MULTIPOLY… trees_cbh_ans %>%   dplyr::arrange(is_training_cbh) %>%   ggplot2::ggplot(mapping = ggplot2::aes(x = tree_height_m, y = tree_cbh_m, color=is_training_cbh)) +    ggplot2::geom_point() +   ggplot2::labs(x = \"tree ht. (m)\", y = \"tree CBH (m)\") +   ggplot2::scale_y_continuous(breaks = scales::extended_breaks(n=12)) +   ggplot2::scale_x_continuous(breaks = scales::extended_breaks(n=14)) +   ggplot2::scale_color_viridis_d(alpha = 0.8, name = \"is CBH\\nfrom cloud?\") +   ggplot2::theme_light() trees_cbh_ans %>%   dplyr::arrange(is_training_cbh) %>%   ggplot2::ggplot(mapping = ggplot2::aes(fill = tree_cbh_m, color=is_training_cbh)) +    ggplot2::geom_sf() +   ggplot2::scale_color_viridis_d(alpha = 0.8, name = \"is CBH\\nfrom cloud?\") +   ggplot2::scale_fill_distiller(palette = \"Greens\", name = \"tree CBH (m)\", direction = 1) +   ggplot2::theme_void() +   ggplot2::theme(     legend.position = \"top\", legend.direction = \"horizontal\"     , panel.border = ggplot2::element_rect(color = \"black\", fill = NA)   ) +   ggplot2::guides(     color = ggplot2::guide_legend(override.aes = list(lwd = 3, fill = NA))   )"},{"path":"https://georgewoolsey.github.io/cloud2trees/index.html","id":"estimate-tree-hmd-for-a-tree-list","dir":"","previous_headings":"","what":"Estimate Tree HMD for a Tree List","title":"Aerial point cloud data to forest inventory tree lists","text":"wish extract height maximum crown diameter (HMD) using height normalized point cloud data (e.g. exported cloud2raster()) trees_hmd() function estimate_tree_hmd cloud2trees() function may relevant interests. just need pass sf class object POLYGON geometry columns treeID tree_height_m height normalized point cloud data trees_hmd() function. function returns data added columns: max_crown_diam_height_m, is_training_hmd. ’ll use tree crown polygons normalized point cloud data examples ship cloud2trees package. data? Let’s look relationship tree height tree HMD extracted point cloud. Note, expect perfect linear relationship tree height HMD throughout entire height range HMD also determined spatially (e.g. fire moves stand).  can look data spatially .","code":"# read example crown polygons f <- system.file(package = \"cloud2trees\",\"extdata\", \"crowns_poly.gpkg\") p <- sf::st_read(f, quiet = T) # path to the normalized point cloud data nlas <- paste0(system.file(package = \"cloud2trees\"),\"/extdata/norm_las\") # call the function trees_hmd_ans <- cloud2trees::trees_hmd(   trees_poly = p   , norm_las = nlas   , estimate_missing_hmd = TRUE ) trees_hmd_ans %>%    dplyr::select(treeID, tree_height_m, max_crown_diam_height_m, is_training_hmd) %>%    dplyr::glimpse() #> Rows: 196 #> Columns: 5 #> $ treeID                  <chr> \"1_458054.1_4450092.9\", \"2_458055.9_4450092.9\"… #> $ tree_height_m           <dbl> 4.599, 5.130, 10.641, 4.610, 4.599, 8.957, 10.… #> $ max_crown_diam_height_m <dbl> 3.531745, 4.681000, 8.943000, 3.151000, 3.2190… #> $ is_training_hmd         <lgl> FALSE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRU… #> $ geom                    <MULTIPOLYGON [m]> MULTIPOLYGON (((458054 4450..., M… trees_hmd_ans %>%   dplyr::arrange(is_training_cbh) %>%   ggplot2::ggplot(     mapping = ggplot2::aes(x = tree_height_m, y = max_crown_diam_height_m, color=is_training_hmd)   ) +    ggplot2::geom_point() +   ggplot2::labs(x = \"tree ht. (m)\", y = \"tree HMD (m)\") +   ggplot2::scale_y_continuous(breaks = scales::extended_breaks(n=12)) +   ggplot2::scale_x_continuous(breaks = scales::extended_breaks(n=14)) +   ggplot2::scale_color_viridis_d(option = \"turbo\", begin = 0.2, alpha = 0.8, name = \"is HMD\\nfrom cloud?\") +   ggplot2::theme_light() trees_hmd_ans %>%   dplyr::arrange(is_training_hmd) %>%   ggplot2::ggplot(mapping = ggplot2::aes(fill = max_crown_diam_height_m, color=is_training_hmd)) +    ggplot2::geom_sf() +   ggplot2::scale_color_viridis_d(option = \"turbo\", begin = 0.2, alpha = 0.8, name = \"is HMD\\nfrom cloud?\") +   ggplot2::scale_fill_distiller(palette = \"Greys\", name = \"tree HMD (m)\", direction = 1) +   ggplot2::theme_void() +   ggplot2::theme(     legend.position = \"top\", legend.direction = \"horizontal\"     , panel.border = ggplot2::element_rect(color = \"black\", fill = NA)   ) +   ggplot2::guides(     color = ggplot2::guide_legend(override.aes = list(lwd = 3, fill = NA))   )"},{"path":"https://georgewoolsey.github.io/cloud2trees/index.html","id":"estimate-tree-biomass-for-a-tree-list","dir":"","previous_headings":"","what":"Estimate Tree Biomass for a Tree List","title":"Aerial point cloud data to forest inventory tree lists","text":"cloud2trees() package includes methods estimating individual tree biomass kilograms, component biomass tree crown kilograms. Currently supported methods estimating biomass include: “landfire” - based LANDFIRE’s Forest Canopy Bulk Density (CBD) data (trees_biomass_landfire()) “cruz” - based Cruz et al. (2003) canopy fuel stratum equations (trees_biomass_cruz()) trees_biomass() function streamlines process estimating individual tree biomass kilograms, component biomass tree crown kilograms. Users can select one, , methods available package estimating biomass. just need pass data frame columns treeID, tree_x, tree_y trees_biomass*() function. can also use sf class object POINT POLYGON geometry (see sf::st_geometry_type()) program use data “-” require treeID column. Since estimating tree crown biomass using stand-based fuel estimates requires back-transformation tree level, trees_biomass_landfire(), trees_biomass_cruz(), trees_biomass() using Cruz LANDFIRE methods also require following data attributes: crown_area_m2, tree_height_m (e.g. exported raster2trees()) tree_cbh_m (e.g. exported trees_cbh()) one dbh_cm, dbh_m, basal_area_m2 (e.g. exported trees_dbh()) ’ll use tree crown polygons ship cloud2trees package.","code":"# read example crown polygons f <- system.file(package = \"cloud2trees\",\"extdata\", \"crowns_poly.gpkg\") tl <- sf::st_read(f, quiet = T)"},{"path":"https://georgewoolsey.github.io/cloud2trees/index.html","id":"trees_biomass","dir":"","previous_headings":"","what":"trees_biomass()","title":"Aerial point cloud data to forest inventory tree lists","text":"trees_biomass() function streamlines process estimating individual tree biomass kilograms, component biomass tree crown kilograms. Users can select one, , methods available package estimating biomass. following function calls equivalent: ’ll use trees_biomass() function ask LANDFIRE Cruz et al. (2003) estimates tree crown biomass kilograms argument method = c(\"landfire\",\"cruz\") get back? check tree list data ’s lot extra information…cruz_crown_biomass_kg landfire_crown_biomass_kg columns include estimates tree crown biomass kilograms plot tree LANDFIRE Cruz crown biomass estimate  estimates look similar exactly . let’s plot  let’s check LANDFIRE stand data data includes cell data (, “stand” represented raster cell) LANDFIRE Forest Canopy Bulk Density (CBD) data can use stand/cell data raster data overlay tree points…let’s LANDFIRE data","code":"# trees_biomass with method = \"landfire\" trees_biomass(tree_list, method = \"landfire\") # is equivalent to trees_biomass_landfire(tree_list) # call trees_biomass and get multiple biomass estimates trees_biomass_ans <- trees_biomass(tree_list = tl, method = c(\"landfire\",\"cruz\")) trees_biomass_ans %>% names() #> [1] \"tree_list\"                \"stand_cell_data_landfire\" #> [3] \"stand_cell_data_cruz\" trees_biomass_ans$tree_list %>% dplyr::glimpse() #> Rows: 196 #> Columns: 36 #> $ treeID                    <chr> \"1_458054.1_4450092.9\", \"2_458055.9_4450092.… #> $ tree_height_m             <dbl> 4.599, 5.130, 10.641, 4.610, 4.599, 8.957, 1… #> $ tree_x                    <dbl> 458054.1, 458055.9, 458064.9, 458078.4, 4580… #> $ tree_y                    <dbl> 4450093, 4450093, 4450093, 4450093, 4450092,… #> $ crown_area_m2             <dbl> 0.1875, 0.3750, 1.8750, 0.7500, 0.3750, 3.37… #> $ fia_est_dbh_cm            <dbl> 7.319132, 8.019020, 19.016688, 7.319132, 7.3… #> $ fia_est_dbh_cm_lower      <dbl> 3.255010, 3.515282, 8.424208, 3.255010, 3.25… #> $ fia_est_dbh_cm_upper      <dbl> 12.58250, 13.93920, 32.91103, 12.58250, 12.5… #> $ dbh_cm                    <dbl> 7.319132, 8.019020, 19.016688, 7.319132, 7.3… #> $ is_training_data          <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA… #> $ dbh_m                     <dbl> 0.07319132, 0.08019020, 0.19016688, 0.073191… #> $ radius_m                  <dbl> 0.03659566, 0.04009510, 0.09508344, 0.036595… #> $ basal_area_m2             <dbl> 0.004207353, 0.005050479, 0.028402703, 0.004… #> $ basal_area_ft2            <dbl> 0.04528795, 0.05436335, 0.30572669, 0.045287… #> $ ptcld_extracted_dbh_cm    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ ptcld_predicted_dbh_cm    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ tree_cbh_m                <dbl> 2.770816, 2.750028, 1.500000, 1.500000, 2.77… #> $ is_training_cbh           <lgl> FALSE, FALSE, TRUE, TRUE, FALSE, TRUE, TRUE,… #> $ comp_trees_per_ha         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ comp_relative_tree_height <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ comp_dist_to_nearest_m    <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … #> $ forest_type_group_code    <chr> \"200\", \"200\", \"200\", \"200\", \"200\", \"200\", \"2… #> $ forest_type_group         <chr> \"Douglas-fir group\", \"Douglas-fir group\", \"D… #> $ hardwood_softwood         <chr> \"Softwood\", \"Softwood\", \"Softwood\", \"Softwoo… #> $ cruz_stand_id             <dbl> 32, 32, 32, 33, 32, 32, 31, 33, 32, 31, 31, … #> $ cruz_tree_kg_per_m3       <dbl> 1.0196573, 1.0196573, 1.0196573, 1.8371350, … #> $ cruz_stand_kg_per_m3      <dbl> 0.017647375, 0.017647375, 0.017647375, 0.003… #> $ cruz_crown_biomass_kg     <dbl> 0.2330152, 0.6066891, 11.6508594, 2.8567451,… #> $ landfire_stand_id         <dbl> 41, 41, 41, 42, 41, 42, 41, 42, 42, 41, 41, … #> $ crown_dia_m               <dbl> 0.4886025, 0.6909883, 1.5450968, 0.9772050, … #> $ crown_length_m            <dbl> 1.8281841, 2.3799726, 9.1409998, 3.1100001, … #> $ crown_volume_m3           <dbl> 0.2285230, 0.5949931, 11.4262497, 1.5550001,… #> $ landfire_tree_kg_per_m3   <dbl> 0.5285632, 0.5285632, 0.5285632, 1.1615116, … #> $ landfire_stand_kg_per_m3  <dbl> 0.11, 0.11, 0.11, 0.08, 0.11, 0.08, 0.11, 0.… #> $ landfire_crown_biomass_kg <dbl> 0.1207889, 0.3144915, 6.0394953, 1.8061507, … #> $ geometry                  <POINT [m]> POINT (458054.1 4450093), POINT (45805… library(patchwork) # plot tree landfire crown biomass estimate p1 <- trees_biomass_ans$tree_list %>%   ggplot2::ggplot(     mapping = ggplot2::aes(       x = tree_height_m       , y = landfire_crown_biomass_kg       , color = crown_area_m2     )   ) +   ggplot2::geom_point() # plot tree cruz crown biomass estimate p2 <- trees_biomass_ans$tree_list %>%   ggplot2::ggplot(     mapping = ggplot2::aes(       x = tree_height_m       , y = cruz_crown_biomass_kg       , color = crown_area_m2     )   ) +   ggplot2::geom_point() # patchwork it p1/p2 # get the max for the upper limit scale ul <- max(   trees_biomass_ans$tree_list$cruz_crown_biomass_kg   , trees_biomass_ans$tree_list$landfire_crown_biomass_kg ) # plot tree landfire vs. cruz crown biomass estimate trees_biomass_ans$tree_list %>%   ggplot2::ggplot(     mapping = ggplot2::aes(       x = landfire_crown_biomass_kg, y = cruz_crown_biomass_kg     )   ) +   ggplot2::geom_abline(lwd = 1.5) +   ggplot2::geom_smooth(method = \"lm\", se=F, color = \"gray\", linetype = \"dashed\") +   ggplot2::geom_point(ggplot2::aes(color = tree_height_m)) +   ggplot2::scale_x_continuous(limits = c(0, ul)) +   ggplot2::scale_y_continuous(limits = c(0, ul)) trees_biomass_ans$stand_cell_data_landfire %>% dplyr::filter(trees>0) %>% dplyr::glimpse() #> Rows: 4 #> Columns: 19 #> $ landfire_stand_id        <dbl> 41, 42, 50, 51 #> $ x                        <dbl> -799740, -799710, -799740, -799710 #> $ y                        <dbl> 1949370, 1949370, 1949340, 1949340 #> $ area                     <dbl> 900, 900, 900, 900 #> $ pct_overlap              <dbl> 1.0000000, 0.9901794, 0.9117767, 0.8549631 #> $ overlap_area_m2          <dbl> 900.0000, 891.1614, 820.5990, 769.4668 #> $ overlap_area_ha          <dbl> 0.09000000, 0.08911614, 0.08205990, 0.07694668 #> $ rast_epsg_code           <chr> \"5070\", \"5070\", \"5070\", \"5070\" #> $ trees                    <int> 76, 57, 39, 24 #> $ basal_area_m2            <dbl> 0.9394342, 0.4925679, 0.3439884, 0.2819664 #> $ mean_crown_length_m      <dbl> 4.267942, 3.194076, 3.995164, 4.211663 #> $ mean_crown_dia_m         <dbl> 1.660573, 1.185514, 1.654449, 1.501857 #> $ sum_crown_volume_m3      <dbl> 799.3865, 196.0506, 403.6156, 195.4602 #> $ basal_area_m2_per_ha     <dbl> 10.438158, 5.527257, 4.191918, 3.664439 #> $ trees_per_ha             <dbl> 844.4444, 639.6147, 475.2626, 311.9043 #> $ landfire_stand_kg_per_m3 <dbl> 0.11, 0.08, 0.08, 0.08 #> $ kg_per_m2                <dbl> 0.4694736, 0.2555261, 0.3196131, 0.3369330 #> $ biomass_kg               <dbl> 422.5263, 227.7150, 262.2742, 259.2588 #> $ landfire_tree_kg_per_m3  <dbl> 0.5285632, 1.1615116, 0.6498119, 1.3264021 # get the projection for the stand cell data epsg_code <- trees_biomass_ans$stand_cell_data_landfire$rast_epsg_code[1] %>% as.numeric() # plot the stand cell data with trees overlaid trees_biomass_ans$stand_cell_data_landfire %>%   dplyr::filter(trees>0) %>%   ggplot2::ggplot() +   ggplot2::geom_tile(ggplot2::aes(x=x,y=y,fill = landfire_stand_kg_per_m3), color = \"gray44\") +   ggplot2::geom_text(ggplot2::aes(x=x,y=y,label = trees), color = \"white\") +   ggplot2::geom_sf(     data = trees_biomass_ans$tree_list %>% sf::st_transform(crs = epsg_code)     , ggplot2::aes(color = cruz_crown_biomass_kg)   ) +   ggplot2::labs(fill=\"landfire\\nstand kg/m3\", color = \"landfire\\ncrown kg\", caption = \"# trees shown in cell\") +   ggplot2::scale_fill_viridis_c(option = \"rocket\", na.value = \"gray\", direction = -1) +   ggplot2::scale_color_viridis_c(option = \"viridis\", na.value = \"gray22\", begin = 0.6) +   ggplot2::theme_void()"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/check_las_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Check a for a directory with .laz|.las files, the path of a file, or an object of class LAS|LASCatalog — check_las_data","title":"Check a for a directory with .laz|.las files, the path of a file, or an object of class LAS|LASCatalog — check_las_data","text":"Check character directory .laz|.las files, path file, object class LAS|LASCatalog","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/check_las_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check a for a directory with .laz|.las files, the path of a file, or an object of class LAS|LASCatalog — check_las_data","text":"","code":"check_las_data(las)"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/check_las_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check a for a directory with .laz|.las files, the path of a file, or an object of class LAS|LASCatalog — check_las_data","text":"las character. directory .laz|.las files files, path single .laz|.las file, -- object class LAS|LASCatalog","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/check_spatial_points.html","id":null,"dir":"Reference","previous_headings":"","what":"Check a data frame for spatial point data. Convert to points if needed. — check_spatial_points","title":"Check a data frame for spatial point data. Convert to points if needed. — check_spatial_points","text":"Check data frame spatial point data. Convert points needed.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/check_spatial_points.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check a data frame for spatial point data. Convert to points if needed. — check_spatial_points","text":"","code":"check_spatial_points(tree_list, crs = NA)"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/check_spatial_points.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check a data frame for spatial point data. Convert to points if needed. — check_spatial_points","text":"tree_list data.frame. data frame columns treeID, tree_x, tree_y, tree_height_m. sf class object POINT geometry (see sf::st_geometry_type()), program use data \"-\" require treeID tree_height_m columns. crs string. crs string returned sf::st_crs() EPSG code x,y coordinates. Defaults crs tree_list data class \"sf\".","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/chunk_las_catalog.html","id":null,"dir":"Reference","previous_headings":"","what":"Tile raw .las|.laz files to work with smaller chunks — chunk_las_catalog","title":"Tile raw .las|.laz files to work with smaller chunks — chunk_las_catalog","text":"Function tile raw .las|.laz files work smaller chunks based point density coverage area","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/chunk_las_catalog.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tile raw .las|.laz files to work with smaller chunks — chunk_las_catalog","text":"","code":"chunk_las_catalog(   folder,   outfolder = getwd(),   accuracy_level = 2,   max_ctg_pts = 7e+07,   max_area_m2 = 9e+07,   transform = FALSE,   new_crs = NA,   old_crs = NA )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/chunk_las_catalog.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tile raw .las|.laz files to work with smaller chunks — chunk_las_catalog","text":"folder string. path folder containing set las/laz files. Can also vector file paths. outfolder string. path folder write tiled las files . accuracy_level numeric. Choose processing accuracy. accuracy_level = 1 uses DTM height normalize points accuracy_level = 2 uses triangulation high point density (20 pts/m2) height normalize points accuracy_level = 3 uses triangulation high point density (100 pts/m2) height normalize points max_ctg_pts numeric. Max number points process one time. Setting number higher possibly reduce run times increase chance running memory vice versa. max_area_m2 numeric. Max area process one time. See max_ctg_pts parameter, one less important never experienced memory issues large areas (just lots points) transform logical. las/laz files transformed? set TRUE parameters new_crs must defined. new_crs string. crs change epsg numerical code old_crs string. crs change epsg numerical code","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/chunk_las_catalog.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tile raw .las|.laz files to work with smaller chunks — chunk_las_catalog","text":"list 1) process_data sf object; 2) is_chunked_grid indicator chunks created; 3) plt ggplot object","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/chunk_las_catalog.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Tile raw .las|.laz files to work with smaller chunks — chunk_las_catalog","text":"https://r-lidar.github.io/lidRbook/norm.html https://github.com/r-lidar/lasR/issues/18#issuecomment-2027818414","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/chunk_las_catalog.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tile raw .las|.laz files to work with smaller chunks — chunk_las_catalog","text":"","code":"if (FALSE) { # \\dontrun{  f <- \"../lasdata\"  chunk_las_catalog(folder = f, outfolder = getwd())  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/clip_tree_list_aoi.html","id":null,"dir":"Reference","previous_headings":"","what":"internal functions to work with tree list data within a specified area of interest (AOI) or ","title":"internal functions to work with tree list data within a specified area of interest (AOI) or ","text":"internal functions work tree list data within AOI. example, use tree list (e.g. exported raster2trees()) within QUIC-Fire modelling tool additional columns required one needs define study area align DTM tree list domain.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/clip_tree_list_aoi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"internal functions to work with tree list data within a specified area of interest (AOI) or ","text":"","code":"clip_tree_list_aoi(   tree_list,   crs,   study_boundary,   bbox_aoi = F,   buffer = 0,   reproject_epsg = NULL )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/clip_tree_list_aoi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"internal functions to work with tree list data within a specified area of interest (AOI) or ","text":"tree_list data.frame. data frame columns treeID, tree_x, tree_y. sf class object POINT geometry (see sf::st_geometry_type()), program use data \"-\" require treeID column. required columns include: crown_area_m2, tree_height_m (e.g. exported raster2trees()) tree_cbh_m (e.g. exported trees_cbh()) one dbh_cm, dbh_m,  basal_area_m2 (e.g. exported trees_dbh()) crs string. crs string returned sf::st_crs() EPSG code x,y coordinates. Defaults crs tree_list data class \"sf\". study_boundary sf. boundary study area define area interest may extend beyond space trees. must sf class object single record. need get trees within multiple different AOI's, purrr::map() function. bbox_aoi logical. study_boundary transformed bounding box instead original shape determining trees within boundary? set true, bounding box created prior applying buffer. buffer numeric. Buffer applied study area prior determining trees within boundary. Units determined horizontal CRS settings tree_list data CRS reproject_epsg. reproject_epsg numeric. EPSG code reproject data prior buffering clipping. determine projection output data.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/cloud2raster.html","id":null,"dir":"Reference","previous_headings":"","what":"Use raw .las|.laz files to generate CHM, DTM, and Normalized .las files — cloud2raster","title":"Use raw .las|.laz files to generate CHM, DTM, and Normalized .las files — cloud2raster","text":"cloud2raster() --one function process raw .las|.laz files generate CHM raster (.tif), DTM raster (.tif), .las files height normalized. order operations : Tile raw point cloud work smaller chunks reduce potential memory issues high density clouds using chunk_las_catalog() Classify point cloud using lasR::classify_with_csf() Remove outlier points using lasR::classify_with_ivf() Produce triangulation ground points (meshed DTM) using lasR::triangulate() Rasterize result Delaunay triangulation using lasR::rasterize() create DTM Height normalize point cloud using either DTM triangulation lasR::transform_with() Use height normalized point cloud create CHM based highest point pixel using lasR::rasterize() Pits spikes filling CHM raster using lasR::pit_fill() Smooth CHM raster tile gaps using terra::focal()","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/cloud2raster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use raw .las|.laz files to generate CHM, DTM, and Normalized .las files — cloud2raster","text":"","code":"cloud2raster(   output_dir,   input_las_dir,   input_treemap_dir = NULL,   input_foresttype_dir = NULL,   accuracy_level = 2,   max_ctg_pts = 7e+07,   max_area_m2 = 9e+07,   transform = FALSE,   new_crs = NA,   old_crs = NA,   keep_intrmdt = F,   dtm_res_m = 1,   chm_res_m = 0.25,   min_height = 2,   max_height = 70,   overwrite = TRUE )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/cloud2raster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use raw .las|.laz files to generate CHM, DTM, and Normalized .las files — cloud2raster","text":"output_dir parent directory new folders point_cloud_processing_delivery point_cloud_processing_temp written exports input_las_dir directory .las|.laz point cloud data exists...program search sub-directories .las|.laz files process one input_treemap_dir character. directory Treemap 2016 exists. Use get_treemap() first. input_foresttype_dir character. directory Forest Type Groups data exists. Use get_foresttype() first. accuracy_level numeric. Choose processing accuracy. accuracy_level = 1 uses DTM height normalize points accuracy_level = 2 uses triangulation high point density (20 pts/m2) height normalize points accuracy_level = 3 uses triangulation high point density (100 pts/m2) height normalize points max_ctg_pts numeric. Max number points process one time. Setting number higher possibly reduce run times increase chance running memory vice versa. max_area_m2 numeric. Max area process one time. See max_ctg_pts parameter, one less important never experienced memory issues large areas (just lots points) transform logical. las/laz files transformed? set TRUE parameters new_crs must defined. new_crs string. crs change epsg numerical code old_crs string. crs change epsg numerical code keep_intrmdt logical. process writes intermediate data disk, keep intermediate files (classfied, normalized, stem las files)? dtm_res_m numeric. desired resolution DTM produced meters. chm_res_m numeric. desired resolution CHM produced meters. min_height numeric. Set minimum height (m) individual tree detection max_height numeric. Set maximum height (m) canopy height model overwrite logical. output files point_cloud_processing_delivery directory previous iterations deleted?","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/cloud2raster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Use raw .las|.laz files to generate CHM, DTM, and Normalized .las files — cloud2raster","text":"Returns goods. Exports files goods new folders \"point_cloud_processing_delivery\" \"point_cloud_processing_temp\" output_dir defined user function call.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/cloud2raster.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Use raw .las|.laz files to generate CHM, DTM, and Normalized .las files — cloud2raster","text":"https://r-lidar.github.io/lasR/index.html https://r-lidar.github.io/lidRbook/normalization.html","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/cloud2raster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Use raw .las|.laz files to generate CHM, DTM, and Normalized .las files — cloud2raster","text":"","code":"if (FALSE) { # \\dontrun{  # test las file but this could also be a directory path with >1 .las|.laz files  i <- system.file(\"extdata\", \"MixedConifer.laz\", package=\"lidR\")  # run it  r <- cloud2trees::cloud2raster(output_dir = tempdir(), input_las_dir = i)  # what is it?  r %>% names()  # there's a DTM  r$dtm_rast %>% terra::plot()  # there's a CHM  r$chm_rast %>% terra::plot()  # there's a data.frame with the file structure for the project  r$create_project_structure_ans %>% dplyr::glimpse()  # there's a information detailing how the point cloud was processed  r$chunk_las_catalog_ans$process_data %>% dplyr::glimpse()  r$chunk_las_catalog_ans$is_chunked_grid  r$chunk_las_catalog_ans$las_ctg@data %>% dplyr::glimpse()  # there's a list of the height normalized .las files created  r$normalize_flist  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/cloud2trees-package.html","id":null,"dir":"Reference","previous_headings":"","what":"cloud2trees: Point Cloud Data to Forest Inventory Tree List — cloud2trees-package","title":"cloud2trees: Point Cloud Data to Forest Inventory Tree List — cloud2trees-package","text":"Extract tree list, CHM, DTM, .las|.laz point cloud data. Point cloud data can LiDAR sensor photogrammetry (.e. structure motion).","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/cloud2trees.html","id":null,"dir":"Reference","previous_headings":"","what":"Use raw .las|.laz files to generate CHM, DTM, and a tree list — cloud2trees","title":"Use raw .las|.laz files to generate CHM, DTM, and a tree list — cloud2trees","text":"cloud2trees() --one function process raw .las|.laz files generate CHM raster (.tif), DTM raster (.tif), tree list tree location, height, DBH. order operations : Generate CHM point cloud using cloud2raster() Perform individual tree detection using raster2trees() Quantify individual tree competition metrics using trees_competition() (set TRUE) Extract tree DBH values normalized point cloud using treels_stem_dbh() (set TRUE) Model tree DBH values using trees_dbh() (set TRUE) Extract tree forest type group using trees_type() (set TRUE) Extract tree CBH values normalized point cloud estimate missing values using trees_cbh() (set TRUE) Estimate tree biomass (crown biomass) using trees_biomass() (method denoted) See documentation individual function called details.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/cloud2trees.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use raw .las|.laz files to generate CHM, DTM, and a tree list — cloud2trees","text":"","code":"cloud2trees(   output_dir,   input_las_dir,   input_treemap_dir = NULL,   input_foresttype_dir = NULL,   input_landfire_dir = NULL,   accuracy_level = 2,   max_ctg_pts = 7e+07,   max_area_m2 = 9e+07,   transform = FALSE,   new_crs = NA,   old_crs = NA,   keep_intrmdt = FALSE,   dtm_res_m = 1,   chm_res_m = 0.25,   min_height = 2,   max_height = 70,   ws = itd_ws_functions()[[\"log_fn\"]],   estimate_tree_dbh = FALSE,   max_dbh = 2,   dbh_model = \"lin\",   estimate_dbh_from_cloud = FALSE,   estimate_tree_competition = FALSE,   competition_buffer_m = 5,   search_dist_max,   competition_max_search_dist_m = 10,   estimate_tree_type = FALSE,   type_max_search_dist_m = 1000,   estimate_tree_hmd = FALSE,   hmd_tree_sample_n = NA,   hmd_tree_sample_prop = NA,   hmd_estimate_missing_hmd = FALSE,   estimate_biomass_method = NA,   biomass_max_crown_kg_per_m3 = 2,   estimate_tree_cbh = FALSE,   cbh_tree_sample_n = NA,   cbh_tree_sample_prop = NA,   cbh_which_cbh = \"lowest\",   cbh_estimate_missing_cbh = FALSE,   cbh_min_vhp_n = 3,   cbh_voxel_grain_size_m = 1,   cbh_dist_btwn_bins_m = 1,   cbh_min_fuel_layer_ht_m = 1,   cbh_lad_pct_gap = 25,   cbh_lad_pct_base = 25,   cbh_num_jump_steps = 1,   cbh_min_lad_pct = 10,   cbh_frst_layer_min_ht_m = 1,   overwrite = TRUE )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/cloud2trees.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use raw .las|.laz files to generate CHM, DTM, and a tree list — cloud2trees","text":"output_dir parent directory new folders point_cloud_processing_delivery point_cloud_processing_temp written exports input_las_dir directory .las|.laz point cloud data exists...program search sub-directories .las|.laz files process one input_treemap_dir character. directory Treemap 2016 exists. Use get_treemap() first. input_foresttype_dir character. directory Forest Type Groups data exists. Use get_foresttype() first. input_landfire_dir character. directory LANDFIRE CBD data exists. Use get_landfire() first. accuracy_level numeric. Choose processing accuracy. accuracy_level = 1 uses DTM height normalize points accuracy_level = 2 uses triangulation high point density (20 pts/m2) height normalize points accuracy_level = 3 uses triangulation high point density (100 pts/m2) height normalize points max_ctg_pts numeric. Max number points process one time. Setting number higher possibly reduce run times increase chance running memory vice versa. max_area_m2 numeric. Max area process one time. See max_ctg_pts parameter, one less important never experienced memory issues large areas (just lots points) transform logical. las/laz files transformed? set TRUE parameters new_crs must defined. new_crs string. crs change epsg numerical code old_crs string. crs change epsg numerical code keep_intrmdt logical. process writes intermediate data disk, keep intermediate files (classfied, normalized, stem las files)? dtm_res_m numeric. desired resolution DTM produced meters. chm_res_m numeric. desired resolution CHM produced meters. min_height numeric. Set minimum height (m) individual tree detection max_height numeric. Set maximum height (m) canopy height model ws numeric function. Length diameter moving window used detect local maxima units input data (usually meters). numeric fixed window size used. function, function determines size window given location canopy. default function takes height given pixel argument return desired size search window centered pixel. estimate_tree_dbh logical. tree DBH estimated? See trees_dbh(). max_dbh numeric. Set largest tree diameter (m) expected point cloud dbh_model string. Set model use local dbh-height allometry. Can \"rf\" random forest \"lin\" linear estimate_dbh_from_cloud logical. DBH estimated point cloud? See treels_stem_dbh(). Setting TRUE may significantly increase processing time. estimate_tree_competition logical. tree competition metrics calculated? See trees_competition(). Setting TRUE may slightly increase processing time. competition_buffer_m number. Set buffer around tree (m) calculate competition metrics search_dist_max Use competition_max_search_dist_m argument instead. competition_max_search_dist_m number. Maximum search distance (m) nearest tree competition. Larger search distances increase processing time possibly result memory issues. competition trees found within distance, return column comp_dist_to_nearest_m = competition_max_search_dist_m parameter. estimate_tree_type logical. tree forest type estimated? See trees_type(). type_max_search_dist_m number. Maximum search distance (m) obtain forest type group data trees overlap non-forest data original Wilson (2023) data. Larger search distances increase processing time possibly result memory issues. estimate_tree_hmd logical. tree height maximum crown diameter (HMD) estimated? See trees_hmd(). hmd_tree_sample_n, hmd_tree_sample_prop numeric. Provide either tree_sample_n, number trees, tree_sample_prop, proportion trees attempt extract HMD point cloud . neither supplied, tree_sample_n = 777 used. supplied, tree_sample_n used. Increasing tree_sample_prop toward one (1) increase processing time, perhaps significantly depending number trees trees_poly data. maximum number trees extract tree HMD using cloud2trees() 20,000. Try trees_hmd() outputs cloud2trees() want attempt extract HMD >20,000 trees. hmd_estimate_missing_hmd logical. likely HMD extracted successfully every tree. missing HMD values estimated using tree height location information based trees HMD successfully extracted? estimate_biomass_method character. estimate tree biomass tree (crown biomass) enter one list multiple biomass methods. See trees_biomass(). Leave blank (.e. NA) skip biomass estimation. biomass_max_crown_kg_per_m3 numeric. maximum CBD tree crown kilograms per cubic meter. Values limit set median value area using stands CBD values lower limit. default value 2 kilograms per cubic meter based Mell et al. (2009) found dry bulk density tree crown 2.6 kilograms per cubed meter using Douglas-fir trees grown Christmas tree farms. Set parameter large value (e.g. 1e10) NULL avoid limiting tree crown CBD. estimate_tree_cbh logical. tree DBH estimated? See trees_cbh(). Make sure set cbh_estimate_missing_cbh = TRUE want obtain CBH values cases CBH extracted point cloud. cbh_tree_sample_n, cbh_tree_sample_prop numeric. Provide either tree_sample_n, number trees, tree_sample_prop, proportion trees attempt extract CBH point cloud . neither supplied, tree_sample_n = 333 used. supplied, tree_sample_n used. Increasing tree_sample_prop toward one (1) increase processing time, perhaps significantly depending number trees trees_poly data. maximum number trees extract tree CBH using cloud2trees() 20,000. Try trees_cbh() outputs cloud2trees() want attempt extract CBH >20,000 trees. cbh_which_cbh character. One : \"lowest\"; \"highest\"; \"max_lad\". See Viedma et al. (2024) reference. \"lowest\" - Height CBH segmented tree based last distance found profile \"highest\" - Height CBH segmented tree based maximum distance found profile \"max_lad\" - Height CBH segmented tree based maximum LAD percentage cbh_estimate_missing_cbh logical. even cbh_tree_sample_prop parameter set \"1\", likely CBH extracted successfully every tree. missing CBH values estimated using tree height location information based trees CBH successfully extracted? cbh_min_vhp_n numeric. minimum number vertical height profiles (VHPs) needed estimate CBH. cbh_voxel_grain_size_m numeric. horizontal resolution (suggested 1 meter lad profiles 10 meters LAI maps). See grain.size leafR::lad.voxels() cbh_dist_btwn_bins_m numeric. value actual height bin step (meters). See step LadderFuelsR::get_gaps_fbhs() cbh_min_fuel_layer_ht_m numeric. value actual minimum base height (meters). See min_height LadderFuelsR::get_gaps_fbhs() cbh_lad_pct_gap numeric. value percentile threshold used identify gaps (default percentile 25th). See perc_gap LadderFuelsR::get_gaps_fbhs() cbh_lad_pct_base numeric. value percentile threshold used identify fuels layers base height (default percentile 25th). See perc_base LadderFuelsR::get_gaps_fbhs() cbh_num_jump_steps numeric. value number height bin steps can jumped reshape fuels layers. See number_steps LadderFuelsR::get_real_fbh() cbh_min_lad_pct numeric. value minimum required LAD percentage fuel layer. See threshold LadderFuelsR::get_layers_lad() cbh_frst_layer_min_ht_m numeric. value depth height first fuel layer. first fuel layer maximum LAD depth greater indicated value, fuel layer considered CBH tree. contrary, depth <= value, CBH maximum LAD second fuel layer, although maximum LAD. See hdepth1_height LadderFuelsR::get_cbh_metrics() overwrite logical. output files point_cloud_processing_delivery directory previous iterations deleted?","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/cloud2trees.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Use raw .las|.laz files to generate CHM, DTM, and a tree list — cloud2trees","text":"Returns goods. Exports files goods new folders \"point_cloud_processing_delivery\" \"point_cloud_processing_temp\" output_dir defined user function call.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/cloud2trees.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Use raw .las|.laz files to generate CHM, DTM, and a tree list — cloud2trees","text":"","code":"if (FALSE) { # \\dontrun{  # test las file but this could also be a directory path with >1 .las|.laz files  i <- system.file(\"extdata\", \"MixedConifer.laz\", package=\"lidR\")  # run it  cloud2trees_ans <- cloud2trees::cloud2trees(output_dir = tempdir(), input_las_dir = i)  # what is it?  cloud2trees_ans %>% names()  # there's a DTM  cloud2trees_ans$dtm_rast %>% terra::plot()  # there's a CHM  cloud2trees_ans$chm_rast %>% terra::plot()  # there are tree crowns  cloud2trees_ans$crowns_sf %>% dplyr::glimpse()  cloud2trees_ans$crowns_sf %>% ggplot2::ggplot() +   ggplot2::geom_sf(mapping = ggplot2::aes(fill = tree_height_m))  # there are tree top points  cloud2trees_ans$treetops_sf %>% dplyr::glimpse()  cloud2trees_ans$treetops_sf %>% ggplot2::ggplot() +   ggplot2::geom_sf(mapping = ggplot2::aes(color = tree_height_m))  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/cloud2trees_to_lanl_trees.html","id":null,"dir":"Reference","previous_headings":"","what":"Use outputs from cloud2trees() to generate inputs for LANL TREES program — cloud2trees_to_lanl_trees","title":"Use outputs from cloud2trees() to generate inputs for LANL TREES program — cloud2trees_to_lanl_trees","text":"cloud2trees_to_lanl_trees() uses output cloud2trees() generate inputs LANL TREES program pathway fire modeling Quic-Fire primary input directory outputs cloud2trees(). default directory written cloud2trees() point_cloud_processing_delivery must contain (minimum): DTM raster name formatted : \"dtm_xx.tif\" Tree list data name formatted : \"final_detected_tree_tops.gpkg\" (tree points) \"final_detected_crowns.gpkg\" (tree crowns) study area spatial file can read sf package (see sf::st_drivers())","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/cloud2trees_to_lanl_trees.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use outputs from cloud2trees() to generate inputs for LANL TREES program — cloud2trees_to_lanl_trees","text":"","code":"cloud2trees_to_lanl_trees(   input_dir,   study_boundary = NA,   bbox_aoi = T,   buffer = 0,   topofile = \"flat\",   cbd_method = \"landfire\",   output_dir = tempdir(),   fuel_litter = list(ilitter = 0, lrho = 4.667, lmoisture = 0.06, lss = 5e-04, ldepth =     0.06),   fuel_grass = list(igrass = 0, grho = 1.17, gmoisture = 0.06, gss = 5e-04, gdepth =     0.27) )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/cloud2trees_to_lanl_trees.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use outputs from cloud2trees() to generate inputs for LANL TREES program — cloud2trees_to_lanl_trees","text":"input_dir directory outputs cloud2trees(). default directory written cloud2trees() point_cloud_processing_delivery study_boundary sf. boundary study area used determine outputs bbox_aoi logical. study_boundary transformed bounding box instead original shape determining objects within boundary? buffer numeric. Buffer applied study area prior determining objects within boundary. Units determined horizontal CRS settings tree list data topofile character. one \"flat\" \"dtm\": \"flat\" - always flat QUIC-Fire \"dtm\" - uses topo.dat file created based DTM; potentially FIRETEC cbd_method character. one \"landfire\" \"cruz\": Tree crown biomass method: \"landfire\" - based LANDFIRE's Forest Canopy Bulk Density (CBD) data (trees_biomass_landfire()) \"cruz\" - based Cruz et al. (2003) canopy fuel stratum equations (trees_biomass_cruz()) output_dir parent directory new folder lanl_trees_delivery written exports fuel_litter list. list() numeric vector c(). see default. must parameters order: \"ilitter\" : 0 = litter, 1 = litter \"lrho\" : litter bulk density (kg/m3) \"lmoisture : litter moisture (percent 0-1 scale) \"lss\" : litter sizescale (m) \"ldepth\" : litter depth (m) fuel_grass list. list() numeric vector c(). see default. must parameters order: \"igrass\" : 0 = grass, 1 = grass \"grho\" : grass bulk density (kg/m3) \"gmoisture\" : grass moisture (percent 0-1 scale) \"gss\" : grass sizescale (m) \"gdepth\" : grass depth (m)","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/cloud2trees_to_lanl_trees.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Use outputs from cloud2trees() to generate inputs for LANL TREES program — cloud2trees_to_lanl_trees","text":"Returns list objects: \"tree_list\" = cropped tree list based study area extent customized settings \"aoi\" = study area extent customized settings \"dtm\" = cropped DTM based study area extent customized settings \"domain_path\" = path \"Lidar_Bounds.geojson\" file \"topofile_path\" = path \"topo.dat\" file \"fuellist_path\" = path TREES program \"fuellist\" file \"treelist_path\" = path \"Cloud2Trees_TreeList.txt\" file","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/cloud2trees_to_lanl_trees.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Use outputs from cloud2trees() to generate inputs for LANL TREES program — cloud2trees_to_lanl_trees","text":"https://github.com/lanl/Trees/ Quic-Fire","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/cloud2trees_to_lanl_trees.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Use outputs from cloud2trees() to generate inputs for LANL TREES program — cloud2trees_to_lanl_trees","text":"","code":"if (FALSE) { # \\dontrun{  # test las file but this could also be a directory path with >1 .las|.laz files  i <- system.file(\"extdata\", \"MixedConifer.laz\", package=\"lidR\")  # set the dir to write the output  my_dir <- tempdir()  # run it  cloud2trees_ans <- cloud2trees::cloud2trees(    output_dir = my_dir    , input_las_dir = i    # turn on all of the attribute estimations    , estimate_tree_dbh = T    , estimate_tree_type = T    , estimate_tree_hmd = T    , hmd_tree_sample_prop = 0.5    , hmd_estimate_missing_hmd = T    , estimate_biomass_method = \"landfire\"    , estimate_tree_cbh = T    , cbh_tree_sample_prop = 0.3    , cbh_estimate_missing_cbh = T  )  # generate a fake study_boundary we know overlaps the tree list  my_aoi <- cloud2trees_ans$treetops_sf %>%    sf::st_bbox() %>%    sf::st_as_sfc() %>%    sf::st_buffer(-10) %>%    sf::st_as_sf()  # plot it  ggplot2::ggplot() +    ggplot2::geom_sf(data = cloud2trees_ans$treetops_sf) +    ggplot2::geom_sf(data = my_aoi, fill = NA, color = \"blue\")  # cloud2trees::cloud2trees() wrote the `point_cloud_processing_delivery` folder  cloud2trees_output_dir <- file.path(my_dir,\"point_cloud_processing_delivery\")  list.files(cloud2trees_output_dir)  list.dirs(cloud2trees_output_dir, recursive = F)  # now cloud2trees_to_lanl_trees()  cloud2trees_to_lanl_trees_ans <- cloud2trees_to_lanl_trees(    input_dir = cloud2trees_output_dir    , study_boundary = my_aoi    , bbox_aoi = F    , buffer = 0    , topofile = \"flat\"    , cbd_method = \"landfire\"    , output_dir = cloud2trees_output_dir  )  cloud2trees_to_lanl_trees_ans %>% names()  list.dirs(cloud2trees_output_dir, recursive = F)  lanl_trees_output_dir <- file.path(cloud2trees_output_dir,\"lanl_trees_delivery\")  list.files(lanl_trees_output_dir)  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/create_lax_for_tiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Create spatial index .lax files — create_lax_for_tiles","title":"Create spatial index .lax files — create_lax_for_tiles","text":"Function create spatial index files .lax .las|.laz files speed processing","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/create_lax_for_tiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create spatial index .lax files — create_lax_for_tiles","text":"","code":"create_lax_for_tiles(las_file_list)"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/create_lax_for_tiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create spatial index .lax files — create_lax_for_tiles","text":"las_file_list list .las|.laz files full directory path","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/create_lax_for_tiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create spatial index .lax files — create_lax_for_tiles","text":"list file names","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/create_lax_for_tiles.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create spatial index .lax files — create_lax_for_tiles","text":"https://r-lidar.github.io/lidRbook/spatial-indexing.html","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/create_lax_for_tiles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create spatial index .lax files — create_lax_for_tiles","text":"","code":"if (FALSE) { # \\dontrun{  f <- list.files(getwd(), pattern = \".*\\\\.(laz|las)$\", full.names = TRUE)  create_lax_for_tiles(las_file_list = f)  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/create_project_structure.html","id":null,"dir":"Reference","previous_headings":"","what":"Create project structure — create_project_structure","title":"Create project structure — create_project_structure","text":"Function generate nested project directories based user-defined directory create output file structure","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/create_project_structure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create project structure — create_project_structure","text":"","code":"create_project_structure(   output_dir,   input_las_dir,   input_treemap_dir = NULL,   input_foresttype_dir = NULL )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/create_project_structure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create project structure — create_project_structure","text":"output_dir parent directory new folders point_cloud_processing_delivery point_cloud_processing_temp written exports input_las_dir directory .las|.laz point cloud data exists...program search sub-directories .las|.laz files process one input_treemap_dir character. directory Treemap 2016 exists. Use get_treemap() first. input_foresttype_dir character. directory Forest Type Groups data exists. Use get_foresttype() first.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/create_project_structure.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create project structure — create_project_structure","text":"data.frame.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/crop_raster_match_points.html","id":null,"dir":"Reference","previous_headings":"","what":"internal functions to extract raster values at point locations — crop_raster_match_points","title":"internal functions to extract raster values at point locations — crop_raster_match_points","text":"internal functions extract raster values point locations used trees_type() tree_biomass() LANDFIRE rasters part, functions take point raster data inputs general process (see trees_type() example): crop_raster_match_points() check undesirable NA values point_values crop_raster_match_points() undesirable values: reclass_landfire_rast() reclass_foresttype_rast() agg_fill_rast_match_points(), see details function definition use point_values agg_fill_rast_match_points() null otherwise, use point_values crop_raster_match_points() Note development: currently looking entire bounding box points (study boundary defined) fill NA raster cells computationally intensive process, especially large areas (>100k ha), fine resolution rasters (<=30m) points uniformly randomly dispersed across entire AOI, current process likely best process points clustered groups across AOI, future development attempt group points clusters iterate raster filling process cluster groups may allow finer resolution raster data input (instead aggregating) see examples","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/crop_raster_match_points.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"internal functions to extract raster values at point locations — crop_raster_match_points","text":"","code":"crop_raster_match_points(   points,   rast,   study_boundary = NA,   max_search_dist_m = 1000 )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/crop_raster_match_points.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"internal functions to extract raster values at point locations — crop_raster_match_points","text":"points sf. rast SpatRaster. study_boundary sf. max_search_dist_m numeric.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/crop_raster_match_points.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"internal functions to extract raster values at point locations — crop_raster_match_points","text":"","code":"if (FALSE) { # \\dontrun{ # !!!!!!!!!!!!!!!! this is a starter example for the author if decide to cluster points # !!!!!!!!!!!!!!!! and apply raster match, fill, aggregate separately for clusters # Sample data data <- data.frame(     x = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10),     y = c(2, 4, 3, 1, 5, 6, 7, 8, 9, 10) )  # Calculate distances distances <- dist(data)  # Perform hierarchical clustering hc <- hclust(distances, method = \"complete\")  # Calculate WSS for different numbers of clusters wss <- numeric(10) for (k in 1:10) {   wss[k] <- sum(kmeans(data, centers = k)$withinss) }  # Plot the elbow plot(1:10, wss, type = \"b\", xlab = \"Number of Clusters (k)\",      ylab = \"Within-Cluster Sum of Squares (WSS)\")  # Find the optimal number of clusters (this is subjective) # You might need to visually inspect the plot optimal_k <- which.min(diff(wss, differences = 2))  # Cut the dendrogram based on the optimal number of clusters clusters <- cutree(hc, k = optimal_k) } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/find_ext_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Find the location of external data — find_ext_data","title":"Find the location of external data — find_ext_data","text":"Find location external data Functions get_*() download external data","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/find_ext_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find the location of external data — find_ext_data","text":"","code":"find_ext_data(   input_treemap_dir = NULL,   input_foresttype_dir = NULL,   input_landfire_dir = NULL )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/find_ext_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find the location of external data — find_ext_data","text":"input_treemap_dir character. directory Treemap 2016 exists. Use get_treemap() first. input_foresttype_dir character. directory Forest Type Groups data exists. Use get_foresttype() first. input_landfire_dir character. directory LANDFIRE CBD data exists. Use get_landfire() first.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/find_ext_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find the location of external data — find_ext_data","text":"Returns list values either NULL unable locate external data files , directory external data files located. list includes named variables treemap_dir foresttype_dir","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/find_ext_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find the location of external data — find_ext_data","text":"","code":"if (FALSE) { # \\dontrun{  find_ext_data()  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_cruz_stand_kg_per_m3.html","id":null,"dir":"Reference","previous_headings":"","what":"internal functions to estimate tree biomass — get_cruz_stand_kg_per_m3","title":"internal functions to estimate tree biomass — get_cruz_stand_kg_per_m3","text":"internal functions extract raster values point locations used trees_biomass*() functions part, functions used distribute raster cell (.e. \"stand\") level estimates fuel load individual trees","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_cruz_stand_kg_per_m3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"internal functions to estimate tree biomass — get_cruz_stand_kg_per_m3","text":"","code":"get_cruz_stand_kg_per_m3(   forest_type_group_code,   basal_area_m2_per_ha,   trees_per_ha )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_cruz_stand_kg_per_m3.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"internal functions to estimate tree biomass — get_cruz_stand_kg_per_m3","text":"forest_type_group_code numeric. extracted trees_type() basal_area_m2_per_ha numeric. trees_per_ha numeric.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Download all external data used by package — get_data","title":"Download all external data used by package — get_data","text":"package requires external data estimate individual tree DBH (see get_treemap()) extract forest type tree list (see get_foresttype()). --one function downloads external data used package.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download all external data used by package — get_data","text":"","code":"get_data(savedir = NULL, force = F)"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download all external data used by package — get_data","text":"savedir Optional directory save data new location. Defaults package contents. force Whether overwrite existing data","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download all external data used by package — get_data","text":"","code":"if (FALSE) { # \\dontrun{  get_data()  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_foresttype.html","id":null,"dir":"Reference","previous_headings":"","what":"Download Forest Type Groups of the Continental United States data — get_foresttype","title":"Download Forest Type Groups of the Continental United States data — get_foresttype","text":"Forest Type Groups Continental United States data used estimate individual tree forest type group. See trees_type()","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_foresttype.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download Forest Type Groups of the Continental United States data — get_foresttype","text":"","code":"get_foresttype(savedir = NULL, force = F, res = 30)"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_foresttype.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download Forest Type Groups of the Continental United States data — get_foresttype","text":"savedir Optional directory save data new location. Defaults package contents. force Whether overwrite existing data res Resolution forest type data download. Default \"30\" downloads 30m raster, value download 90m raster.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_foresttype.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download Forest Type Groups of the Continental United States data — get_foresttype","text":"Forest Type Groups Continental United States Wilson, B.T. (2023). Forest Type Groups Continental United States.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_foresttype.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download Forest Type Groups of the Continental United States data — get_foresttype","text":"","code":"if (FALSE) { # \\dontrun{  get_foresttype()  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_landfire.html","id":null,"dir":"Reference","previous_headings":"","what":"Download Forest Type Groups of the Continental United States data — get_landfire","title":"Download Forest Type Groups of the Continental United States data — get_landfire","text":"LANDFIRE Forest Canopy Bulk Density (CBD) data used estimate individual tree crown biomass kilograms See trees_biomass_landfire()","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_landfire.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download Forest Type Groups of the Continental United States data — get_landfire","text":"","code":"get_landfire(savedir = NULL, force = F)"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_landfire.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download Forest Type Groups of the Continental United States data — get_landfire","text":"savedir Optional directory save data new location. Defaults package contents. force Whether overwrite existing data","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_landfire.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download Forest Type Groups of the Continental United States data — get_landfire","text":"LANDFIRE Forest Canopy Bulk Density (CBD) U.S. Department Agriculture U.S. Department Interior.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_landfire.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download Forest Type Groups of the Continental United States data — get_landfire","text":"","code":"if (FALSE) { # \\dontrun{  get_landfire()  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_treemap.html","id":null,"dir":"Reference","previous_headings":"","what":"Download TreeMap 2016 data — get_treemap","title":"Download TreeMap 2016 data — get_treemap","text":"estimate individual tree DBH based point cloud detected tree height models fit FIA plot data within buffer point cloud boundary. FIA plots identified using TreeMap 2016, model FIA plot locations imputed throughout forested areas conterminous United States 30 m spatial resolution. See trees_dbh()","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_treemap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download TreeMap 2016 data — get_treemap","text":"","code":"get_treemap(savedir = NULL, force = F)"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_treemap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download TreeMap 2016 data — get_treemap","text":"savedir Optional directory save data new location. Defaults package contents. force Whether overwrite existing data","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_treemap.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Download TreeMap 2016 data — get_treemap","text":"https://doi.org/10.2737/RDS-2021-0074 Riley, Karin L.; Grenfell, Isaac C.; Finney, Mark .; Shaw, John D. 2021. TreeMap 2016: tree-level model forests conterminous United States circa 2016. Fort Collins, CO: Forest Service Research Data Archive.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_treemap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download TreeMap 2016 data — get_treemap","text":"","code":"if (FALSE) { # \\dontrun{  get_treemap()  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_url_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Download url data — get_url_data","title":"Download url data — get_url_data","text":"Generic function download data url .zip file data Functions get_treemap() get_foresttype() use ","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_url_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download url data — get_url_data","text":"","code":"get_url_data(   eval_url = NULL,   my_name = NULL,   savedir = NULL,   req_file_list = NULL,   force = F,   cleanup_zip = T,   move_files_to_top = T )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_url_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download url data — get_url_data","text":"eval_url Required url .zip file downloaded. url string must end .zip my_name Required name folder data extracted savedir Optional directory save data new location. Defaults package contents. req_file_list Optional list files check re-downloading full data force Whether overwrite existing data cleanup_zip Whether remove .zip file extracting contents","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_url_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download url data — get_url_data","text":"","code":"if (FALSE) { # \\dontrun{  get_treemap()  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_vertical_crs.html","id":null,"dir":"Reference","previous_headings":"","what":"tools for working with projections, crs, epsg, and whatnot — get_vertical_crs","title":"tools for working with projections, crs, epsg, and whatnot — get_vertical_crs","text":"tools working projections, crs, epsg, whatnot","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_vertical_crs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"tools for working with projections, crs, epsg, and whatnot — get_vertical_crs","text":"","code":"get_vertical_crs(x)"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_vertical_crs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"tools for working with projections, crs, epsg, and whatnot — get_vertical_crs","text":"x sf. object class can read sf::st_crs \"LAS\" class","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/get_vertical_crs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"tools for working with projections, crs, epsg, and whatnot — get_vertical_crs","text":"data.frame units scale factor vertical projection","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/itd_tuning.html","id":null,"dir":"Reference","previous_headings":"","what":"Individual Tree Detection (ITD) tuning — itd_tuning","title":"Individual Tree Detection (ITD) tuning — itd_tuning","text":"itd_tuning() used visually assess tree crown delineation results different window size functions used detection individual trees. cloud2trees package performs individual tree detection using lidR::locate_trees() lidR::lmf() algorithm. local maximum filter algorithm allows constant window size variable window size defined function. See lidR package book excellent detail ITD defining window size. itd_tuning() allows users test different window size functions sample data determine function suitable area analyzed. preferred function can used ws parameter raster2trees() /cloud2trees().","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/itd_tuning.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Individual Tree Detection (ITD) tuning — itd_tuning","text":"","code":"itd_tuning(   input_las_dir,   n_samples = 3,   ws_fn_list = NULL,   min_height = 2,   chm_res_m = 0.25 )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/itd_tuning.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Individual Tree Detection (ITD) tuning — itd_tuning","text":"input_las_dir character. directory .las|.laz point cloud data exists...program search sub-directories .las|.laz files process one n_samples numeric. number sample plots 0.1 ha test window functions. maximum 5. center point cloud data coverage always first plot sampled long points exist central 0.1 ha. ws_fn_list list. function named list functions. Leave NULL test default exponential (concave ), linear, logarithmic (concave ) functions. providing custom function, must always return numeric value >0 (see examples). min_height numeric. Set minimum height (m) individual tree detection chm_res_m numeric. desired resolution CHM produced meters.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/itd_tuning.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Individual Tree Detection (ITD) tuning — itd_tuning","text":"Returns list : 1) \"plot_samples\" plot sample canopy height model (CHM) extracted tree crowns window size tested; 2) \"ws_fn_list\" list window size functions tested can used pass desired function ws parameter raster2trees() /cloud2trees().","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/itd_tuning.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Individual Tree Detection (ITD) tuning — itd_tuning","text":"https://r-lidar.github.io/lidRbook/itd.html","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/itd_tuning.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Individual Tree Detection (ITD) tuning — itd_tuning","text":"","code":"if (FALSE) { # \\dontrun{   # do it   library(tidyverse)   # test las file but this could also be a directory path with >1 .las|.laz files   i <- system.file(package = \"lidR\", \"extdata\", \"MixedConifer.laz\")   ####################################################   # check the default itd_tuning() window functions   ####################################################    # run it with defaults    itd_tuning_ans <- itd_tuning(input_las_dir = i)    # what's in it?    names(itd_tuning_ans)    # look at the tuning plot showing the tree crowns on the CHM    itd_tuning_ans$plot_samples    # look at the summary of the trees detected by each ITD function    itd_tuning_ans$plot_sample_summary    # the \"exp_fn\" looks pretty good, let's store it    best_default <- itd_tuning_ans$ws_fn_list$exp_fn    # we can see what this function looks like for window size    ggplot2::ggplot() +      ggplot2::geom_function(fun = best_default) +      ggplot2::xlim(-5,60) +      ggplot2::labs(x = \"heights\", y = \"ws\", color = \"\")    # pass our best function to the cloud2trees() to process the full point cloud coverage    cloud2trees_ans <- cloud2trees(output_dir = tempdir(), input_las_dir = i, ws = best_default)    # the same plot as the the tuning plot with tree crowns overlaid on CHM    ggplot2::ggplot() +      ggplot2::geom_tile(        data = cloud2trees_ans$chm_rast %>%          terra::as.data.frame(xy=T) %>%          dplyr::rename(f=3)        , mapping = ggplot2::aes(x = x, y = y, fill = f)        , na.rm = T      ) +      ggplot2::scale_fill_viridis_c(        option = \"plasma\"        , breaks = scales::breaks_extended(n=10)      ) +      ggplot2::geom_sf(        data = cloud2trees_ans$crowns_sf        , fill = NA, color = \"gray33\", lwd = 1      ) +      ggplot2::scale_x_continuous(expand = c(0, 0)) +      ggplot2::scale_y_continuous(expand = c(0, 0)) +      ggplot2::labs(x = \"\", y = \"\", fill = \"CHM (m)\") +      ggplot2::theme_light() +      ggplot2::theme(axis.text = ggplot2::element_blank())   ####################################################   # let's test some custom window functions   ####################################################     # a constant window size has to be defined as:      ## x*0 + constant      my_constant <- function(x){(x * 0) + 3} ## will always return 3     # a custom linear function      my_linear <- function(x) {(x * 0.1) + 3}     # run it with custom functions      itd_tuning_ans2 <- itd_tuning(        input_las_dir = i        , ws_fn_list = list(           my_constant=my_constant           , my_linear=my_linear           , best_default=best_default # the best from our first test         )        , n_samples = 2       )     # look at the tuning plot showing the tree crowns on the CHM      itd_tuning_ans$plot_samples     # look at the summary of the trees detected by each ITD function      itd_tuning_ans$plot_sample_summary     # we can see what our custom \"my_linear\" function looks like      ggplot2::ggplot() +        ggplot2::geom_function(fun = itd_tuning_ans2$ws_fn_list$my_linear) +        ggplot2::xlim(-5,60) +        ggplot2::labs(x = \"heights\", y = \"ws\", color = \"\")  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/itd_ws_functions.html","id":null,"dir":"Reference","previous_headings":"","what":"Individual Tree Detection (ITD) functions — itd_ws_functions","title":"Individual Tree Detection (ITD) functions — itd_ws_functions","text":"itd_ws_functions() list functions can used determining variable window size detection individual trees. cloud2trees package performs individual tree detection using lidR::locate_trees() lidR::lmf() algorithm. local maximum filter algorithm allows constant window size variable window size defined function. See lidR package book excellent detail ITD defining window size.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/itd_ws_functions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Individual Tree Detection (ITD) functions — itd_ws_functions","text":"","code":"itd_ws_functions()"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/itd_ws_functions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Individual Tree Detection (ITD) functions — itd_ws_functions","text":"Returns list named functions can used pass desired function ws parameter raster2trees() /cloud2trees().","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/itd_ws_functions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Individual Tree Detection (ITD) functions — itd_ws_functions","text":"","code":"if (FALSE) { # \\dontrun{   # what is this?   itd_ws_functions() %>% class()   # is this list named?   itd_ws_functions() %>% names()   # what is the first thing in the list named?   itd_ws_functions()[1] %>% names()   # we can reference it by name   itd_ws_functions()[\"lin_fn\"] %>% names()   # how can we access a function?   itd_ws_functions()[\"exp_fn\"] %>% is.function() # still a list   itd_ws_functions()[[\"exp_fn\"]] %>% is.function() # now a function   itd_ws_functions() %>% purrr::pluck(\"exp_fn\") %>% is.function() # also now a function   # let's store it   def_exp_fn <- itd_ws_functions()[[\"exp_fn\"]]   # can we use it?   def_exp_fn(9)   # can we plot a function?   ggplot2::ggplot() +     ggplot2::geom_function(fun = itd_ws_functions()[[\"exp_fn\"]]) +     ggplot2::xlim(-1,60)   # can we plot all functions?   ggplot2::ggplot() +     ggplot2::geom_function(ggplot2::aes(color=\"lin_fn\"), fun = itd_ws_functions()[[\"lin_fn\"]]) +     ggplot2::geom_function(ggplot2::aes(color=\"exp_fn\"), fun = itd_ws_functions()[[\"exp_fn\"]]) +     ggplot2::geom_function(ggplot2::aes(color=\"log_fn\"), fun = itd_ws_functions()[[\"log_fn\"]]) +     ggplot2::xlim(-1,60)  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/ladderfuelsr_cbh.html","id":null,"dir":"Reference","previous_headings":"","what":"estimate CBH for a single tree using LadderFuelsR package — ladderfuelsr_cbh","title":"estimate CBH for a single tree using LadderFuelsR package — ladderfuelsr_cbh","text":"ladderfuelsr_cbh() --one function process height normalized .las|.laz files using functionality LadderFuelsR package. function returns list data.frame objects results different LadderFuelsR steps. Returns NULL process unable detect CBH point cloud. ladderfuelsr_cbh() outputs: order operations : Create data frame 3D voxels information (xyz) Leaf Area Density (LAD) values las file using leafR::lad.voxels() Calculate lad profile input lad.voxels using leafR::lad.profile() Calculate gaps fuel layers base height (FBH) difference percentiles consecutive LAD values along vertical tree profile (VTP) using LadderFuelsR::get_gaps_fbhs() Calculate percentile value fuel layer base height using LadderFuelsR::calculate_gaps_perc() Calculate distances (heights) fuel layers difference consecutive gaps fuel bases using LadderFuelsR::get_distance() Calculate fuels depth difference gaps interleaved fuel layers minus one step fuel depths greater one step using LadderFuelsR::get_depths() Reshape fuel layers removing distances equal number height bin steps, keeping first \"base height\" consecutive ones separated distance using LadderFuelsR::get_real_fbh() Recalculate fuel layers depth considering distances greater actual height bin step using LadderFuelsR::get_real_depths() Recalculate distance fuel layers considering distances greater number height bin steps using LadderFuelsR::get_effective_gap() Calculate percentage LAD within fuel layer (first output) removes fuel layers LAD percentage less specified threshold using LadderFuelsR::get_layers_lad() Determine CBH segmented tree using three criteria: maximum LAD percentage, maximum distance last distance using LadderFuelsR::get_cbh_metrics()","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/ladderfuelsr_cbh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"estimate CBH for a single tree using LadderFuelsR package — ladderfuelsr_cbh","text":"","code":"ladderfuelsr_cbh(   lad_profile_df = NULL,   las = NULL,   treeID = NA,   min_vhp_n = 4,   voxel_grain_size_m = 1,   dist_btwn_bins_m = 1,   min_fuel_layer_ht_m = 1,   lad_pct_gap = 25,   lad_pct_base = 25,   num_jump_steps = 1,   min_lad_pct = 10,   frst_layer_min_ht_m = 1 )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/ladderfuelsr_cbh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"estimate CBH for a single tree using LadderFuelsR package — ladderfuelsr_cbh","text":"lad_profile_df data.frame. return leafr_for_ladderfuelsr() data.frame must columns: treeID, lad, total_pulses, height. lad_profile_df las parameters defined, preference data.frame las string -- object. single tree .las|.laz file path -- object class LAS height normalized. treeID numeric. LadderFuelsR process requires treeID uniquely identifies points within tree , left NA process attempt locate treeID data based attribute point cloud data.frame numeric min_vhp_n numeric. minimum number vertical height profiles (VHPs) needed estimate CBH. voxel_grain_size_m numeric. used las parameter defined. horizontal resolution (suggested 1 meter lad profiles). See grain.size leafR::lad.voxels() dist_btwn_bins_m numeric. value actual height bin step (meters). See step LadderFuelsR::get_gaps_fbhs() min_fuel_layer_ht_m numeric. value actual minimum base height (meters). See min_height LadderFuelsR::get_gaps_fbhs() lad_pct_gap numeric. value percentile threshold used identify gaps (default percentile 25th). See perc_gap LadderFuelsR::get_gaps_fbhs() lad_pct_base numeric. value percentile threshold used identify fuels layers base height (default percentile 25th). See perc_base LadderFuelsR::get_gaps_fbhs() num_jump_steps numeric. value number height bin steps can jumped reshape fuels layers. See number_steps LadderFuelsR::get_real_fbh() min_lad_pct numeric. value minimum required LAD percentage fuel layer. See threshold LadderFuelsR::get_layers_lad() frst_layer_min_ht_m numeric. value depth height first fuel layer. first fuel layer maximum LAD depth greater indicated value , fuel layer considered CBH tree. contrary, depth <= value, CBH maximum LAD second fuel layer, although maximum LAD. See hdepth1_height LadderFuelsR::get_cbh_metrics()","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/ladderfuelsr_cbh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"estimate CBH for a single tree using LadderFuelsR package — ladderfuelsr_cbh","text":"Returns list data.frame objects results different LadderFuelsR steps. Returns NULL process unable detect CBH point cloud.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/ladderfuelsr_cbh.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"estimate CBH for a single tree using LadderFuelsR package — ladderfuelsr_cbh","text":"https://doi.org/10.1111/2041-210X.14427 Viedma, O., Silva, C. ., Moreno, J. M., & Hudak, . T. (2024). LadderFuelsR: new automated tool vertical fuel continuity analysis crown base height detection using light detection ranging. Methods Ecology Evolution. https://github.com/olgaviedma/LadderFuelsR https://doi.org/10.3390/rs11010092 Almeida, D. R. . D., Stark, S. C., Shao, G., Schietti, J., Nelson, B. W., Silva, C. ., ... & Brancalion, P. H. S. (2019). Optimizing remote detection tropical rainforest structure airborne lidar: Leaf area profile sensitivity pulse density spatial sampling. Remote Sensing, 11(1), 92. https://github.com/DRAAlmeida/leafR","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/ladderfuelsr_cbh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"estimate CBH for a single tree using LadderFuelsR package — ladderfuelsr_cbh","text":"","code":"if (FALSE) { # \\dontrun{  # polygon data  f <- system.file(package = \"cloud2trees\",\"extdata\",\"crowns_poly.gpkg\")  trees_poly <- sf::st_read(f)  # simplify polygons  trees_poly <- simplify_multipolygon_crowns(trees_poly)  # point cloud data  lf <- system.file(package = \"cloud2trees\",\"extdata\",\"norm_las\",\"RMNP_017_2018_normalize.las\")  las <- lidR::readLAS(lf)  las@data %>% dplyr::glimpse()  # polygon_attribute_to_las to attach treeID to las  las <- polygon_attribute_to_las(las, trees_poly, force_crs = T, attribute = \"treeID\")  las@data %>% dplyr::glimpse()  # get the lad profile for each treeID  lad_profile <- leafr_for_ladderfuelsr(      las      , voxel_grain_size_m = 1      , k = 1      , group_treeID = T      , relative = F    )  dplyr::glimpse(lad_profile)  # extract the CBH using ladderfuelsr_cbh()  # before we extract the CBH using ladderfuelsr_cbh(), treeID has to be numeric  lad_profile <- lad_profile %>%    dplyr::mutate(      treeID_backup = treeID, treeID = as.factor(treeID)    )  # for one tree  ladderfuelsr_cbh(      lad_profile_df = lad_profile      , treeID = lad_profile$treeID[1]    ) %>%    purrr::pluck(\"cbh_metrics\") %>%    dplyr::glimpse()  # we can map over multiple trees  cbhs <- lad_profile$treeID %>%    unique() %>%    .[1:22] %>%    purrr::map(\\(x) ladderfuelsr_cbh(        lad_profile_df = lad_profile        , treeID = x      ) %>%      purrr::pluck(\"cbh_metrics\")    ) %>%    dplyr::bind_rows()  dplyr::glimpse(cbhs)  ggplot2::ggplot(data = cbhs, mapping = ggplot2::aes(x=last_Hcbh)) +    ggplot2::geom_density()  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/lasr_chm.html","id":null,"dir":"Reference","previous_headings":"","what":"Create CHM and apply pits and spikes filling via lasR — lasr_chm","title":"Create CHM and apply pits and spikes filling via lasR — lasr_chm","text":"use lasR create CHM apply pits spikes filling raster based St-Onge 2008 (see reference).","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/lasr_chm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create CHM and apply pits and spikes filling via lasR — lasr_chm","text":"","code":"lasr_chm(   chm_file_name,   chm_res = 0.25,   min_height_m = 2,   max_height_m = 70,   lap_sz = 3 )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/lasr_chm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create CHM and apply pits and spikes filling via lasR — lasr_chm","text":"chm_file_name string. write CHM. chm_res numeric. desired resolution CHM produced meters. min_height_m numeric. Set minimum height (m) individual tree detection max_height_m numeric. Set maximum height (m) canopy height model lap_sz numeric. Size Laplacian filter kernel (integer value, pixels) lasR::pit_fill()","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/lasr_chm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create CHM and apply pits and spikes filling via lasR — lasr_chm","text":"lasR pipeline","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/lasr_chm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create CHM and apply pits and spikes filling via lasR — lasr_chm","text":"https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=81365288221f3ac34b51a82e2cfed8d58defb10e","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/lasr_dtm_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"use lasR to combine DTM and normalize step — lasr_dtm_norm","title":"use lasR to combine DTM and normalize step — lasr_dtm_norm","text":"Combining DTM normalize step using lasR functionality","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/lasr_dtm_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"use lasR to combine DTM and normalize step — lasr_dtm_norm","text":"","code":"lasr_dtm_norm(dtm_file_name, frac_for_tri = 1, dtm_res = 1, norm_accuracy = 2)"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/lasr_dtm_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"use lasR to combine DTM and normalize step — lasr_dtm_norm","text":"dtm_file_name string. write DTM. frac_for_tri numeric. fraction points used Delauny triangulation. dtm_res numeric. desired resolution DTM produced meters. norm_accuracy numeric. see chunk_las_catalog. Choose processing accuracy. accuracy_level = 1 uses DTM height normalize points accuracy_level = 2 uses triangulation high point density (20 pts/m2) height normalize points accuracy_level = 3 uses triangulation high point density (100 pts/m2) height normalize points","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/lasr_dtm_norm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"use lasR to combine DTM and normalize step — lasr_dtm_norm","text":"lasR pipeline","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/lasr_dtm_norm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"use lasR to combine DTM and normalize step — lasr_dtm_norm","text":"https://r-lidar.github.io/lidRbook/normalization.html https://github.com/r-lidar/lasR/issues/18#issuecomment-2027818414","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/lasr_pipeline.html","id":null,"dir":"Reference","previous_headings":"","what":"Create lasR package pipeline to process a las grid tile created via chunk_las_catalog() — lasr_pipeline","title":"Create lasR package pipeline to process a las grid tile created via chunk_las_catalog() — lasr_pipeline","text":"Create lasR package pipeline process las grid tile created via chunk_las_catalog()","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/lasr_pipeline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create lasR package pipeline to process a las grid tile created via chunk_las_catalog() — lasr_pipeline","text":"","code":"lasr_pipeline(   processing_grid_num = 1,   process_data,   keep_intrmdt = F,   dtm_res_m = 1,   chm_res_m = 0.25,   min_height = 2,   max_height = 70,   dtm_dir = getwd(),   chm_dir = getwd(),   classify_dir = getwd(),   normalize_dir = getwd() )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/lasr_pipeline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create lasR package pipeline to process a las grid tile created via chunk_las_catalog() — lasr_pipeline","text":"processing_grid_num numeric. processing_grid column data.frame created via chunk_las_catalog() process_data data.frame. data.frame created via chunk_las_catalog() keep_intrmdt logical. process writes intermediate data disk, keep intermediate files (classfied, normalized, stem las files)? dtm_res_m numeric. desired resolution DTM produced meters. chm_res_m numeric. desired resolution CHM produced meters. min_height numeric. Set minimum height (m) individual tree detection max_height numeric. Set maximum height (m) canopy height model dtm_dir string. path folder write tiled DTM files . chm_dir string. path folder write tiled CHM files . classify_dir string. path folder write classified .las files . normalize_dir string. path folder write normalized .las files .","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/lasr_pipeline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create lasR package pipeline to process a las grid tile created via chunk_las_catalog() — lasr_pipeline","text":"lasR pipeline answer list","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/lasr_pipeline.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create lasR package pipeline to process a las grid tile created via chunk_las_catalog() — lasr_pipeline","text":"https://r-lidar.github.io/lasR/index.html","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/leafr_for_ladderfuelsr.html","id":null,"dir":"Reference","previous_headings":"","what":"re-writes leafR steps to allow for treeID as input for ladderfuelsR or ladderfuelsr_cbh() — leafr_for_ladderfuelsr","title":"re-writes leafR steps to allow for treeID as input for ladderfuelsR or ladderfuelsr_cbh() — leafr_for_ladderfuelsr","text":"leafr_for_ladderfuelsr() re-write leafR::lad.voxels() leafR::lad.profile() : removes requirement use file written disk allows calculation LAD treeID attribute pass individual tree point clouds updates use latest lidR functionality removes use sp raster functions updates function tidy data manipulation","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/leafr_for_ladderfuelsr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"re-writes leafR steps to allow for treeID as input for ladderfuelsR or ladderfuelsr_cbh() — leafr_for_ladderfuelsr","text":"","code":"leafr_for_ladderfuelsr(   las,   voxel_grain_size_m = 1,   k = 1,   attribute = \"treeID\",   min_pulses = 0,   relative = FALSE )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/leafr_for_ladderfuelsr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"re-writes leafR steps to allow for treeID as input for ladderfuelsR or ladderfuelsr_cbh() — leafr_for_ladderfuelsr","text":"las object class LAS height normalized. voxel_grain_size_m numeric. horizontal resolution (suggested 1 meter lad profiles 10 meters LAI maps). See grain.size leafR::lad.voxels() k numeric. coefficient transform effective LAI real LAI (k = 1; effective LAI) attribute character. column name attribute group return LAD profile . Default \"treeID\". attribute (whatever defined ) must exist las data min_pulses numeric. minimum number pulses required return record attribute. set zero (default) leave data unfiltered. relative logical. produce lad profile relative total LAI values. Indicate using effective LAI value. set TRUE, lad value relative_lad; otherwise, lad value mean_lad","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/leafr_for_ladderfuelsr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"re-writes leafR steps to allow for treeID as input for ladderfuelsR or ladderfuelsr_cbh() — leafr_for_ladderfuelsr","text":"Returns data.frame can multiple treeIDs use input ladderfuelsr_cbh()","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/leafr_for_ladderfuelsr.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"re-writes leafR steps to allow for treeID as input for ladderfuelsR or ladderfuelsr_cbh() — leafr_for_ladderfuelsr","text":"https://doi.org/10.3390/rs11010092 Almeida, D. R. . D., Stark, S. C., Shao, G., Schietti, J., Nelson, B. W., Silva, C. ., ... & Brancalion, P. H. S. (2019). Optimizing remote detection tropical rainforest structure airborne lidar: Leaf area profile sensitivity pulse density spatial sampling. Remote Sensing, 11(1), 92. https://github.com/DRAAlmeida/leafR","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/leafr_for_ladderfuelsr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"re-writes leafR steps to allow for treeID as input for ladderfuelsR or ladderfuelsr_cbh() — leafr_for_ladderfuelsr","text":"","code":"if (FALSE) { # \\dontrun{  # polygon data  f <- system.file(package = \"cloud2trees\",\"extdata\",\"crowns_poly.gpkg\")  trees_poly <- sf::st_read(f)  # simplify polygons  trees_poly <- simplify_multipolygon_crowns(trees_poly)  # point cloud data  lf <- system.file(package = \"cloud2trees\",\"extdata\",\"norm_las\",\"RMNP_017_2018_normalize.las\")  las <- lidR::readLAS(lf)  las@data %>% dplyr::glimpse()  # polygon_attribute_to_las to attach treeID to las  las <- polygon_attribute_to_las(las, trees_poly, force_crs = T, attribute = \"treeID\")  las@data %>% dplyr::glimpse()  # get the lad profile for each treeID  lad_profile <- leafr_for_ladderfuelsr(      las      , voxel_grain_size_m = 1      , k = 1      , group_treeID = T      , relative = F    )  dplyr::glimpse(lad_profile)  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/polygon_attribute_to_las.html","id":null,"dir":"Reference","previous_headings":"","what":"function to attach polygon attribute to point cloud — polygon_attribute_to_las","title":"function to attach polygon attribute to point cloud — polygon_attribute_to_las","text":"polygon_attribute_to_las() function attach polygon attribute point cloud","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/polygon_attribute_to_las.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"function to attach polygon attribute to point cloud — polygon_attribute_to_las","text":"","code":"polygon_attribute_to_las(las, poly_df, attribute, force_crs = F)"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/polygon_attribute_to_las.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"function to attach polygon attribute to point cloud — polygon_attribute_to_las","text":"las object class LAS poly_df object class sf POLYGON geometry (use cloud2trees::simplify_multipolygon_crowns() first) attribute character. data attribute poly_df want spatially attach las (e.g. treeID) force_crs logical. turn force crs parameter confident data projection.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/polygon_attribute_to_las.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"function to attach polygon attribute to point cloud — polygon_attribute_to_las","text":"Returns LAS class object","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/polygon_attribute_to_las.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"function to attach polygon attribute to point cloud — polygon_attribute_to_las","text":"","code":"if (FALSE) { # \\dontrun{  # polygon data  f <- system.file(package = \"cloud2trees\",\"extdata\",\"crowns_poly.gpkg\")  trees_poly <- sf::st_read(f)  # simplify polygons  trees_poly <- simplify_multipolygon_crowns(trees_poly)  # point cloud data  lf <- system.file(package = \"cloud2trees\",\"extdata\",\"norm_las\",\"RMNP_017_2018_normalize.las\")  las <- lidR::readLAS(lf)  las@data %>% dplyr::glimpse()  # polygon_attribute_to_las to attach treeID to las  las <- polygon_attribute_to_las(las, trees_poly, force_crs = T, attribute = \"treeID\")  las@data %>% dplyr::glimpse()  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/raster2trees.html","id":null,"dir":"Reference","previous_headings":"","what":"Use a CHM raster to detect individual trees — raster2trees","title":"Use a CHM raster to detect individual trees — raster2trees","text":"raster2trees() --one function process CHM raster return spatial data frame tree crown polygons points. order operations : Perform individual tree detection using lidR::locate_trees() lidR::lmf() algorithm Delineate tree crowns using ForestTools::mcws() Note, function estimate DBH detected trees returns tree location, crown area, height information. estimate tree DBH detected tree heights see trees_dbh().","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/raster2trees.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use a CHM raster to detect individual trees — raster2trees","text":"","code":"raster2trees(   chm_rast,   outfolder,   ws = itd_ws_functions()[[\"log_fn\"]],   min_height = 2,   min_crown_area = 0.1,   tempdir = tempdir() )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/raster2trees.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use a CHM raster to detect individual trees — raster2trees","text":"chm_rast raster.  raster terra starsrepresenting canopy height model outfolder string. path folder write crown vector data ws numeric function. Length diameter moving window used detect local maxima units input data (usually meters). numeric fixed window size used. function, function determines size window given location canopy. default function takes height given pixel argument return desired size search window centered pixel. min_height numeric. Set minimum height (m) individual tree detection min_crown_area numeric. Set minimum crown area (m2) individual tree detection tempdir string. Directory write intermediate files. Intermediate files created large rasters big fit memory.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/raster2trees.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Use a CHM raster to detect individual trees — raster2trees","text":"Returns spatial data frame individual tree crown vectors detected using CHM. tree top point coordinates located tree_x tree_y columns. process also writes two .gpkg files outfolder directory: chm_detected_crowns.gpkg chm_detected_tree_tops.gpkg","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/raster2trees.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Use a CHM raster to detect individual trees — raster2trees","text":"https://r-lidar.github.io/lidRbook/itd.html","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/raster2trees.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Use a CHM raster to detect individual trees — raster2trees","text":"","code":"if (FALSE) { # \\dontrun{  f <- paste0(system.file(package = \"cloud2trees\"),\"/extdata/chm.tif\")  crowns_sf <- raster2trees(chm_rast = terra::rast(f), outfolder = tempdir())  crowns_sf %>% class()  crowns_sf %>% dplyr::glimpse()  crowns_sf %>% ggplot2::ggplot() + ggplot2::geom_sf(ggplot2::aes(fill=tree_height_m))  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/rf_tune_subsample.html","id":null,"dir":"Reference","previous_headings":"","what":"implements steps to mitigate very long run-times when tuning random forests models — rf_tune_subsample","title":"implements steps to mitigate very long run-times when tuning random forests models — rf_tune_subsample","text":"rf_tune_subsample() implements steps mitigate long run-times tuning random forests models. randomForest::tuneRF() enables model tuning searching optimal mtry parameter (number variables randomly sampled candidates split) using cross-validation approach. However, computational cost increases significantly number observations randomForest::tuneRF() performs cross-validation internally mtry value tries. 100,000+ observations, cross-validation runs involves building evaluating many random forest trees, making process time-consuming. computational cost random forests driven repeated tree building process, involves recursive partitioning, bootstrapping, feature subset selection. operations, performed massive datasets, result significant computational burden. rf_tune_subsample() remedies issues via: Reducing ntreeTry parameter smaller value. Tuning less precise, finish reasonable time. ntree parameter can increased final model. Subsampling. Uses smaller, representative subsample data (e.g., 10-20% data) find good mtry value subsample.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/rf_tune_subsample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"implements steps to mitigate very long run-times when tuning random forests models — rf_tune_subsample","text":"","code":"rf_tune_subsample(   predictors,   response,   threshold = 14444,   n_subsamples = 4,   ntree_try = 44,   step_factor = 1,   improve = 0.03 )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/rf_tune_subsample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"implements steps to mitigate very long run-times when tuning random forests models — rf_tune_subsample","text":"predictors data.frame. predictor variable (x) data response numeric. vector response variable (y) data. observations ordered match predictors threshold numeric. threshold number observations, observations exceed threshold, subsampling implemented n_subsamples numeric. number times subsample tune using randomForest::tuneRF(). common optimal mtry returned subsample iterations. ntree_try numeric. see randomForest::tuneRF() step_factor numeric. see randomForest::tuneRF() improve numeric. see randomForest::tuneRF()","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/rf_tune_subsample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"implements steps to mitigate very long run-times when tuning random forests models — rf_tune_subsample","text":"numeric value use mtry parameter randomForest::randomForest()","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/simplify_multipolygon_crowns.html","id":null,"dir":"Reference","previous_headings":"","what":"Simplify MULTIPOLYGON to POLYGON geometry in an sf class object — simplify_multipolygon_crowns","title":"Simplify MULTIPOLYGON to POLYGON geometry in an sf class object — simplify_multipolygon_crowns","text":"Function simplify MULTIPOLYGON geometry POLYGON geometry sf class object selecting largest segment MULTIPOLYGON","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/simplify_multipolygon_crowns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simplify MULTIPOLYGON to POLYGON geometry in an sf class object — simplify_multipolygon_crowns","text":"","code":"simplify_multipolygon_crowns(trees_poly)"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/simplify_multipolygon_crowns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simplify MULTIPOLYGON to POLYGON geometry in an sf class object — simplify_multipolygon_crowns","text":"trees_poly data.frame. data frame sf class POLYGON,MULTIPOLYGON geometry (see sf::st_geometry_type()) column treeID","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/simplify_multipolygon_crowns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simplify MULTIPOLYGON to POLYGON geometry in an sf class object — simplify_multipolygon_crowns","text":"sf class object data frame","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/simplify_multipolygon_crowns.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simplify MULTIPOLYGON to POLYGON geometry in an sf class object — simplify_multipolygon_crowns","text":"","code":"if (FALSE) { # \\dontrun{  f <- paste0(system.file(package = \"cloud2trees\"),\"/extdata/crowns_poly.gpkg\")  crowns <- sf::st_read(f, quiet = T)  crowns %>% sf::st_geometry_type() %>% table()  crowns_simp <- simplify_multipolygon_crowns(crowns)  crowns_simp %>% sf::st_geometry_type() %>% table()  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/treels_stem_dbh.html","id":null,"dir":"Reference","previous_headings":"","what":"detect tree stems and estimate DBH using TreeLS package — treels_stem_dbh","title":"detect tree stems and estimate DBH using TreeLS package — treels_stem_dbh","text":"treels_stem_dbh() --one function process height normalized .las|.laz files using functionality TreeLS package. function generates list stems estimates DBH directly point cloud. treels_stem_dbh() outputs: .laz file Classification data updated : ground points (class 2); water points (class 9); stem points (class 4); non-stem (class 5). vector data file gpkg format tree identification stem locations, heights, DBH estimates. order operations : Detect tree stems/boles height normalized point cloud using TreeLS::treeMap() TreeLS::map.hough()  algorithm Merge overlapping tree coordinates using TreeLS::treeMap.merge() Assign tree IDs original points using TreeLS::treePoints() TreeLS::trp.crop() algorithm Flag stem points using TreeLS::stemPoints() TreeLS::stm.hough() algorithm Perform DBH estimation using TreeLS::tlsInventory() TreeLS::shapeFit() algorithm","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/treels_stem_dbh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"detect tree stems and estimate DBH using TreeLS package — treels_stem_dbh","text":"","code":"treels_stem_dbh(   folder,   outfolder,   min_height = 2,   max_dbh = 2,   chunk_these = FALSE )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/treels_stem_dbh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"detect tree stems and estimate DBH using TreeLS package — treels_stem_dbh","text":"folder string. path folder containing set las/laz files. Can also vector file paths. outfolder string. path folder write tiled vector files min_height numeric. Set minimum height (m) individual tree detection max_dbh numeric. Set largest tree diameter (m) expected point cloud chunk_these logical. las/laz files need tiled work smaller subsets? See is_chunked_grid chunk_las_catalog()","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/treels_stem_dbh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"detect tree stems and estimate DBH using TreeLS package — treels_stem_dbh","text":"Returns sf data.frame TreeLS detected trees DBH estimated directly point cloud. Exports files outfolder defined user function call.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/treels_stem_dbh.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"detect tree stems and estimate DBH using TreeLS package — treels_stem_dbh","text":"https://github.com/tiagodc/TreeLS","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/treels_stem_dbh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"detect tree stems and estimate DBH using TreeLS package — treels_stem_dbh","text":"","code":"if (FALSE) { # \\dontrun{  o <- \"../data\"  i <- \"../data/normlasdata\"  r <- cloud2trees::treels_stem_dbh(folder = i, outfolder = o)  r %>% names()  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_biomass.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate tree biomass (or crown biomass) for a tree list — trees_biomass","title":"Estimate tree biomass (or crown biomass) for a tree list — trees_biomass","text":"trees_biomass() streamlines process estimating individual tree biomass kilograms, component biomass tree crown kilograms. Users can select one following methods available package estimating biomass: Tree crown biomass kilograms: \"landfire\" - based LANDFIRE's Forest Canopy Bulk Density (CBD) data (trees_biomass_landfire()) \"cruz\" - based Cruz et al. (2003) canopy fuel stratum equations (trees_biomass_cruz()) Tree total ground biomass kilograms: coming soon multiple methods selected (e.g. method = c(\"cruz\",\"landfire\")), program compile biomass estimates return one tree list.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_biomass.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate tree biomass (or crown biomass) for a tree list — trees_biomass","text":"","code":"trees_biomass(   tree_list,   crs = NA,   study_boundary = NA,   input_landfire_dir = NULL,   input_foresttype_dir = NULL,   method = NA,   max_crown_kg_per_m3 = 2 )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_biomass.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate tree biomass (or crown biomass) for a tree list — trees_biomass","text":"tree_list data.frame. data frame columns treeID, tree_x, tree_y. sf class object POINT geometry (see sf::st_geometry_type()), program use data \"-\" require treeID column. required columns include: crown_area_m2, tree_height_m (e.g. exported raster2trees()) tree_cbh_m (e.g. exported trees_cbh()) one dbh_cm, dbh_m,  basal_area_m2 (e.g. exported trees_dbh()) crs string. crs string returned sf::st_crs() EPSG code x,y coordinates. Defaults crs tree_list data class \"sf\". study_boundary sf. boundary study area define area interest may extend beyond space trees. boundary given, AOI built location trees tree list. input_landfire_dir directory LANDFIRE CBD data exists. Use get_landfire() first. input_foresttype_dir directory Forest Type Groups data exists. Use get_foresttype() first. method character. one (e.g. \"landfire\") multiple (e.g. c(\"cruz\",\"landfire\")) following biomass estimation methods: Tree crown biomass kilograms: \"landfire\" - based LANDFIRE's Forest Canopy Bulk Density (CBD) data (trees_biomass_landfire()) \"cruz\" - based Cruz et al. (2003) canopy fuel stratum equations (trees_biomass_cruz()) Tree total ground biomass kilograms: coming soon max_crown_kg_per_m3 numeric. maximum CBD tree crown kilograms per cubic meter. Values limit set median value area using stands CBD values lower limit. default value 2 kilograms per cubic meter based Mell et al. (2009) found dry bulk density tree crown 2.6 kilograms per cubed meter using Douglas-fir trees grown Christmas tree farms. Set parameter large value (e.g. 1e10) NULL avoid limiting tree crown CBD.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_biomass.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate tree biomass (or crown biomass) for a tree list — trees_biomass","text":"Returns list objects: tree_list = spatial data frame individual trees ; stand_cell_data_landfire = data frame stands/cells projection LANDFIRE raster data ; stand_cell_data_cruz = data frame stands/cells projection FIA forest type group raster data See code examples.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_biomass.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate tree biomass (or crown biomass) for a tree list — trees_biomass","text":"See references : trees_biomass_landfire() trees_biomass_cruz()","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_biomass.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate tree biomass (or crown biomass) for a tree list — trees_biomass","text":"","code":"if (FALSE) { # \\dontrun{ library(tidyverse) library(sf) # use the tree list that ships with the package f <- system.file(package = \"cloud2trees\", \"extdata\", \"crowns_poly.gpkg\") tl <- sf::st_read(f) tl %>% dplyr::glimpse() # call trees_biomass and get multiple biomass estimates trees_biomass_ans <- trees_biomass(tree_list = tl, method = c(\"landfire\",\"cruz\")) # what did we get back? trees_biomass_ans %>% names() # check out the tree list trees_biomass_ans$tree_list %>% dplyr::glimpse() # check out the landfire stand data trees_biomass_ans$stand_cell_data_landfire %>% dplyr::filter(trees>0) %>% dplyr::glimpse() # plot tree landfire crown biomass estimate trees_biomass_ans$tree_list %>%   ggplot2::ggplot(     mapping = ggplot2::aes(       x = tree_height_m       , y = landfire_crown_biomass_kg       , color = crown_area_m2     )   ) +   ggplot2::geom_point() # plot tree cruz crown biomass estimate trees_biomass_ans$tree_list %>%   ggplot2::ggplot(     mapping = ggplot2::aes(       x = tree_height_m       , y = cruz_crown_biomass_kg       , color = crown_area_m2     )   ) +   ggplot2::geom_point() # plot tree landfire vs. cruz crown biomass estimate trees_biomass_ans$tree_list %>%   ggplot2::ggplot(     mapping = ggplot2::aes(       x = landfire_crown_biomass_kg, y = cruz_crown_biomass_kg     )   ) +   ggplot2::geom_abline(lwd = 1.5) +   ggplot2::geom_smooth(method = \"lm\", se=F, color = \"gray\", linetype = \"dashed\") +   ggplot2::geom_point(ggplot2::aes(color = tree_height_m)) +   ggplot2::scale_x_continuous(     limits = c(0       , max(trees_biomass_ans$tree_list$cruz_crown_biomass_kg)     )   ) +   ggplot2::scale_y_continuous(     limits = c(0       , max(trees_biomass_ans$tree_list$cruz_crown_biomass_kg)     )   ) # get the projection for the stand cell data epsg_code <- trees_biomass_ans$stand_cell_data_landfire$rast_epsg_code[1] %>% as.numeric() # plot the stand cell data with trees overlaid trees_biomass_ans$stand_cell_data_landfire %>%   dplyr::filter(trees>0) %>%   ggplot2::ggplot() +   ggplot2::geom_tile(ggplot2::aes(x=x,y=y,fill = landfire_stand_kg_per_m3), color = \"gray44\") +   ggplot2::geom_text(ggplot2::aes(x=x,y=y,label = trees), color = \"white\") +   ggplot2::geom_sf(     data = trees_biomass_ans$tree_list %>% sf::st_transform(crs = epsg_code)     , ggplot2::aes(color = cruz_crown_biomass_kg)   ) +   ggplot2::labs(     fill=\"stand kg/m3\", color = \"landfire\\ncrown kg\"     , caption = \"# trees shown in cell\"   ) +   ggplot2::scale_fill_viridis_c(option = \"rocket\", na.value = \"gray\", direction = -1) +   ggplot2::scale_color_viridis_c(option = \"viridis\", na.value = \"gray22\", begin = 0.6) +   ggplot2::theme_void()  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_biomass_cruz.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate tree crown biomass for a tree list based on Cruz et al. (2003) — trees_biomass_cruz","title":"Estimate tree crown biomass for a tree list based on Cruz et al. (2003) — trees_biomass_cruz","text":"trees_biomass_cruz() uses input tree list (e.g. exported raster2trees()) columns treeID, tree_x, tree_y attempt attach tree crown biomass kilogram estimates based Cruz et al. (2003) equations (see references) FIA forest type group. spatial data frame points input tree list, columns tree_x, tree_y required. FIA forest type group data named forest_type_group_codeis input tree list, function calls trees_type() attempt attach FIA forest type group. required columns include: crown_area_m2, tree_height_m (e.g. exported raster2trees()) tree_cbh_m (e.g. exported trees_cbh()) one dbh_cm, dbh_m,  basal_area_m2 (e.g. exported trees_dbh()) Cruz et al. (2003) study developed models predict canopy fuel stratum stand level four coniferous forest types common western US: Douglas-fir, ponderosa pine, lodgepole pine, mixed conifer. Models forests types currently lacking limits scope methodology. tree list trees FIA forest type group represented list , return data blank Canopy Bulk Density mass flammable material per unit volume tree crown typically expressed units mass per unit volume (e.g., kilograms per cubic meter). process estimating tree crown biomass kilograms : Nearest neighbor imputation used fill FIA forest type data tree falls inside non-forest cell original data LANDFIRE estimate CBD distributed across individual trees fall raster cell : stand level (.e. raster cell), aggregate tree level data within stand obtain: mean_crown_length_m = mean(crown_length_m), tree crown_length_m = tree_height_m - tree_cbh_m sum_crown_volume_m3 = sum(crown_volume_m3), tree crown_volume_m3 = (4/3) * pi * ((crown_length_m/2)) * ((crown_dia_m/2)^2) stand level (.e. raster cell), determine area stand overlaps (overlap_area_m2) AOI defined study_boundary parameter (see ) bounding box trees stand level (.e. raster cell), use Cruz equations (Table 4; see reference) estimate CBD kilograms per cubic meter (cruz_stand_kg_per_m3) stand level (.e. raster cell), get canopy fuel loading (CFL) kilograms per square meter (kg_per_m2 = mean_crown_length_m * cruz_stand_kg_per_m3) stand level (.e. raster cell), get stand biomass kilograms (biomass_kg = kg_per_m2 * overlap_area_m2) stand level (.e. raster cell), single tree CBD kilograms per cubic meter constant (cruz_tree_kg_per_m3 = biomass_kg / sum_crown_volume_m3) Attach single tree CBD kilograms per cubic meter tree level based raster cell spatial overlap Calculate individual tree crown mass kilograms cruz_crown_biomass_kg = cruz_tree_kg_per_m3 * crown_volume_m3","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_biomass_cruz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate tree crown biomass for a tree list based on Cruz et al. (2003) — trees_biomass_cruz","text":"","code":"trees_biomass_cruz(   tree_list,   crs = NA,   study_boundary = NA,   input_foresttype_dir = NULL,   max_crown_kg_per_m3 = 2 )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_biomass_cruz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate tree crown biomass for a tree list based on Cruz et al. (2003) — trees_biomass_cruz","text":"tree_list data.frame. data frame columns treeID, tree_x, tree_y. sf class object POINT geometry (see sf::st_geometry_type()), program use data \"-\" require treeID column. required columns include: crown_area_m2, tree_height_m (e.g. exported raster2trees()) tree_cbh_m (e.g. exported trees_cbh()) one dbh_cm, dbh_m,  basal_area_m2 (e.g. exported trees_dbh()) crs string. crs string returned sf::st_crs() EPSG code x,y coordinates. Defaults crs tree_list data class \"sf\". study_boundary sf. boundary study area define area interest may extend beyond space trees. boundary given, AOI built location trees tree list. input_foresttype_dir directory Forest Type Groups data exists. Use get_foresttype() first. max_crown_kg_per_m3 numeric. maximum CBD tree crown kilograms per cubic meter. Values limit set median value area using stands CBD values lower limit. default value 2 kilograms per cubic meter based Mell et al. (2009) found dry bulk density tree crown 2.6 kilograms per cubed meter using Douglas-fir trees grown Christmas tree farms. Set parameter large value (e.g. 1e10) NULL avoid limiting tree crown CBD.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_biomass_cruz.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate tree crown biomass for a tree list based on Cruz et al. (2003) — trees_biomass_cruz","text":"Returns list objects: tree_list = spatial data frame individual trees ; stand_cell_data = data frame stands/cells projection FIA forest type group raster data See code examples.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_biomass_cruz.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate tree crown biomass for a tree list based on Cruz et al. (2003) — trees_biomass_cruz","text":"Forest Type Groups Continental United States Wilson, B.T. (2023). Forest Type Groups Continental United States. doi:10.1071/WF02024 Cruz, M.G, M.E. Alexander, R.H. Wakimoto. 2003. Assessing canopy fuel stratum characteristics crown fire prone fuel types western North America. Int. J. Wildland Fire. 12(1):39-50. https://doi.org/10.1016/j.combustflame.2009.06.015 Mell, W., Maranghides, ., McDermott, R., & Manzello, S. L. (2009). Numerical simulation experiments burning douglas fir trees. Combustion Flame, 156(10), 2023-2041.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_biomass_cruz.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate tree crown biomass for a tree list based on Cruz et al. (2003) — trees_biomass_cruz","text":"","code":"if (FALSE) { # \\dontrun{ library(tidyverse) library(sf) my_n <- 111 # fake tree list tl <- dplyr::tibble(     treeID = c(1:my_n)     , tree_x = rnorm(n=my_n, mean = 458064, sd = 33)     , tree_y = rnorm(n=my_n, mean = 4450074, sd = 33)     , tree_height_m = rnorm(n=my_n, mean = 10, sd = 7)   ) %>%   dplyr::mutate(     tree_height_m = ifelse(tree_height_m<1.37, 1.37, tree_height_m) # above DBH     , crown_area_m2 = 0.47+(0.49*tree_height_m)     , tree_cbh_m = 0.72+(0.53*tree_height_m)     , dbh_cm = -2.3+(2.14*tree_height_m)   ) # how does our fake tree list look? tl %>% dplyr::glimpse() tl %>% ggplot2::ggplot() + ggplot2::geom_point(ggplot2::aes(x = dbh_cm, y = tree_height_m)) # call the function tl_cruz <- trees_biomass_cruz(tree_list = tl, crs = \"32613\") # what is in it? tl_cruz %>% names() # look at the trees tl_cruz$tree_list %>% dplyr::glimpse() # tree FIA forest type groups tl_cruz$tree_list %>%   sf::st_drop_geometry() %>%   dplyr::count(forest_type_group_code, forest_type_group) # look at the stand tl_cruz$stand_cell_data %>% dplyr::filter(!is.na(trees)) %>% dplyr::glimpse() # get the projection for the stand cell data epsg_code <- tl_cruz$stand_cell_data$rast_epsg_code[1] %>% as.numeric()  # plot the stand cell data with trees overlaid  tl_cruz$stand_cell_data %>%    ggplot2::ggplot() +    ggplot2::geom_tile(ggplot2::aes(x=x,y=y,fill = cruz_stand_kg_per_m3), color = \"gray44\") +    ggplot2::geom_text(ggplot2::aes(x=x,y=y,label = trees), color = \"white\") +    ggplot2::geom_sf(      data = tl_cruz$tree_list %>% sf::st_transform(crs = epsg_code)      , ggplot2::aes(color = cruz_crown_biomass_kg)    ) +    ggplot2::labs(fill=\"stand kg/m3\", color = \"tree crown kg\", caption = \"# trees shown in cell\") +    ggplot2::scale_fill_viridis_c(option = \"rocket\", na.value = \"gray\", direction = -1) +    ggplot2::scale_color_viridis_c(option = \"viridis\", na.value = \"gray22\", begin = 0.6) +    ggplot2::theme_void()  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_biomass_landfire.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate tree crown biomass for a tree list using LANDFIRE data — trees_biomass_landfire","title":"Estimate tree crown biomass for a tree list using LANDFIRE data — trees_biomass_landfire","text":"trees_biomass_landfire() uses input tree list (e.g. exported raster2trees()) columns treeID, tree_x, tree_y attach estimate tree crown biomass using LANDFIRE's Forest Canopy Bulk Density (CBD) data produced jointly U.S. Department Agriculture U.S. Department Interior. spatial data frame points input tree list, columns tree_x, tree_y required. required columns include: crown_area_m2, tree_height_m (e.g. exported raster2trees()) tree_cbh_m (e.g. exported trees_cbh()) one dbh_cm, dbh_m,  basal_area_m2 (e.g. exported trees_dbh()) LANDFIRE's Forest Canopy Bulk Density (CBD) data attached tree tree list based spatial overlap raster data set (see references). Canopy Bulk Density mass flammable material per unit volume tree crown typically expressed units mass per unit volume (e.g., kilograms per cubic meter). process estimating tree crown biomass kilograms : Nearest neighbor imputation used fill LANDFIRE data tree falls inside non-forest cell original data LANDFIRE estimate CBD distributed across individual trees fall raster cell : stand level (.e. raster cell), aggregate tree level data within stand obtain: mean_crown_length_m = mean(crown_length_m), tree crown_length_m = tree_height_m - tree_cbh_m sum_crown_volume_m3 = sum(crown_volume_m3), tree crown_volume_m3 = (4/3) * pi * ((crown_length_m/2)) * ((crown_dia_m/2)^2) stand level (.e. raster cell), determine area stand overlaps (overlap_area_m2) AOI defined study_boundary parameter (see ) bounding box trees stand level (.e. raster cell), get LANDFIRE estimate CBD kilograms per cubic meter (landfire_stand_kg_per_m3) stand level (.e. raster cell), get canopy fuel loading (CFL) kilograms per square meter (kg_per_m2 = mean_crown_length_m * landfire_stand_kg_per_m3) stand level (.e. raster cell), get stand biomass kilograms (biomass_kg = kg_per_m2 * overlap_area_m2) stand level (.e. raster cell), single tree CBD kilograms per cubic meter constant (landfire_tree_kg_per_m3 = biomass_kg / sum_crown_volume_m3) Attach single tree CBD kilograms per cubic meter tree level based raster cell spatial overlap Calculate individual tree crown mass kilograms landfire_crown_biomass_kg = landfire_tree_kg_per_m3 * crown_volume_m3","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_biomass_landfire.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate tree crown biomass for a tree list using LANDFIRE data — trees_biomass_landfire","text":"","code":"trees_biomass_landfire(   tree_list,   crs = NA,   study_boundary = NA,   input_landfire_dir = NULL,   max_crown_kg_per_m3 = 2 )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_biomass_landfire.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate tree crown biomass for a tree list using LANDFIRE data — trees_biomass_landfire","text":"tree_list data.frame. data frame columns treeID, tree_x, tree_y. sf class object POINT geometry (see sf::st_geometry_type()), program use data \"-\" require treeID column. required columns include: crown_area_m2, tree_height_m (e.g. exported raster2trees()) tree_cbh_m (e.g. exported trees_cbh()) one dbh_cm, dbh_m,  basal_area_m2 (e.g. exported trees_dbh()) crs string. crs string returned sf::st_crs() EPSG code x,y coordinates. Defaults crs tree_list data class \"sf\". study_boundary sf. boundary study area define area interest may extend beyond space trees. boundary given, AOI built location trees tree list. input_landfire_dir directory LANDFIRE CBD data exists. Use get_landfire() first. max_crown_kg_per_m3 numeric. maximum CBD tree crown kilograms per cubic meter. Values limit set median value area using stands CBD values lower limit. default value 2 kilograms per cubic meter based Mell et al. (2009) found dry bulk density tree crown 2.6 kilograms per cubed meter using Douglas-fir trees grown Christmas tree farms. Set parameter large value (e.g. 1e10) NULL avoid limiting tree crown CBD.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_biomass_landfire.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate tree crown biomass for a tree list using LANDFIRE data — trees_biomass_landfire","text":"Returns list objects: tree_list = spatial data frame individual trees ; stand_cell_data = data frame stands/cells projection LANDFIRE raster data See code examples.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_biomass_landfire.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate tree crown biomass for a tree list using LANDFIRE data — trees_biomass_landfire","text":"LANDFIRE Forest Canopy Bulk Density (CBD) U.S. Department Agriculture U.S. Department Interior. https://doi.org/10.1016/j.combustflame.2009.06.015 Mell, W., Maranghides, ., McDermott, R., & Manzello, S. L. (2009). Numerical simulation experiments burning douglas fir trees. Combustion Flame, 156(10), 2023-2041.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_biomass_landfire.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate tree crown biomass for a tree list using LANDFIRE data — trees_biomass_landfire","text":"","code":"if (FALSE) { # \\dontrun{ library(tidyverse) library(sf) my_n <- 122 # fake tree list tl <- dplyr::tibble(     treeID = c(1:my_n)     , tree_x = rnorm(n=my_n, mean = 458064, sd = 33)     , tree_y = rnorm(n=my_n, mean = 4450074, sd = 33)     , tree_height_m = rnorm(n=my_n, mean = 10, sd = 7)   ) %>%   dplyr::mutate(     tree_height_m = ifelse(tree_height_m<1.37, 1.37, tree_height_m) # above DBH     , crown_area_m2 = 0.47+(0.49*tree_height_m)     , tree_cbh_m = 0.72+(0.53*tree_height_m)     , dbh_cm = -2.3+(2.14*tree_height_m)   ) # how does our fake tree list look? tl %>% dplyr::glimpse() tl %>% ggplot2::ggplot() + ggplot2::geom_point(ggplot2::aes(x = dbh_cm, y = tree_height_m)) # call the function tl_landfire <- trees_biomass_landfire(tree_list = tl, crs = \"32613\") # what is in it? tl_landfire %>% names() # look at the trees tl_landfire$tree_list %>% dplyr::glimpse() # look at the stand tl_landfire$stand_cell_data %>% dplyr::filter(!is.na(trees)) %>% dplyr::glimpse() # the stand CBD  tl_landfire$stand_cell_data %>%    dplyr::filter(trees>0) %>%    sf::st_drop_geometry() %>%    dplyr::count(landfire_stand_kg_per_m3) # get the projection for the stand cell data epsg_code <- tl_landfire$stand_cell_data$rast_epsg_code[1] %>% as.numeric() # plot the stand cell data with trees overlaid tl_landfire$stand_cell_data %>%   ggplot2::ggplot() +   ggplot2::geom_tile(ggplot2::aes(x=x,y=y,fill = landfire_stand_kg_per_m3), color = \"gray44\") +   ggplot2::geom_text(ggplot2::aes(x=x,y=y,label = trees), color = \"white\") +   ggplot2::geom_sf(     data = tl_landfire$tree_list %>% sf::st_transform(crs = epsg_code)     , ggplot2::aes(color = landfire_crown_biomass_kg)   ) +   ggplot2::labs(fill=\"stand kg/m3\", color = \"tree crown kg\", caption = \"# trees shown in cell\") +   ggplot2::scale_fill_viridis_c(option = \"rocket\", na.value = \"gray\", direction = -1) +   ggplot2::scale_color_viridis_c(option = \"viridis\", na.value = \"gray22\", begin = 0.6) +   ggplot2::theme_void()  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_cbh.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate CBH using tree crown polygons and normalized point cloud data — trees_cbh","title":"Estimate CBH using tree crown polygons and normalized point cloud data — trees_cbh","text":"trees_cbh() uses input tree crown polygons (e.g. exported raster2trees()) columns treeID tree_height_m estimate tree CBH using height normalized point cloud data (e.g. exported cloud2raster()). CBH extracted directly height normalized point cloud using process outlined Viedma et al. (2024) implemented via ladderfuelsr_cbh(). likely trees insufficient data point cloud successfully estimate CBH. user can elect estimate missing CBH values accomplished via: Attempt extract CBH sample trees elected user (tree_sample_n,tree_sample_prop parameter) using ladderfuelsr_cbh() Successfully extracted CBH trees become training data used estimate height-CBH allometry relationship spatially informed using relative tree location compared training data height location predicting CBH model built point cloud training data used predict CBH non-training (.e. missing CBH) data","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_cbh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate CBH using tree crown polygons and normalized point cloud data — trees_cbh","text":"","code":"trees_cbh(   trees_poly,   norm_las = NULL,   tree_sample_n = NA,   tree_sample_prop = NA,   which_cbh = \"lowest\",   estimate_missing_cbh = TRUE,   min_vhp_n = 3,   voxel_grain_size_m = 1,   dist_btwn_bins_m = 1,   min_fuel_layer_ht_m = 1,   lad_pct_gap = 25,   lad_pct_base = 25,   num_jump_steps = 1,   min_lad_pct = 10,   frst_layer_min_ht_m = 1,   force_same_crs = F,   outfolder = tempdir() )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_cbh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate CBH using tree crown polygons and normalized point cloud data — trees_cbh","text":"trees_poly must one following required attributes treeID tree_height_m: sf class object POLYGON geometry (see sf::st_geometry_type()). Recommended smaller tree lists (e.g. <100k) can fit memory. character vector path single multiple spatial files can read sf::st_read() POLYGON geometry. Recommended large tree lists (e.g. 100k+) might cause memory issues. character path directory \"final_detected_crowns*\" files cloud2trees() raster2trees(). Recommended large tree lists (e.g. 100k+) might cause memory issues. norm_las character. directory nomalized las files, path single .laz|.las file\", -- object class LAS. responsibility ensure point cloud projected trees_poly data tree_sample_n, tree_sample_prop numeric. Provide either tree_sample_n, number trees, tree_sample_prop, proportion trees attempt extract CBH point cloud . neither supplied, tree_sample_n = 333 used. supplied, tree_sample_n used. Increasing tree_sample_prop toward one (1) increase processing time, perhaps significantly depending number trees trees_poly data. which_cbh character. One : \"lowest\"; \"highest\"; \"max_lad\". See Viedma et al. (2024) reference. \"lowest\" - Height CBH segmented tree based last distance found profile \"highest\" - Height CBH segmented tree based maximum distance found profile \"max_lad\" - Height CBH segmented tree based maximum LAD percentage estimate_missing_cbh logical. even tree_sample_prop parameter set \"1\", likely CBH extracted successfully every tree. missing CBH values estimated using tree height location information based trees CBH successfully extracted? min_vhp_n numeric. minimum number vertical height profiles (VHPs) needed estimate CBH. voxel_grain_size_m numeric. horizontal resolution (suggested 1 meter lad profiles 10 meters LAI maps). See grain.size leafR::lad.voxels() dist_btwn_bins_m numeric. value actual height bin step (meters). See step LadderFuelsR::get_gaps_fbhs() min_fuel_layer_ht_m numeric. value actual minimum base height (meters). See min_height LadderFuelsR::get_gaps_fbhs() lad_pct_gap numeric. value percentile threshold used identify gaps (default percentile 25th). See perc_gap LadderFuelsR::get_gaps_fbhs() lad_pct_base numeric. value percentile threshold used identify fuels layers base height (default percentile 25th). See perc_base LadderFuelsR::get_gaps_fbhs() num_jump_steps numeric. value number height bin steps can jumped reshape fuels layers. See number_steps LadderFuelsR::get_real_fbh() min_lad_pct numeric. value minimum required LAD percentage fuel layer. See threshold LadderFuelsR::get_layers_lad() frst_layer_min_ht_m numeric. value depth height first fuel layer. first fuel layer maximum LAD depth greater indicated value, fuel layer considered CBH tree. contrary, depth <= value, CBH maximum LAD second fuel layer, although maximum LAD. See hdepth1_height LadderFuelsR::get_cbh_metrics() force_same_crs logical. force crs point cloud polygon confident data projection. data created cloud2trees pipeline (e.g. cloud2raster()) always projection even recognized lidR functions outfolder string. path folder write model data . Note, actual missing value estimation many RF models estimated model averaging used. However, first estimated model saved export fully represent process used fill missing values.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_cbh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate CBH using tree crown polygons and normalized point cloud data — trees_cbh","text":"Returns spatial data frame individual trees.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_cbh.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate CBH using tree crown polygons and normalized point cloud data — trees_cbh","text":"https://doi.org/10.1111/2041-210X.14427 Viedma, O., Silva, C. ., Moreno, J. M., & Hudak, . T. (2024). LadderFuelsR: new automated tool vertical fuel continuity analysis crown base height detection using light detection ranging. Methods Ecology Evolution. https://github.com/olgaviedma/LadderFuelsR https://doi.org/10.3390/rs11010092 Almeida, D. R. . D., Stark, S. C., Shao, G., Schietti, J., Nelson, B. W., Silva, C. ., ... & Brancalion, P. H. S. (2019). Optimizing remote detection tropical rainforest structure airborne lidar: Leaf area profile sensitivity pulse density spatial sampling. Remote Sensing, 11(1), 92. https://github.com/DRAAlmeida/leafR","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_cbh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate CBH using tree crown polygons and normalized point cloud data — trees_cbh","text":"","code":"if (FALSE) { # \\dontrun{  library(tidyverse)  library(sf)  # example tree crown polygons  f <- system.file(package = \"cloud2trees\",\"extdata\",\"crowns_poly.gpkg\")  crowns <- sf::st_read(f, quiet = T)  # example normalized las files are in this directory  norm_d <- system.file(package = \"cloud2trees\",\"extdata\",\"norm_las\")  # now run the trees_cbh()  trees_cbh_ans <- trees_cbh(     trees_poly = crowns     , norm_las = norm_d     , tree_sample_n = 44     , estimate_missing_cbh = T     , force_same_crs = T    )  # what?  trees_cbh_ans %>% class()  trees_cbh_ans %>% dplyr::select(treeID,tidyselect::contains(\"cbh\")) %>% dplyr::glimpse()  # spatial polygons  trees_cbh_ans %>% ggplot2::ggplot() +    ggplot2::geom_sf(ggplot2::aes(fill=tree_cbh_m,color=is_training_cbh))  # relationship between height and cbh  trees_cbh_ans %>%     ggplot2::ggplot(       ggplot2::aes(x = tree_height_m, y = tree_cbh_m, color=is_training_cbh)      ) +     ggplot2::geom_point()  # tabulate training data  trees_cbh_ans %>%    sf::st_drop_geometry() %>%    dplyr::count(is_training_cbh)  #### try a file list  #### Recommended for large tree lists (e.g. 100k+) that might cause memory issues.  # we'll split the crowns  # as is done automatically for tree lists >250k by raster2trees() and cloud2trees()  crowns <- crowns %>%    dplyr::mutate(      # makes 2 groups of data      grp = ceiling(dplyr::row_number()/(dplyr::n()/2))    )  # make file names  my_dir <- tempdir()  fnm_1 <- file.path(my_dir, \"crowns1.gpkg\")  fnm_2 <- file.path(my_dir, \"crowns2.gpkg\")  fnm_1  # write the data  sf::st_write(crowns %>% dplyr::filter(grp==1), dsn = fnm_1, append = F) # grp 1  sf::st_write(crowns %>% dplyr::filter(grp==2), dsn = fnm_2, append = F) # grp 2  # try trees_cbh with our file list  flist <- c(fnm_1,fnm_2)  # now run the trees_cbh()  trees_cbh_ans2 <- trees_cbh(   trees_poly = flist   , norm_las = norm_d   , tree_sample_n = 44   , estimate_missing_cbh = T   , force_same_crs = T  )  # tabulate training data  trees_cbh_ans2 %>%    sf::st_drop_geometry() %>%    dplyr::count(is_training_cbh)  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_cbh_sf.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate CBH using tree crown polygons and normalized point cloud data — trees_cbh_sf","title":"Estimate CBH using tree crown polygons and normalized point cloud data — trees_cbh_sf","text":"trees_cbh_sf() uses input tree crown polygons (e.g. exported raster2trees()) columns treeID tree_height_m estimate tree CBH using height normalized point cloud data (e.g. exported cloud2raster()). CBH extracted directly height normalized point cloud using process outlined Viedma et al. (2024) implemented via ladderfuelsr_cbh(). likely trees insufficient data point cloud successfully estimate CBH. user can elect estimate missing CBH values accomplished via: Attempt extract CBH sample trees elected user (tree_sample_n,tree_sample_prop parameter) using ladderfuelsr_cbh() Successfully extracted CBH trees become training data used estimate height-CBH allometry relationship spatially informed using relative tree location compared training data height location predicting CBH model built point cloud training data used predict CBH non-training (.e. missing CBH) data","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_cbh_sf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate CBH using tree crown polygons and normalized point cloud data — trees_cbh_sf","text":"","code":"trees_cbh_sf(   trees_poly,   norm_las = NULL,   tree_sample_n = NA,   tree_sample_prop = NA,   which_cbh = \"lowest\",   min_vhp_n = 3,   voxel_grain_size_m = 1,   dist_btwn_bins_m = 1,   min_fuel_layer_ht_m = 1,   lad_pct_gap = 25,   lad_pct_base = 25,   num_jump_steps = 1,   min_lad_pct = 10,   frst_layer_min_ht_m = 1,   force_same_crs = F,   trees_sample = NA,   ofile = NA )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_cbh_sf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate CBH using tree crown polygons and normalized point cloud data — trees_cbh_sf","text":"trees_poly sf. sf class object POLYGON geometry (see sf::st_geometry_type()), program use data \"-\" require treeID tree_height_m columns. path single spatial polygon file. norm_las character. directory nomalized las files, path single .laz|.las file\", -- object class LAS. responsibility ensure point cloud projected trees_poly data tree_sample_n, tree_sample_prop numeric. Provide either tree_sample_n, number trees, tree_sample_prop, proportion trees attempt extract CBH point cloud . neither supplied, tree_sample_n = 333 used. supplied, tree_sample_n used. Increasing tree_sample_prop toward one (1) increase processing time, perhaps significantly depending number trees trees_poly data. which_cbh character. One : \"lowest\"; \"highest\"; \"max_lad\". See Viedma et al. (2024) reference. \"lowest\" - Height CBH segmented tree based last distance found profile \"highest\" - Height CBH segmented tree based maximum distance found profile \"max_lad\" - Height CBH segmented tree based maximum LAD percentage min_vhp_n numeric. minimum number vertical height profiles (VHPs) needed estimate CBH. voxel_grain_size_m numeric. horizontal resolution (suggested 1 meter lad profiles 10 meters LAI maps). See grain.size leafR::lad.voxels() dist_btwn_bins_m numeric. value actual height bin step (meters). See step LadderFuelsR::get_gaps_fbhs() min_fuel_layer_ht_m numeric. value actual minimum base height (meters). See min_height LadderFuelsR::get_gaps_fbhs() lad_pct_gap numeric. value percentile threshold used identify gaps (default percentile 25th). See perc_gap LadderFuelsR::get_gaps_fbhs() lad_pct_base numeric. value percentile threshold used identify fuels layers base height (default percentile 25th). See perc_base LadderFuelsR::get_gaps_fbhs() num_jump_steps numeric. value number height bin steps can jumped reshape fuels layers. See number_steps LadderFuelsR::get_real_fbh() min_lad_pct numeric. value minimum required LAD percentage fuel layer. See threshold LadderFuelsR::get_layers_lad() frst_layer_min_ht_m numeric. value depth height first fuel layer. first fuel layer maximum LAD depth greater indicated value, fuel layer considered CBH tree. contrary, depth <= value, CBH maximum LAD second fuel layer, although maximum LAD. See hdepth1_height LadderFuelsR::get_cbh_metrics() force_same_crs logical. force crs point cloud polygon confident data projection. data created cloud2trees pipeline (e.g. cloud2raster()) always projection even recognized lidR functions trees_sample data.frame. provide tree sample list one generated sample_trees_flist() includes treeID column. provided, tree_sample_n,tree_sample_prop ignored ofile character logical. character value provided output written disk csv location provided. set TRUE file path used input trees_poly, csv file written location name prefixed \"cbh_\". Leave NA return data.frame trees tree list trees_poly CBH values added","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_competition.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate competition metrics for a tree list — trees_competition","title":"Calculate competition metrics for a tree list — trees_competition","text":"trees_competition() uses input tree list (e.g. exported raster2trees()) columns treeID, tree_x, tree_y, tree_height_m calculate competition metrics tree level. Competition metrics returned include: Distance nearest neighbor (comp_dist_to_nearest_m) Trees per ha within 5m radius (comp_trees_per_ha) relative tree height (comp_relative_tree_height = height_tree / height_max) within 5m radius value 1 indicates tallest tree.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_competition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate competition metrics for a tree list — trees_competition","text":"","code":"trees_competition(   tree_list,   crs = NA,   competition_buffer_m = 5,   study_boundary = NA,   search_dist_max = 10 )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_competition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate competition metrics for a tree list — trees_competition","text":"tree_list data.frame. data frame columns treeID, tree_x, tree_y, tree_height_m. sf class object POINT geometry (see sf::st_geometry_type()), program use data \"-\" require treeID tree_height_m columns. crs string. crs string returned sf::st_crs() EPSG code x,y coordinates. Defaults crs tree_list data class \"sf\". competition_buffer_m number. Set buffer around tree (m) calculate competition metrics study_boundary sf. want scale per ha calculations, provide geography study boundary search_dist_max number. Maximum search distance (m) nearest tree. Larger search distances increase processing time possibly result memory issues. competition trees found within distance, return column comp_dist_to_nearest_m = search_dist_max parameter.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_competition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate competition metrics for a tree list — trees_competition","text":"Returns spatial data frame individual trees.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_competition.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate competition metrics for a tree list — trees_competition","text":"https://doi.org/10.3390/f13122077 Tinkham et al. (2022). Modeling missing DBHs: Influence model form UAV DBH characterization. Forests, 13(12), 2077.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_competition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate competition metrics for a tree list — trees_competition","text":"","code":"if (FALSE) { # \\dontrun{  # example tree list  tl <- dplyr::tibble(      treeID = c(1:21)      , tree_x = rnorm(n=21, mean = 458064, sd = 11)      , tree_y = rnorm(n=21, mean = 4450074, sd = 11)      , tree_height_m = exp(rgamma(n = 21, shape = (7/4)^2, rate = (4^2)/7))    )  # call the function  tl_comp <- trees_competition(tree_list = tl, crs = \"32613\")  # what?  tl_comp %>% class()  tl_comp %>% dplyr::select(tidyselect::starts_with(\"comp_\")) %>% dplyr::glimpse()  tl_comp %>% ggplot2::ggplot() + ggplot2::geom_sf(ggplot2::aes(color=comp_dist_to_nearest_m))  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_dbh.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate DBH for a tree list based on height — trees_dbh","title":"Estimate DBH for a tree list based on height — trees_dbh","text":"trees_dbh() uses input tree list (e.g. exported raster2trees()) columns treeID, tree_x, tree_y, tree_height_m estimate tree DBH. regional model height estimating DBH determined process: Use TreeMap (get_treemap()) FIA plot data area tree list estimate height-DBH allometry relationship Use height predicting DBH model built FIA data predict DBH based tree height tree list training data provided treels_dbh_locations returned treels_stem_dbh(): regional model using FIA plot data used filter DBH training data estimated point cloud training data used estimate height-DBH allometry relationship Use height predicting DBH model built point cloud training data predict DBH based tree height tree list","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_dbh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate DBH for a tree list based on height — trees_dbh","text":"","code":"trees_dbh(   tree_list,   crs = NA,   study_boundary = NA,   dbh_model = \"lin\",   treels_dbh_locations = NA,   boundary_buffer = 50,   input_treemap_dir = NULL,   outfolder = tempdir() )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_dbh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate DBH for a tree list based on height — trees_dbh","text":"tree_list data.frame. data frame columns treeID, tree_x, tree_y, tree_height_m. sf class object POINT geometry (see sf::st_geometry_type()), program use data \"-\" require treeID tree_height_m columns. crs string. crs string returned sf::st_crs() EPSG code x,y coordinates. Defaults crs tree_list data class \"sf\". study_boundary sf. boundary study define area regional model. boundary given, regional model built location trees tree list. dbh_model string. Set model use local dbh-height allometry. Can \"rf\" random forest \"lin\" linear treels_dbh_locations sf. Return treels_stem_dbh(). Must also provide crown polygons (returned raster2trees()) tree_list data sf class object POLYGON geometry (see sf::st_geometry_type()) valid file provided, make DBH predictions based training data instead regional model FIA data boundary_buffer numeric. Set buffer (m) study area boundary filter FIA plot data based TreeMap input_treemap_dir directory Treemap 2016 exists. Use get_treemap() first. outfolder string. path folder write model data ","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_dbh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate DBH for a tree list based on height — trees_dbh","text":"Returns spatial data frame individual trees.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_dbh.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate DBH for a tree list based on height — trees_dbh","text":"https://doi.org/10.2737/RDS-2025-0032 Houtman, Rachel M.; Leatherman, Lila S. T.; Zimmer, Scott N.; Housman, Ian W.; Shrestha, Abhinav; Shaw, John D.; Riley, Karin L. 2025. TreeMap 2022 CONUS: tree-level model forests conterminous United States circa 2022. Fort Collins, CO: Forest Service Research Data Archive. https://doi.org/10.3390/f13122077 Tinkham et al. (2022). Modeling missing DBHs: Influence model form UAV DBH characterization. Forests, 13(12), 2077.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_dbh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate DBH for a tree list based on height — trees_dbh","text":"","code":"if (FALSE) { # \\dontrun{  library(tidyverse)  # example tree list  tl <- dplyr::tibble(      treeID = c(1:21)      , tree_x = rnorm(n=21, mean = 458064, sd = 11)      , tree_y = rnorm(n=21, mean = 4450074, sd = 11)      , tree_height_m = exp(rgamma(n = 21, shape = (7/4)^2, rate = (4^2)/7))    )  # save our output somewhere (not required)  outdir <- tempdir()  # call the function  tl_dbh <- trees_dbh(tree_list = tl, crs = \"32613\", outfolder = outdir)  # what?  tl_dbh %>% class()  tl_dbh %>% dplyr::select(tidyselect::contains(\"dbh_cm\")) %>% dplyr::glimpse()  tl_dbh %>% ggplot2::ggplot() + ggplot2::geom_sf(ggplot2::aes(color=dbh_cm))  # what outputs did we get?  list.files(outdir)  # cloud2trees::trees_dbh() saved the FIA-measured trees used to train the allometric model  read.csv(file.path(outdir, \"regional_dbh_height_model_training_data.csv\")) %>%    summary()  # cloud2trees::trees_dbh() saved the actual allometric model  # let's load and review  dbh_mod_temp <- readRDS(file.path(outdir, \"regional_dbh_height_model.rds\"))  # what is this?  dbh_mod_temp %>% class()  # we can draw fit curves with probability bands using the tidybayes package  library(tidybayes)  # define our height range to predict over  dplyr::tibble(tree_height_m = seq(from = 0, to = 25, by = 1)) %>%    tidybayes::add_epred_draws(dbh_mod_temp, ndraws = 2000) %>%    ggplot2::ggplot(ggplot2::aes(x = tree_height_m)) +      tidybayes::stat_lineribbon(        ggplot2::aes(y = .epred, color = \"estimate\")        , .width = c(0.5,0.95)        , lwd = 0.6      ) +      ggplot2::scale_fill_brewer(palette = \"Oranges\") +      ggplot2::scale_color_manual(values = c(\"gray33\")) +      ggplot2::labs(x = \"tree ht. (m)\", y = \"est. tree DBH (cm)\", color = \"\") +      ggplot2::scale_x_continuous(limits = c(0,NA), breaks = scales::extended_breaks(n=11)) +      ggplot2::scale_y_continuous(limits = c(0,NA), breaks = scales::extended_breaks(n=11)) +      ggplot2::theme_light()  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_hmd.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate HMD using tree crown polygons and normalized point cloud data — trees_hmd","title":"Estimate HMD using tree crown polygons and normalized point cloud data — trees_hmd","text":"trees_hmd() uses input tree crown polygons (e.g. exported raster2trees()) columns treeID tree_height_m extracting height maximum crown diameter (HMD) using height normalized point cloud data (e.g. exported cloud2raster()). HMD extracted directly height normalized point cloud finding height non-ground point farthest tree center (.e. tree top). early version process developed Andrew Sanchez Meador. likely trees insufficient data point cloud successfully estimate HMD. user can elect estimate missing HMD values accomplished via: Attempt extract HMD trees Successfully extracted HMD trees become training data used estimate height-HMD allometry relationship spatially informed using relative tree location compared training data height location predicting HMD model built point cloud training data used predict HMD non-training (.e. missing HMD) data","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_hmd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate HMD using tree crown polygons and normalized point cloud data — trees_hmd","text":"","code":"trees_hmd(   trees_poly,   norm_las = NULL,   tree_sample_n = NA,   tree_sample_prop = NA,   estimate_missing_hmd = TRUE,   force_same_crs = F,   outfolder = tempdir() )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_hmd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate HMD using tree crown polygons and normalized point cloud data — trees_hmd","text":"trees_poly must one following required attributes treeID tree_height_m: sf class object POLYGON geometry (see sf::st_geometry_type()). Recommended smaller tree lists (e.g. <100k) can fit memory. character vector path single multiple spatial files can read sf::st_read() POLYGON geometry. Recommended large tree lists (e.g. 100k+) might cause memory issues. character path directory \"final_detected_crowns*\" files cloud2trees() raster2trees(). Recommended large tree lists (e.g. 100k+) might cause memory issues. norm_las character. directory nomalized las files, path single .laz|.las file\", -- object class LAScatalog. responsibility ensure point cloud projected trees_poly data tree_sample_n, tree_sample_prop numeric. Provide either tree_sample_n, number trees, tree_sample_prop, proportion trees attempt extract HMD point cloud . neither supplied, tree_sample_n = 777 used. supplied, tree_sample_n used. Increasing tree_sample_prop toward one (1) increase processing time, perhaps significantly depending number trees trees_poly data. estimate_missing_hmd logical. likely HMD extracted successfully every tree (especially low density clouds). missing HMD values estimated using tree height location information based trees HMD successfully extracted? force_same_crs logical. force crs point cloud polygon confident data projection. data created cloud2trees pipeline (e.g. cloud2raster()) always projection even recognized lidR functions outfolder string. path folder write model data . Note, actual missing value estimation many RF models estimated model averaging used. However, first estimated model saved export fully represent process used fill missing values.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_hmd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate HMD using tree crown polygons and normalized point cloud data — trees_hmd","text":"Returns spatial data frame individual trees added columns: max_crown_diam_height_m, is_training_hmd","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_hmd.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate HMD using tree crown polygons and normalized point cloud data — trees_hmd","text":"early version process developed Andrew Sanchez Meador.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_hmd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate HMD using tree crown polygons and normalized point cloud data — trees_hmd","text":"","code":"if (FALSE) { # \\dontrun{   library(tidyverse)   library(sf)   # example tree crown polygons   f <- paste0(system.file(package = \"cloud2trees\"),\"/extdata/crowns_poly.gpkg\")   crowns <- sf::st_read(f, quiet = T)   # example normalized las files are in this directory   norm_d <- paste0(system.file(package = \"cloud2trees\"),\"/extdata/norm_las\")   # now run the trees_hmd()   trees_hmd_ans <- trees_hmd(      trees_poly = crowns      , norm_las = norm_d      , force_same_crs = T      , estimate_missing_hmd = T)   # what?   trees_hmd_ans %>% dplyr::glimpse()   # spatial polygons   trees_hmd_ans %>% ggplot2::ggplot() +      ggplot2::geom_sf(ggplot2::aes(fill=max_crown_diam_height_m))   # relationship between height and hmd   trees_hmd_ans %>%      ggplot2::ggplot(        ggplot2::aes(          x = tree_height_m, y = max_crown_diam_height_m, color=is_training_hmd        )      ) +      ggplot2::geom_point()   #### try a file list   #### Recommended for large tree lists (e.g. 100k+) that might cause memory issues.   # we'll split the crowns   # as is done automatically for tree lists >250k by raster2trees() and cloud2trees()   crowns <- crowns %>%     dplyr::mutate(       # makes 2 groups of data       grp = ceiling(dplyr::row_number()/(dplyr::n()/2))     )   # make file names   my_dir <- tempdir()   fnm_1 <- file.path(my_dir, \"crowns1.gpkg\")   fnm_2 <- file.path(my_dir, \"crowns2.gpkg\")   fnm_1   # write the data   sf::st_write(crowns %>% dplyr::filter(grp==1), dsn = fnm_1, append = F) # grp 1   sf::st_write(crowns %>% dplyr::filter(grp==2), dsn = fnm_2, append = F) # grp 2   # try trees_cbh with our file list   flist <- c(fnm_1,fnm_2)   # now run the trees_hmd()   trees_hmd_ans2 <- trees_hmd(      trees_poly = flist      , norm_las = norm_d      , force_same_crs = T      , estimate_missing_hmd = T)   # tabulate training data   trees_hmd_ans %>%     sf::st_drop_geometry() %>%     dplyr::count(is_training_hmd)  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_hmd_sf.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate HMD using tree crown polygons and normalized point cloud data — trees_hmd_sf","title":"Estimate HMD using tree crown polygons and normalized point cloud data — trees_hmd_sf","text":"trees_hmd_sf() uses input tree crown polygons (e.g. exported raster2trees()) columns treeID tree_height_m extracting height maximum crown diameter (HMD) using height normalized point cloud data (e.g. exported cloud2raster()). HMD extracted directly height normalized point cloud finding height non-ground point farthest tree center (.e. tree top). early version process developed Andrew Sanchez Meador. likely trees insufficient data point cloud successfully estimate HMD. user can elect estimate missing HMD values accomplished via: Attempt extract HMD trees Successfully extracted HMD trees become training data used estimate height-HMD allometry relationship spatially informed using relative tree location compared training data height location predicting HMD model built point cloud training data used predict HMD non-training (.e. missing HMD) data","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_hmd_sf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate HMD using tree crown polygons and normalized point cloud data — trees_hmd_sf","text":"","code":"trees_hmd_sf(   trees_poly,   norm_las = NULL,   tree_sample_n = NA,   tree_sample_prop = NA,   force_same_crs = F,   trees_sample = NA,   ofile = NA )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_hmd_sf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate HMD using tree crown polygons and normalized point cloud data — trees_hmd_sf","text":"trees_poly sf. sf class object POLYGON geometry (see sf::st_geometry_type()), program use data \"-\" require treeID tree_height_m columns. path single spatial polygon file. norm_las character. directory nomalized las files, path single .laz|.las file\", -- object class LAScatalog. responsibility ensure point cloud projected trees_poly data tree_sample_n, tree_sample_prop numeric. Provide either tree_sample_n, number trees, tree_sample_prop, proportion trees attempt extract HMD point cloud . neither supplied, tree_sample_n = 777 used. supplied, tree_sample_n used. Increasing tree_sample_prop toward one (1) increase processing time, perhaps significantly depending number trees trees_poly data. force_same_crs logical. force crs point cloud polygon confident data projection. data created cloud2trees pipeline (e.g. cloud2raster()) always projection even recognized lidR functions trees_sample data.frame. provide tree sample list one generated sample_trees_flist() includes treeID column. provided, tree_sample_n,tree_sample_prop ignored ofile character logical. character value provided output written disk csv location provided. set TRUE file path used input trees_poly, csv file written location name prefixed \"hmd_\". Leave NA return data.frame trees tree list trees_poly HMD values added","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_landfire_cbd.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract LANDFIRE CBD raster cell value for a tree list based on location — trees_landfire_cbd","title":"Extract LANDFIRE CBD raster cell value for a tree list based on location — trees_landfire_cbd","text":"trees_landfire_cbd() uses input tree list (e.g. exported raster2trees()) columns treeID, tree_x, tree_y attach LANDFIRE's Forest Canopy Bulk Density (CBD) data estimate kilograms per cubic meter produced jointly U.S. Department Agriculture U.S. Department Interior. spatial data frame points input tree list, columns tree_x, tree_y required. LANDFIRE's Forest Canopy Bulk Density (CBD) data attached tree tree list based spatial overlap raster data set (see references). Canopy Bulk Density mass flammable material per unit volume tree crown typically expressed units mass per unit volume (e.g., kilograms per cubic meter). simplified process attaching LANDFIRE CBD raster cell value tree : Nearest neighbor imputation used fill LANDFIRE data tree falls inside non-forest cell original data LANDFIRE raster cell value kilograms per cubic meter applied tree based spatial overlap","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_landfire_cbd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract LANDFIRE CBD raster cell value for a tree list based on location — trees_landfire_cbd","text":"","code":"trees_landfire_cbd(   tree_list,   crs = NA,   study_boundary = NA,   input_landfire_dir = NULL,   max_search_dist_m = 1000 )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_landfire_cbd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract LANDFIRE CBD raster cell value for a tree list based on location — trees_landfire_cbd","text":"tree_list data.frame. data frame columns treeID, tree_x, tree_y, tree_height_m. sf class object POINT geometry (see sf::st_geometry_type()), program use data \"-\" require treeID column. crs string. crs string returned sf::st_crs() EPSG code x,y coordinates. Defaults crs tree_list data class \"sf\". study_boundary sf. boundary study define area regional model. boundary given, regional model built location trees tree list. input_landfire_dir directory LANDFIRE CBD data exists. Use get_landfire() first. max_search_dist_m number. Maximum search distance (m) obtain forest type group data trees tree_list overlap non-forest data original Wilson (2023) data. Larger search distances increase processing time possibly result memory issues.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_landfire_cbd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract LANDFIRE CBD raster cell value for a tree list based on location — trees_landfire_cbd","text":"Returns list objects: tree_list = spatial data frame individual trees column landfire_cell_kg_per_m3 added ; landfire_rast = raster kilograms per cubic meter area.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_landfire_cbd.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract LANDFIRE CBD raster cell value for a tree list based on location — trees_landfire_cbd","text":"LANDFIRE Forest Canopy Bulk Density (CBD) U.S. Department Agriculture U.S. Department Interior.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_landfire_cbd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract LANDFIRE CBD raster cell value for a tree list based on location — trees_landfire_cbd","text":"","code":"if (FALSE) { # \\dontrun{  library(tidyverse)  # example tree list  tl <- dplyr::tibble(      treeID = c(1:21)      , tree_x = rnorm(n=21, mean = 458064, sd = 11)      , tree_y = rnorm(n=21, mean = 4450074, sd = 11)    )  # call the function  tl_lf <- trees_landfire_cbd(tree_list = tl, crs = \"32613\")  # what?  tl_lf %>% class()  # a list, but what is in it?  tl_lf %>% names()  # what's in the trees data?  tl_lf$tree_list %>% dplyr::glimpse()  # plot the tree_list spatial points  tl_lf$tree_list %>% ggplot2::ggplot() +   ggplot2::geom_sf(ggplot2::aes(color=landfire_cell_kg_per_m3))  # plot the landfire cbd raster  tl_lf$landfire_rast %>% terra::plot()  # we can overlay these  tl_lf$landfire_rast %>%    terra::as.data.frame(xy = T) %>%    ggplot2::ggplot() +    ggplot2::geom_tile(ggplot2::aes(x=x,y=y,fill=kg_per_m3), color = \"gray\") +    ggplot2::geom_sf(      data = tl_lf$tree_list %>% sf::st_transform(terra::crs(tl_lf$landfire_rast))      , mapping = ggplot2::aes(color=landfire_cell_kg_per_m3)    ) +    ggplot2::scale_color_distiller(palette = \"Oranges\")  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate forest type for a tree list based on location — trees_type","title":"Estimate forest type for a tree list based on location — trees_type","text":"trees_type() uses input tree list (e.g. exported raster2trees()) columns treeID, tree_x, tree_y attach species information using USDA Forest Inventory Analysis (FIA) codes. spatial data frame points input tree list, columns tree_x, tree_y required. FIA Forest Type Group Code attached tree tree list based spatial overlap Forest Type Groups Continental United States dataset Wilson 2023. simplified process attaching forest type group tree : Forest type group 30-m raster (Wilson 2023) aggregated 90-m make data accessible entire continental US Nearest neighbor imputation used fill forest type data tree falls inside -forest cell original data FIA forest type group applied tree based spatial overlap","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate forest type for a tree list based on location — trees_type","text":"","code":"trees_type(   tree_list,   crs = NA,   study_boundary = NA,   input_foresttype_dir = NULL,   max_search_dist_m = 1000 )"},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate forest type for a tree list based on location — trees_type","text":"tree_list data.frame. data frame columns treeID, tree_x, tree_y, tree_height_m. sf class object POINT geometry (see sf::st_geometry_type()), program use data \"-\" require treeID column. crs string. crs string returned sf::st_crs() EPSG code x,y coordinates. Defaults crs tree_list data class \"sf\". study_boundary sf. boundary study area define area regional model. boundary given, regional model built location trees tree list. input_foresttype_dir directory Forest Type Groups data exists. Use get_foresttype() first. max_search_dist_m number. Maximum search distance (m) obtain forest type group data trees tree_list overlap non-forest data original Wilson (2023) data. Larger search distances increase processing time possibly result memory issues.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_type.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate forest type for a tree list based on location — trees_type","text":"Returns list objects: tree_list = spatial data frame individual trees; foresttype_rast = raster forest types area.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_type.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate forest type for a tree list based on location — trees_type","text":"Forest Type Groups Continental United States Wilson, B.T. (2023). Forest Type Groups Continental United States.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/reference/trees_type.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate forest type for a tree list based on location — trees_type","text":"","code":"if (FALSE) { # \\dontrun{  library(tidyverse)  # example tree list  tl <- dplyr::tibble(      treeID = c(1:21)      , tree_x = rnorm(n=21, mean = 458064, sd = 11)      , tree_y = rnorm(n=21, mean = 4450074, sd = 11)    )  # call the function  tl_type <- trees_type(tree_list = tl, crs = \"32613\")  # what?  tl_type %>% class()  # a list, but what is in it?  tl_type %>% names()  # plot the tree_list spatial points  tl_type$tree_list %>% ggplot2::ggplot() + ggplot2::geom_sf(ggplot2::aes(color=forest_type_group))  # plot the foresttype_rast raster  tl_type$foresttype_rast %>% terra::plot()  } # }"},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-073","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.7.3","title":"cloud2trees 0.7.3","text":"Fix: itd_tuning() longer fails sample plots trees either returns results backup plot detailed error message. Change: itd_tuning() now also includes plot_sample_summary object named list return includes figures summarizing trees extracted ITD window functions tested.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-072","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.7.2","title":"cloud2trees 0.7.2","text":"Updates use TreeMap 2022 (https://doi.org/10.2737/RDS-2025-0032). New data enables possible future development include species classification modeling CBH allometric prediction. Users update new data using: Change: trees_dbh() uses whichever version TreeMap installed detecting unique structure data available. warning given TreeMap 2022 downloaded. Also, improved error messages function users can better diagnose issues.","code":"get_treemap(force = T)"},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-071","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.7.1","title":"cloud2trees 0.7.1","text":"Updates cloud2trees_to_lanl_trees() writes data, includes unit tests cloud2trees_to_lanl_trees() (testing processing step directly), adds description file outputs cloud2trees_to_lanl_trees() process README, Rounded litter grass bulk density 3 digits fuellist output file Rounded litter grass moisture 2 digits fuellist output file Rounded litter grass sizescale 5 digits fuellist output file Rounded litter grass depth 2 digits fuellist output file Rounded numeric data Cloud2Trees_TreeList.txt file 4 digits Generate files except “topo.dat” file issue warning missing data Halt execution issue error missing data Change: cloud2trees() raster2trees() now check ws argument (ITD window function) prior data processing avoid failure processing steps already completed Fix: simplify_multipolygon_crowns() now accounts cases single tree multiple polygon parts equal area also largest part function returns exactly number records input data","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-070","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.7.0","title":"cloud2trees 0.7.0","text":"Enable formatting cloud2trees() data outputs LANL TREES program formatting fire modeling New: Adds function cloud2trees_to_lanl_trees() use outputs cloud2trees() generate inputs LANL TREES program New: utility functions working tree list data given AOI well preparing data LANL TREES R/utils_aoi.R","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-069","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.6.9","title":"cloud2trees 0.6.9","text":"Saving models used estimate missing HMD CBH values. Note, actual missing value estimation many RF models estimated model averaging used. However, first estimated model saved new export functionality fully represent process used fill missing values. Change: trees_hmd() now saves model used estimate missing HMD values path specified outfolder parameter estimate_missing_hmd = T Change: trees_cbh() now saves model used estimate missing HMD values path specified outfolder parameter estimate_missing_hmd = T Change: cloud2trees() automatically saves model used estimate missing HMD CBH values point_cloud_processing_delivery directory","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-068","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.6.8","title":"cloud2trees 0.6.8","text":"Change: cloud2raster() now implements noise removal point cloud prior ground classification stage (addition stage) minimize influence egregious outlier points classification","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-067","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.6.7","title":"cloud2trees 0.6.7","text":"Fix: itd_tuning() now accounts possible data transformation occurs raster2trees() State Plane Coordinate System (SPCS) zone projections use U.S. survey feet express eastings northings","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-066","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.6.6","title":"cloud2trees 0.6.6","text":"point cloud data – mostly USGS ALS acquisitions – made publicly available State Plane Coordinate System (SPCS) zone projections use U.S. survey feet express eastings northings (e.g. EPSG:6430). Furthermore, data utilize coordinate system combines two coordinate systems, horizontal vertical system defining Well-Known Text (WKT) using Compound Coordinate System (“COMPD_CS”). example, “NAD83(2011) / Colorado North (ftUS) + NAVD88 height - Geoid18 (ftUS)”. None cloud2trees methods methods utilized program designed work U.S. survey feet units. Furthermore, simple way transform data projected utilizing compound coordinate system transformations require manipulation full point cloud XYZ data (see ). update implements steps look specifically data projected using horizontal projection U.S. survey feet units, detected, program manipulates full point cloud data perform transformation. transformation applies EPSG:5070 projection, “NAD83/Conus Albers”, coordinate reference system (CRS) units meters spanning continental US (thus, feet transformation work elsewhere). transformation, cloud2trees methods methods utilized program work designed data projected using metric units. workflow tested two different SPCS zones issues identified unit tests passing issues may persist novel point cloud data. New: raster2trees(), extension cloud2trees(), implements steps look specifically data projected using horizontal projection U.S. survey feet units, detected, program manipulates full point cloud data perform transformation without input user. New: utility functions manipulation feet projections R/utils_projection.R","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-065","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.6.5","title":"cloud2trees 0.6.5","text":"Fix: trees_biomass() refuse overwrite values “landfire_” “cruz_” columns columns already existed data passed tree_list. update now forces overwrite data columns already present data.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-064","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.6.4","title":"cloud2trees 0.6.4","text":"Fix: ladderfuelsr_cbh() fail using las parameter due lack proper reference pointsByZSlice() function leafR package (https://github.com/DRAAlmeida/leafR). error within leafR package workaround define global variable pointsByZSlice <<- leafR::pointsByZSlice. Eventually, ladderfuelsr_cbh() needs break reliance leafR package. Fix: implements internal function as_character_safe() defined R/check_spatial_points.R convert numeric columns character meant used table identifier (.e. “primary key”) ensuring number cast character scientific notation. see difference, compare .character(1000000000) as_character_safe(1000000000).","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-063","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.6.3","title":"cloud2trees 0.6.3","text":"Fix: trees_biomass() (trees_biomass_*() functions) return NA biomass values trees fell within raster cell exactly bordered extent tree list. change calculates biomass border trees half raster cell (.e. forest “stand”) within study extent updating calc_rast_cell_overlap() utility function R/utils_biomass.R","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-062","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.6.2","title":"cloud2trees 0.6.2","text":"Several methods attaching tree component metrics involve modelling missing values using random forest model. computational cost random forests driven repeated tree building process, involves recursive partitioning, bootstrapping, feature subset selection. performed XXL tree lists (e.g. 100k+) operations result significant computational burden. Furthermore, large data sets can exceed available RAM, leading disk swapping, significantly slows computation. mitigate memory problems using randomForest::randomForest(), updates implement data subsampling large data sets reduce memory consumption randomly sampling representative subset training data. process iterated different subsets results combined via model averaging. Model averaging technique improving robustness accuracy random forest models, especially dealing large data sets. Change: trees_hmd() now implements random forest tuning modelling techniques described large data sets Change: trees_cbh() now implements random forest tuning modelling techniques described large data sets Change: moves utility functions random forest models R/utils_rf.R","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-061","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.6.1","title":"cloud2trees 0.6.1","text":"Change: updates trees_hmd() 0.6.0 now allows processing list files crown polygon data split crown polygon files “final_detected_crowns*” written automatically tree lists >250k raster2trees() cloud2trees(). enables extracting HMD XXL tree lists (e.g. 100k+) effectively mitigates memory issues associated lists. sampling still done considering full tree list. Change: moves utility functions trees_hmd() R/utils_hmd.R","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-060","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.6.0","title":"cloud2trees 0.6.0","text":"Change: trees_cbh() now allows processing list files crown polygon data split crown polygon files “final_detected_crowns*” written automatically tree lists >250k raster2trees() cloud2trees(). enables extracting CBH XXL tree lists (e.g. 100k+) effectively mitigates memory issues associated lists. sampling still done considering full tree list. Change: moves utility functions trees_cbh() R/utils_cbh.R trees_poly parameter trees_cbh() now accepts: sf class object POLYGON geometry (see [sf::st_geometry_type()]). Recommended smaller tree lists (e.g. <100k) can fit memory. character vector path single multiple spatial files can read [sf::st_read()] POLYGON geometry. Recommended large tree lists (e.g. 100k+) might cause memory issues. character path directory “final_detected_crowns*” files cloud2trees() raster2trees(). Recommended large tree lists (e.g. 100k+) might cause memory issues.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-059","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.5.9","title":"cloud2trees 0.5.9","text":"New: itd_ws_functions() makes list default functions can used determining variable window size detection individual trees accessible. Change: chunk_las_catalog() allow processing point clouds “NA” CRS projection using cloud2raster(). Enabling processing point cloud data “NA” projection. Fix: trees_cbh() potential memory leak cause memory full issues processing XXL tree lists (e.g. 100k+) cause “Error: allocate vector size…” errors just completely overwhelm machine. Taking steps remedy might ever fully resolved.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-058","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.5.8","title":"cloud2trees 0.5.8","text":"Several methods attaching tree component metrics involve modelling missing values using random forest model. cloud2trees random forest models tuned unique run using randomForest::tuneRF() enables model tuning searching optimal mtry parameter (number variables randomly sampled candidates split) using cross-validation approach. However, computational cost increases significantly number observations randomForest::tuneRF() performs cross-validation internally mtry value tries. large model training data (e.g. 100k+ observations), cross-validation runs involves building evaluating many random forest trees, making process time-consuming. update adds internal function rf_tune_subsample() implement steps mitigate long run-times tuning random forests models. rf_tune_subsample() mitigates long run-times : Reducing ntreeTry parameter smaller value. Tuning less precise, finish reasonable time. ntree parameter increased final model. Subsampling uses smaller, representative subsample data (e.g., 10-20% data) find good mtry value subsample. Change: trees_hmd() implements rf_tune_subsample() mitigate long run-times Change: trees_cbh() implements rf_tune_subsample() mitigate long run-times Change: trees_dbh() implements rf_tune_subsample() mitigate long run-times","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-057","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.5.7","title":"cloud2trees 0.5.7","text":"Fix: trees_cbh() trees_hmd() able match based treeID treeID column character also cast numeric value (e.g. “1111111”) due writing results disk storage rather keeping everything memory lidR::catalog_apply() re-reading results. update re-casts treeID ’s original data type. Fix: trees_cbh() trees_hmd() fail trees_poly data contained many trees (e.g. >1M) due exceeding maximum allowed size future package default options set via lidR::catalog_apply(). update chunks XXL tree lists groups 500k processing limit size constraint errors. Change: trees_hmd() now includes tree_sample_n tree_sample_prop parameters give option limit sample size. Prior change, HMD attempt extracted trees. Change: cloud2trees() now includes hmd_tree_sample_n hmd_tree_sample_prop parameters give option limit HMD sample size. Prior change, HMD attempt extracted trees. limit HMD samples via cloud2trees() set 20,000. Change: itd_tuning() renames default window size functions appropriately match function shape. defaults : exponential (exp_fn; concave ) nonlin_fn previous versions, linear (lin_fn) change, logarithmic (log_fn; concave ) exp_fn previous versions.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-056","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.5.6","title":"cloud2trees 0.5.6","text":"Fix: raster2trees() potentially fail writing data tempdir = tempdir() raster big fit memory. update also forces treeID column return data character type. Lastly, output function now written “final_detected_*.gpkg” instead “chm_detected_*.gpkg” match output cloud2trees(). Change: cloud2trees() now writes return data raster2trees() (“final_detected_*.gpkg”) prior completing following steps overwrites file upon completion steps.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-055","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.5.5","title":"cloud2trees 0.5.5","text":"Fix: raster2trees() potentially fail processing large rasters read terra “-memory” due invalid tree crown geometries generated raster tile processing. update implements additional checks fixes processing section raster big fit memory.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-054","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.5.4","title":"cloud2trees 0.5.4","text":"trees_biomass() (trees_biomass_*()) function allowed application unconstrained tree crown bulk density (CBD) values kilograms per cubic meter calculate crown biomass kilograms. CBD values calculated using sequence equations detailed trees_biomass_*() function documentation. scenarios small trees small crown diameters short crown lengths, example, CBD values >5 kilograms per cubic meter (sometimes even much larger) estimated using process. high CBD values improbable based literature. Mell et al. (2009) found dry bulk density tree crown 2.6 kilograms per cubed meter using Douglas-fir trees grown Christmas tree farms. update allows users constrain tree CBD values. Change: trees_biomass() (trees_biomass_*() functions) now parameter max_crown_kg_per_m3 limits maximum CBD tree crown kilograms per cubic meter. Values limit set median value area using stands CBD values lower limit. Change: cloud2trees() adds biomass_max_crown_kg_per_m3 parameter limit maximum CBD tree crown kilograms per cubic meter.","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-053","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.5.3","title":"cloud2trees 0.5.3","text":"New: Adds function itd_tuning() visually assess tree crown delineation results different window size functions used detection individual trees. Change: cloud2trees() raster2trees() now use non-linear window function individual tree detection (point settings got alignment)","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-052","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.5.2","title":"cloud2trees 0.5.2","text":"Fix: trees_cbh() check CBH height estimate missing CBH values attribute named “treeID” pre-existed point cloud data. fix forces overwrite “treeID” attribute point cloud data using polygon data. Change: cloud2trees() limits number trees extract CBH 20,000. users desire attempt extract CBH >20,000 trees, trees_cbh() can used standalone outputs cloud2trees().","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-051","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.5.1","title":"cloud2trees 0.5.1","text":"Updates process extract tree CBH implementing re-creation steps needed initially developed packages. Improves performance extraction CBH point cloud possibly allow users increase tree_sample_n /tree_sample_prop parameters trees_cbh() function. See (#10, @georgewoolsey). New: Adds leafr_for_ladderfuelsr() re-writes leafR package steps (https://github.com/DRAAlmeida/leafR) allow attribute input (e.g. “treeID”) removes need write individual tree point clouds disk extract LAD. output function used input ladderfuelsR (https://github.com/olgaviedma/LadderFuelsR) steps implemented ladderfuelsr_cbh() present package. New: Adds polygon_attribute_to_las() function attach polygon attribute point cloud Change: ladderfuelsr_cbh() now accepts input generated leafr_for_ladderfuelsr() addition maintaining backwards capability Change: trees_cbh() incorporates new process extract CBH noted increases default sample size Internal: R/check_las_data.R internal utility check input readable point cloud","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-050","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.5.0","title":"cloud2trees 0.5.0","text":"Implements methods estimate tree biomass (crown biomass) using stand-level estimates (e.g. LANDFIRE raster estimates) distributed across individual trees stand. See (#9, @georgewoolsey). New: Adds function trees_biomass() use input tree list (e.g. exported raster2trees()) estimate tree (crown) biomass using one many methods made available listed documentation New: Adds function trees_biomass_cruz() use input tree list (e.g. exported raster2trees()) estimate tree crown biomass based Cruz et al. (2003) New: Adds function trees_biomass_landfire() use input tree list (e.g. exported raster2trees()) estimate tree crown biomass based LANDFIRE’s Forest Canopy Bulk Density (CBD) data New: Adds function trees_landfire_cbd() attach raster cell value LANDFIRE’s Forest Canopy Bulk Density (CBD) data tree list New: Adds function get_landfire() download external LANDFIRE’s Forest Canopy Bulk Density (CBD) data Change: get_data() incorporates get_landfire() Change: find_ext_data() looks LANDFIRE data Change: cloud2trees() incorporates biomass process via trees_biomass() using parameter estimate_biomass_method Internal: R/utils_biomass.R internal utility functions distributing stand-level biomass tree-level Internal: R/check_spatial_points.R internal function standardize process check tree list passed trees_*() functions","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-042","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.4.2","title":"cloud2trees 0.4.2","text":"Updates point raster matching functionality allow broader application updates FIA Forest Type data 30m resolution. See (#8, @georgewoolsey). Change: get_foresttype() now defaults download 30m resolution data. previously ran get_foresttype() get_data() want use 30m data need manually download data . See example update local copy. New: Internal utility functions (see “utils_*.R”) created make point raster data matching extendable data (e.g. LANDFIRE) Change: trees_type() implements new internal point raster functions update local copy FIA Forest Type data:","code":"cloud2trees::get_foresttype(force = T, res = 30)"},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-041","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.4.1","title":"cloud2trees 0.4.1","text":"New: Makes function find_ext_data() attempts locate external data visible (internal) Change: cloud2raster() writes point cloud catalog file raw_las_ctg_info.gpkg point_cloud_processing_delivery directory","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-040","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.4.0","title":"cloud2trees 0.4.0","text":"Implements process extract height maximum crown diameter (HMD). See (#4, @georgewoolsey). New: Adds function trees_hmd() use input tree crown polygons (e.g. exported raster2trees()) estimate tree HMD based input normalized point cloud New: Adds simplify_multipolygon_crowns() simplify MULTIPOLYGON POLYGON geometry sf class object Change: cloud2trees() incorporates HMD process via trees_hmd()","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-031","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.3.1","title":"cloud2trees 0.3.1","text":"Updates processes rely lasR package implemented major revisions breaking changes lasR 0.13.0. package cloud2trees now requires lasR >= 0.13.1. Even updates, users may continue encounter bugs near future. See (#3, @georgewoolsey). update execute: Change: lasr_*() (internal functions) replace LASlib filters conform new lasR filtering (see https://r-lidar.github.io/lasR/reference/filters.html) Change: lasr_dtm_norm() (internal function) replaces LASlib filter -keep_random_fraction lasR::sampling_pixel() decimate ground points (see https://github.com/r-lidar/lasR/issues/102)","code":"# update lasR install.packages(\"lasR\", repos = \"https://r-lidar.r-universe.dev\") # update cloud2trees remotes::install_github(repo = \"georgewoolsey/cloud2trees\", upgrade = F)"},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-030","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.3.0","title":"cloud2trees 0.3.0","text":"Implements process extract USDA Forest Inventory Analysis (FIA) forest type group based Forest Type Groups Continental United States data (Wilson 2023). See (#2, @georgewoolsey). New: Adds function trees_type() use input tree list (e.g. exported raster2trees()) attach species information using FIA codes New: Adds get_data() --one function downloads external data used package New: Adds get_foresttype() downloads external data Forest Type Groups Continental United States New: Adds find_ext_data() attempts find location external data (downloaded get_*()) Change: cloud2trees() incorporates CONUS forest type process via trees_type()","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-020","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.2.0","title":"cloud2trees 0.2.0","text":"Integrates process extract crown base height (CBH) using workflow outlined Viedma et al. (2024) using package LadderFuelsR (https://github.com/olgaviedma/LadderFuelsR). See (#1, @georgewoolsey). New: Adds function trees_cbh() use input tree crown polygons (e.g. exported raster2trees()) estimate tree CBH based input normalized point cloud New: Adds ladderfuelsr_cbh() --one function extract CBH single tree, height normalized cloud using functionality LadderFuelsR package Change: cloud2trees() incorporates CBH process via trees_cbh() New: Adds error handling cloud2trees() stages trees extracted (e.g. DBH extraction) function complete successfully write extracted trees data point_cloud_processing_delivery directory. error message issued end (ERROR!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! : …) state portion complete successfully user can attempt re-run portion different settings (generally trees_*() function)","code":""},{"path":"https://georgewoolsey.github.io/cloud2trees/news/index.html","id":"cloud2trees-010","dir":"Changelog","previous_headings":"","what":"cloud2trees 0.1.0","title":"cloud2trees 0.1.0","text":"Open public","code":""}]
