% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cloud2trees.R
\name{cloud2trees}
\alias{cloud2trees}
\title{Use raw .las|.laz files to generate CHM, DTM, and a tree list}
\usage{
cloud2trees(
  output_dir,
  input_las_dir,
  input_treemap_dir = paste0(system.file(package = "cloud2trees"), "/extdata/treemap"),
  accuracy_level = 2,
  max_ctg_pts = 7e+07,
  max_area_m2 = 9e+07,
  transform = FALSE,
  new_crs = NA,
  old_crs = NA,
  keep_intrmdt = FALSE,
  dtm_res_m = 1,
  chm_res_m = 0.25,
  min_height = 2,
  max_height = 70,
  ws = function(x) {
     y <- dplyr::case_when(is.na(x) ~ 0.001, x < 0 ~ 0.001, x < 2 ~
    1, x > 30 ~ 5, TRUE ~ 0.75 + (x * 0.14))
     return(y)
 },
  estimate_tree_dbh = FALSE,
  max_dbh = 2,
  dbh_model = "lin",
  estimate_dbh_from_cloud = FALSE,
  estimate_tree_competition = FALSE,
  competition_buffer_m = 5,
  search_dist_max = 10,
  overwrite = TRUE
)
}
\arguments{
\item{output_dir}{parent directory where new folders \code{point_cloud_processing_delivery} and \code{point_cloud_processing_temp} will be written for exports}

\item{input_las_dir}{directory where .las|.laz point cloud data exists...program will search all sub-directories for all .las|.laz files and process them as one}

\item{input_treemap_dir}{directory where Treemap 2016 exists. Use \code{\link[=get_treemap]{get_treemap()}} first.}

\item{accuracy_level}{numeric. Choose processing accuracy.
accuracy_level = 1 uses DTM to height normalize the points
accuracy_level = 2 uses triangulation with high point density (20 pts/m2) to height normalize the points
accuracy_level = 3 uses triangulation with very high point density (100 pts/m2) to height normalize the points}

\item{max_ctg_pts}{numeric. Max number of points to process at one time. Setting this number higher will possibly reduce run times but increase the chance of running out of memory and vice versa.}

\item{max_area_m2}{numeric. Max area to process at one time. See \code{max_ctg_pts} parameter, this one is less important as never experienced memory issues with large areas (just lots of points)}

\item{transform}{logical. should the las/laz files be transformed? If set to \code{TRUE} the parameters \code{new_crs} must be defined.}

\item{new_crs}{string. crs to change to as an epsg numerical code}

\item{old_crs}{string. crs to change from as an epsg numerical code}

\item{keep_intrmdt}{logical. this process writes intermediate data to the disk, keep those intermediate files (classfied, normalized, stem las files)?}

\item{dtm_res_m}{numeric. The desired resolution of the DTM produced in meters.}

\item{chm_res_m}{numeric. The desired resolution of the CHM produced in meters.}

\item{min_height}{numeric. Set the minimum height (m) for individual tree detection}

\item{max_height}{numeric. Set the maximum height (m) for the canopy height model}

\item{ws}{numeric or function. Length or diameter of the moving window used to detect the local
maxima in the units of the input data (usually meters). If it is numeric a fixed window size is used.
If it is a function, the function determines the size of the window at any given location on the canopy.
By default function takes the height of a given pixel as its only argument and return the
desired size of the search window when centered on that pixel.}

\item{estimate_tree_dbh}{logical. Should tree DBH be estimated? See \code{\link[=trees_dbh]{trees_dbh()}}.}

\item{max_dbh}{numeric. Set the largest tree diameter (m) expected in the point cloud}

\item{dbh_model}{string. Set the model to use for local dbh-height allometry. Can be "rf" for random forest or "lin" for linear}

\item{estimate_dbh_from_cloud}{logical. Should DBH be estimated from the point cloud? See \code{\link[=treels_stem_dbh]{treels_stem_dbh()}}. Setting to \code{TRUE} may significantly increase processing time.}

\item{estimate_tree_competition}{logical. Should tree competition metrics be calculated? See \code{\link[=trees_competition]{trees_competition()}}. Setting to \code{TRUE} may slightly increase processing time.}

\item{competition_buffer_m}{number. Set buffer around tree (m) to calculate competition metrics}

\item{search_dist_max}{number. Maximum search distance (m) to nearest tree for competition. Larger search distances will increase processing time and possibly result in memory issues.
If no competition trees are found within this distance, the return column \code{comp_dist_to_nearest_m} = \code{search_dist_max} parameter.}

\item{overwrite}{logical. Should the output files in the \code{point_cloud_processing_delivery} directory from previous iterations be deleted?}
}
\value{
Returns the goods.
Exports files of the goods to new folders "point_cloud_processing_delivery" and "point_cloud_processing_temp" in the
\code{output_dir} defined by the user in the function call.
}
\description{
\code{cloud2trees()} is an all-in-one function to process raw .las|.laz files
to generate a CHM raster (.tif), a DTM raster (.tif), and a tree list with tree location, height, and DBH
The order of operations is:
\itemize{
\item Generate a CHM from the point cloud using \code{\link[=cloud2raster]{cloud2raster()}}
\item Perform individual tree detection using \code{\link[=raster2trees]{raster2trees()}}
\item Quantify individual tree competition metrics using \code{\link[=trees_competition]{trees_competition()}} (\emph{if set to TRUE})
\item Extract tree DBH values from the normalized point cloud using \code{\link[=treels_stem_dbh]{treels_stem_dbh()}} (\emph{if set to TRUE})
\item Model tree DBH values using \code{\link[=trees_dbh]{trees_dbh()}} (\emph{if set to TRUE})
}

See the documentation for each individual function called for more details.
}
\examples{
 \dontrun{
 o <- "hey"
 }
}
